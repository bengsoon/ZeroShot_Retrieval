{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "\n",
    "> Evaluation: Evaluators for zeroqaret project - ColBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zeroqaret.dataset import BEIRDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bengsoon/conda/envs/xcs224/lib/python3.9/site-packages/beir/datasets/data_loader.py:2: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "from loguru import logger\n",
    "import os\n",
    "from pathlib import Path\n",
    "from fastcore.basics import patch_to, patch\n",
    "\n",
    "from zeroqaret.helper import create_header\n",
    "from zeroqaret.dataset import BEIRDataset\n",
    "\n",
    "from getpass import getpass\n",
    "from typing import Union, Dict, List\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from colbert import Indexer, Searcher\n",
    "from colbert.infra import Run, RunConfig, ColBERTConfig\n",
    "from colbert import Trainer\n",
    "from colbert.data import Queries, Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from beir.retrieval.models import SentenceBERT\n",
    "from beir.retrieval.search.dense import DenseRetrievalExactSearch\n",
    "from beir.retrieval.evaluation import EvaluateRetrieval\n",
    "from beir import util\n",
    "from time import time\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from beir import util\n",
    "from typing import Union, Tuple, List\n",
    "from datetime import datetime\n",
    "import torch\n",
    "import numpy as np\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers import util as sbert_util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Get Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-10-31 12:41:15.471\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mzeroqaret.dataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1mDatasets will be saved in '/home/bengsoon/Projects/xcs224u_project/zeroqaret/datasets'\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "beir_datasets = BEIRDataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Collector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class ResultsCollector:\n",
    "    \"\"\" Collect results from Retrieval Evaluation for single dataset.\"\"\"\n",
    "    def __init__(self,\n",
    "                 model_path: str = None,\n",
    "                 dataset_name: str = None,\n",
    "                 split: str = \"test\",\n",
    "                 ):\n",
    "        self.model_path = model_path\n",
    "        self.dataset_name = dataset_name\n",
    "        self.split = split\n",
    "        logger.info(\"ResultsCollector object initialized.\")\n",
    "        \n",
    "    def collect(self,\n",
    "                experiment_name, \n",
    "                retriever,\n",
    "                results,\n",
    "                results_time):\n",
    "        \n",
    "        ndcg, map, recall, precision = retriever.evaluate(retriever.qrels, results, retriever.k_values)\n",
    "        \n",
    "        if not hasattr(self, \"ndcg\"): self.ndcg = pd.DataFrame()\n",
    "        if not hasattr(self, \"map\"): self.map = pd.DataFrame()\n",
    "        if not hasattr(self, \"recall\"): self.recall = pd.DataFrame()\n",
    "        if not hasattr(self, \"precision\"): self.precision = pd.DataFrame()\n",
    "        if not hasattr(self, \"time\"): self.time = pd.DataFrame()\n",
    "        \n",
    "        self.ndcg[experiment_name] = pd.Series(ndcg)\n",
    "        self.map[experiment_name] = pd.Series(map)\n",
    "        self.recall[experiment_name] = pd.Series(recall)\n",
    "        self.precision[experiment_name] = pd.Series(precision)\n",
    "        self.time[experiment_name] = pd.Series(results_time)\n",
    "\n",
    "    @property\n",
    "    def all(self):\n",
    "        metrics = [\"ndcg\", \"map\", \"recall\", \"precision\", \"time\"]\n",
    "        total_df = pd.DataFrame()\n",
    "        for attr in self.__dir__():\n",
    "            if attr in metrics:\n",
    "                total_df = pd.concat((total_df, getattr(self, attr)))\n",
    "        return total_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "@patch_to(ResultsCollector)\n",
    "def save_as_csv(self,\n",
    "                file_path: str,\n",
    "                table: str\n",
    "               ):\n",
    "    df = getattr(self, table)\n",
    "    df.to_csv(file_path, index = False)\n",
    "    logger.info(f\"Table '{table}' saved as '{file_path}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## SBERT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbert_model_name = \"all-mpnet-base-v2\"\n",
    "sbert_model = models.SentenceBERT(model_path=sbert_model_name)\n",
    "batch_size = 256,\n",
    "\n",
    "normalize = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbert_model = DenseRetrievalExactSearch(models.SentenceBERT(sbert_model_name, ), batch_size = 256, corpus_chunk_size=512*9999)\n",
    "sbert_retriever = EvaluateRetrieval(sbert_model, score_function=\"dot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus, queries, qrels = beir_datasets.load_dataset(\"scifact\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time()\n",
    "sbert_results = sbert_retriever.retrieve(corpus, queries)\n",
    "end_time = time()\n",
    "print(\"Time taken to retrieve: {:.2f} seconds\".format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Format of `results` from `retriever.retrieve`:\n",
    "``` python\n",
    "    {\n",
    "        str(qid) : {\n",
    "            str(pid) : score\n",
    "        }\n",
    "    }\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"Retriever evaluation for k in: {}\".format(sbert_retriever.k_values))\n",
    "sbert_ndcg, sbert_map, sbert_recall, sbert_precision = sbert_retriever.evaluate(qrels, sbert_results, sbert_retriever.k_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mrr = sbert_retriever.evaluate_custom(qrels, sbert_results, sbert_retriever.k_values, metric=\"mrr\")\n",
    "recall_cap = sbert_retriever.evaluate_custom(qrels, sbert_results, sbert_retriever.k_values, metric=\"r_cap\")\n",
    "hole = sbert_retriever.evaluate_custom(qrels, sbert_results, sbert_retriever.k_values, metric=\"hole\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k = 10\n",
    "\n",
    "query_id, ranking_scores = random.choice(list(sbert_results.items()))\n",
    "scores_sorted = sorted(ranking_scores.items(), key=lambda item: item[1], reverse=True)\n",
    "logger.info(\"Query : %s\\n\" % queries[query_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for rank in range(top_k):\n",
    "    doc_id = scores_sorted[rank][0]\n",
    "    # Format: Rank x: ID [Title] Body\n",
    "    logger.info(\"Rank %d: %s [%s] - %s\\n\" % (rank+1, doc_id, corpus[doc_id].get(\"title\"), corpus[doc_id].get(\"text\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from beir.retrieval import models\n",
    "# from beir import util\n",
    "# from typing import Union, Tuple, List\n",
    "# from datetime import datetime\n",
    "# import torch\n",
    "# import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# logger.info(\"Computing Document Embeddings...\")\n",
    "# if normalize:\n",
    "#     corpus_embs = model.encode_corpus(reduced_corpus, batch_size=128, convert_to_tensor=True, normalize_embeddings=True)\n",
    "# else:\n",
    "#     corpus_embs = model.encode_corpus(reduced_corpus, batch_size=128, convert_to_tensor=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## SBERTEval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SBERTEval(EvaluateRetrieval):\n",
    "    def __init__(self,\n",
    "                 model_path: Union[str, Tuple] = None,      \n",
    "                 normalize: bool = True, # if True, normalize encodings. Use dot-product if normalize, otherwise cosine-sim.\n",
    "                 encoding_batch_size: int = 128, # batch size for document embedding calculations.\n",
    "                 k_values: List[int] = [1,3,5,10,100,1000], # Top-k retrieval values for similarity search\n",
    "                 \n",
    "                ) -> None:\n",
    "        \"\"\" \n",
    "        Wrapper function for models.SentenceBERT with evaluation and experimentation functionality with MLflow. \n",
    "        Adapted from https://github.com/beir-cellar/beir/blob/main/examples/benchmarking/benchmark_sbert.py\n",
    "        \"\"\"\n",
    "        self.model_path = model_path\n",
    "        self.normalize = normalize\n",
    "        self.encoding_batch_size = encoding_batch_size\n",
    "        self.k_values = k_values\n",
    "        self.top_k = max(k_values)\n",
    "\n",
    "        ### SBERT model ###\n",
    "        self.model = SentenceBERT(self.model_path)\n",
    "                \n",
    "        ### initialize EvaluateRetrieval\n",
    "        super().__init__(self.model)\n",
    "\n",
    "        ### BEIRDatasets class ###\n",
    "        self.beir_datasets = BEIRDataset()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@patch_to(SBERTEval)\n",
    "def compute_corpus_embeddings(self, corpus):\n",
    "    if self.normalize:\n",
    "        return self.model.encode_corpus(corpus, batch_size=self.encoding_batch_size, convert_to_tensor=True, normalize_embeddings=True, show_progress_bar=True)\n",
    "    else:\n",
    "        return self.model.encode_corpus(corpus, batch_size=self.encoding_batch_size, convert_to_tensor=True, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@patch_to(SBERTEval)\n",
    "def search_queries(self,\n",
    "                   queries: Union[str, List], # single query or batch queries\n",
    "                   top_k: int\n",
    "                  ) -> (List[List[int]], List[List[float]]) :\n",
    "\n",
    "    \"\"\"\n",
    "    Performs cosine similarity calculation between query and document embeddings.\n",
    "    Returns (List[list of top-k docs indices for each query], List[similarity score for each query])  \n",
    "    \"\"\"\n",
    "    \n",
    "    if isinstance(queries, str):\n",
    "        queries = [queries]\n",
    "    \n",
    "    if self.normalize:\n",
    "        queries_emb = self.model.encode_queries(queries, batch_size=1, convert_to_tensor=True, normalize_embeddings=True, show_progress_bar=False)\n",
    "        #### Dot product for normalized embeddings is equal to cosine similarity\n",
    "        sim_scores = util.dot_score(queries_emb.to(\"cuda\"), self.doc_embeddings.to(\"cuda\"))\n",
    "    else:\n",
    "        queries_emb = self.model.encode_queries(queries, batch_size=1, convert_to_tensor=True, show_progress_bar=False)\n",
    "        #### Behind the hood, this cos_sim function will normalize the tensors first before applying dot-product \n",
    "        sim_scores = util.cos_sim(queries_emb.to(\"cuda\"), self.doc_embeddings.to(\"cuda\"))\n",
    "    \n",
    "    #### Get top-k ranking\n",
    "    sim_scores[torch.isnan(sim_scores)] = -1\n",
    "    sim_scores_top_k_values, sim_scores_top_k_idx = torch.topk(sim_scores, top_k, dim=1, largest=True, sorted=True)\n",
    "    \n",
    "    sim_scores_top_k_values = sim_scores_top_k_values.cpu().tolist()\n",
    "    sim_scores_top_k_idx = sim_scores_top_k_idx.cpu().tolist()\n",
    "    \n",
    "    return (sim_scores_top_k_idx, sim_scores_top_k_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@patch_to(SBERTEval)\n",
    "def beir_retrieval(self,\n",
    "                   dataset_name: str, # beir dataset name\n",
    "                   split: str = 'test', # split name\n",
    "                ) -> (Dict[str, Dict[str, float]], float):\n",
    "    \"\"\" Retrieval for BeIR dataset. \n",
    "    \n",
    "    Returns tuple of\n",
    "     - retrieval results `{str(qid) : {str(pid) : float(score)}}`\n",
    "     - time: `{\"Average Query Time (ms/it)\": float, \"Total Query Time (s)\": float, \"Total Document Embedding Time (s)\": float}\n",
    "\n",
    "     \"\"\"\n",
    "    logger.info(create_header(f\" Evaluation for '{dataset_name}' \"))\n",
    "    \n",
    "    # load dataset\n",
    "    self.raw_corpus, self.queries, self.qrels = self.beir_datasets.load_dataset(dataset_name, split)\n",
    "    self.corpus_ids, self.query_ids = list(self.raw_corpus), list(self.queries)\n",
    "\n",
    "    self.corpus = [self.raw_corpus[corpus_id] for corpus_id in self.corpus_ids]\n",
    "\n",
    "    logger.info(f\"Pre-computing Document Embeddings for '{dataset_name}' dataset...\")\n",
    "    #### Measuring Index size consumed by document embeddings\n",
    "    start = datetime.now()\n",
    "    self.doc_embeddings = self.compute_corpus_embeddings(self.corpus)\n",
    "    self.doc_embeddings = self.doc_embeddings.cpu()\n",
    "    end = datetime.now()\n",
    "    total_doc_emb_time = (end - start)\n",
    "    total_doc_emb_time = total_doc_emb_time.total_seconds()\n",
    "    \n",
    "    cpu_memory = sys.getsizeof(np.asarray([emb.numpy() for emb in self.doc_embeddings]))\n",
    "    \n",
    "    logger.info(\"Number of documents: {}, Dim: {}\".format(len(self.doc_embeddings), len(self.doc_embeddings[0])))\n",
    "    logger.info(\"Index size (in MB): {:.2f}MB\".format(cpu_memory*0.000001))\n",
    "    logger.info(f\"Time taken for pre-computing corpus embedding: {total_doc_emb_time:.2f} s\")\n",
    "    logger.info(\"Pre-computing of Document Embeddings done.\\n\\n\")\n",
    "    \n",
    "    #### Query benchmarking evaluation\n",
    "    logger.info(f\"Starting query benchmark evaluation ...\")\n",
    "    time_taken_all = {}\n",
    "    beir_results = {}\n",
    "    for query_id in tqdm(self.query_ids):\n",
    "        query = self.queries[query_id]\n",
    "        \n",
    "        #### Compute query embedding and retrieve similar scores using dot-product\n",
    "        start = datetime.now()\n",
    "        query_search_top_idx, query_search_score = self.search_queries(query, self.top_k)\n",
    "        end = datetime.now()\n",
    "        \n",
    "        #### Measuring time taken in ms (milliseconds)\n",
    "        time_taken = (end - start)\n",
    "        time_taken = time_taken.total_seconds() * 1000\n",
    "        time_taken_all[query_id] = time_taken\n",
    "        # logger.info(\"{}: {} {:.2f}ms\".format(query_id, query, time_taken))\n",
    "\n",
    "        # append to search_results {str(qid) : {str(pid) : score}}\n",
    "        beir_results[str(query_id)] = {str(self.corpus_ids[id]): score for id, score in zip(query_search_top_idx[0], query_search_score[0])}\n",
    "\n",
    "    total_query_time = sum(list(time_taken_all.values())) # in ms\n",
    "    average_query_time = total_query_time/len(time_taken_all) # ms/it\n",
    "    logger.info(\"Average time taken: {:.2f} ms / query\".format(average_query_time))\n",
    "    logger.info(\"Total time taken: {:.2f} s\".format(total_query_time))\n",
    "\n",
    "    time = {}\n",
    "    time[\"Average Query Time (ms/it)\"] = average_query_time\n",
    "    time[\"Total Query Time (s)\"] = total_query_time / 1000 # in seconds\n",
    "    time[\"Total Document Embedding Time (s)\"] = total_doc_emb_time\n",
    "\n",
    "    return (beir_results, time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## ColBERTv2 as BeIR Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class ColBERTRetrievalSearch(Indexer):\n",
    "    def __init__(self, \n",
    "                 checkpoint: str, # ColBERT checkpoint\n",
    "                 index_name: str, # name of the index\n",
    "                 experiment_name: str, # name of experiment\n",
    "                 collection: \"Collection\", # collection object in Collection format\n",
    "                 collection_ids: Dict, # {colbert_index: beir_pid}\n",
    "                 doc_maxlen: int,\n",
    "                 nbits: int,\n",
    "                 kmeans: int = 4,\n",
    "                 overwrite_param: Union[bool, str] = 'reuse',\n",
    "                 **kwargs):\n",
    "        \"\"\"\n",
    "        Retrieval Search wrapper for ColBERTv2, adapted from BeIR's `DenseRetrievalExactSearch`\n",
    "         (https://github.com/beir-cellar/beir/blob/f062f038c4bfd19a8ca942a9910b1e0d218759d4/beir/retrieval/search/dense/exact_search.py#L12).\n",
    "\n",
    "        The difference to BeIR's implementation is that if `corpus` and `corpus_ids` are passed at initialization stage, \n",
    "            it will pre-compute document encodings and store it. \n",
    "\n",
    "        If `index_name` and `overwrite = 'reuse'        \n",
    "        \"\"\"\n",
    "        self.checkpoint = checkpoint\n",
    "        self.index_name = index_name\n",
    "        self.collection = collection\n",
    "        self.collection_ids = collection_ids\n",
    "        self.experiment_name = experiment_name\n",
    "        self.doc_maxlen = doc_maxlen\n",
    "        self.nbits = nbits\n",
    "        self.kmeans = kmeans\n",
    "        self.overwrite_param = overwrite_param\n",
    "        \n",
    "        with Run().context(RunConfig(nranks=1, experiment=experiment_name)):  # nranks specifies the number of GPUs to use\n",
    "            config = ColBERTConfig(doc_maxlen=self.doc_maxlen, nbits=self.nbits, kmeans_niters=self.kmeans) # kmeans_niters specifies the number of iterations of k-means clustering; 4 is a good and fast default.\n",
    "                                                                                        # Consider larger numbers for small datasets.\n",
    "        \n",
    "            super().__init__(checkpoint=self.checkpoint, config=config)\n",
    "            self.index(name=self.index_name, collection=self.collection, overwrite=self.overwrite_param)\n",
    "            \n",
    "            self.searcher = Searcher(index=self.index_name, collection=self.collection)\n",
    "\n",
    "    def search(self,\n",
    "               corpus: \"Collection\" = None, # corpus in Collection format\n",
    "               queries: \"Queries\" = None, # queries in Queries format\n",
    "               k: int = 10, # top-K value\n",
    "               score_function = None, # redundant; here to make it compatible with function call from EvaluateRetrieval\n",
    "               filter_fn = None,              \n",
    "               full_length_search: bool = False,\n",
    "               **kwargs,\n",
    "              ) -> Dict[str, Dict[str, float]]:\n",
    "\n",
    "        res = self.searcher.search_all(queries, k, filter_fn, full_length_search)\n",
    "        self.results = {}\n",
    "        for qid, doc_res in res.items():\n",
    "            doc_res = {self.collection_ids[cid] : score for cid, rank, score in doc_res}\n",
    "            self.results[str(qid)] = doc_res\n",
    "\n",
    "        return self.results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `SciFact`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"scifact\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-10-31 12:41:22.562\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m12\u001b[0m - \u001b[1mResultsCollector object initialized.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "scifact_results = ResultsCollector(dataset_name=dataset_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SBERT Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use `multi-qa-MiniLM-L6-cos-v1` as our baseline;\n",
    "\n",
    "_This model was tuned for semantic search: Given a query/question, if can find relevant passages. It was trained on a large and diverse set of (question, answer) pairs._ [Ref](https://www.sbert.net/docs/pretrained_models.html#:~:text=Model%20Overview,-The%20following%20table&text=The%20all%2Dmpnet%2Dbase%2D,all%20existing%20sentence%2Dtransformers%20models.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model = \"multi-qa-MiniLM-L6-cos-v1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-10-31 12:41:27.090\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mzeroqaret.dataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1mDatasets will be saved in '/home/bengsoon/Projects/xcs224u_project/zeroqaret/datasets'\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "baseline_retriever = SBERTEval(model_path = baseline_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-10-31 12:41:32.009\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mbeir_retrieval\u001b[0m:\u001b[36m13\u001b[0m - \u001b[1m\n",
      "   \n",
      "****************************************************************************************************   \n",
      "******                                                                                        ******   \n",
      "*                                     Evaluation for 'scifact'                                     *   \n",
      "******                                                                                        ******   \n",
      "****************************************************************************************************\n",
      "\u001b[0m\n",
      "\u001b[32m2023-10-31 12:41:32.012\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mzeroqaret.dataset\u001b[0m:\u001b[36mload_dataset\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1mDownloading dataset 'scifact'...\u001b[0m\n",
      "\u001b[32m2023-10-31 12:41:32.012\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mzeroqaret.dataset\u001b[0m:\u001b[36mload_dataset\u001b[0m:\u001b[36m65\u001b[0m - \u001b[1mSaved on '/home/bengsoon/Projects/xcs224u_project/zeroqaret/datasets/scifact'\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8064e259f2e9479b82aa448504a91ea3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5183 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-10-31 12:41:32.095\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mbeir_retrieval\u001b[0m:\u001b[36m21\u001b[0m - \u001b[1mPre-computing Document Embeddings for 'scifact' dataset...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfdc7c97cd6a4fefabd9e8c378b8adda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-10-31 12:41:44.262\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mbeir_retrieval\u001b[0m:\u001b[36m32\u001b[0m - \u001b[1mNumber of documents: 5183, Dim: 384\u001b[0m\n",
      "\u001b[32m2023-10-31 12:41:44.264\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mbeir_retrieval\u001b[0m:\u001b[36m33\u001b[0m - \u001b[1mIndex size (in MB): 7.96MB\u001b[0m\n",
      "\u001b[32m2023-10-31 12:41:44.265\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mbeir_retrieval\u001b[0m:\u001b[36m34\u001b[0m - \u001b[1mTime taken for pre-computing corpus embedding: 12.15 s\u001b[0m\n",
      "\u001b[32m2023-10-31 12:41:44.266\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mbeir_retrieval\u001b[0m:\u001b[36m35\u001b[0m - \u001b[1mPre-computing of Document Embeddings done.\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[32m2023-10-31 12:41:44.267\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mbeir_retrieval\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mStarting query benchmark evaluation ...\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [00:02<00:00, 105.73it/s]\n",
      "\u001b[32m2023-10-31 12:41:47.109\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mbeir_retrieval\u001b[0m:\u001b[36m60\u001b[0m - \u001b[1mAverage time taken: 8.95 ms / query\u001b[0m\n",
      "\u001b[32m2023-10-31 12:41:47.110\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mbeir_retrieval\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mTotal time taken: 2683.61 s\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "results, results_time = baseline_retriever.beir_retrieval(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "scifact_results.collect(experiment_name=\"Baseline SBERT\", retriever=baseline_retriever, results=results, results_time=results_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Baseline SBERT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NDCG@1</th>\n",
       "      <td>0.436670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NDCG@3</th>\n",
       "      <td>0.504440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NDCG@5</th>\n",
       "      <td>0.523540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NDCG@10</th>\n",
       "      <td>0.540290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NDCG@100</th>\n",
       "      <td>0.589090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NDCG@1000</th>\n",
       "      <td>0.601310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAP@1</th>\n",
       "      <td>0.410280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAP@3</th>\n",
       "      <td>0.477850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAP@5</th>\n",
       "      <td>0.490840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAP@10</th>\n",
       "      <td>0.499190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAP@100</th>\n",
       "      <td>0.509100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAP@1000</th>\n",
       "      <td>0.509550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall@1</th>\n",
       "      <td>0.410280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall@3</th>\n",
       "      <td>0.553940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall@5</th>\n",
       "      <td>0.601830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall@10</th>\n",
       "      <td>0.650110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall@100</th>\n",
       "      <td>0.880330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall@1000</th>\n",
       "      <td>0.976670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P@1</th>\n",
       "      <td>0.436670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P@3</th>\n",
       "      <td>0.204440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P@5</th>\n",
       "      <td>0.135330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P@10</th>\n",
       "      <td>0.074330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P@100</th>\n",
       "      <td>0.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P@1000</th>\n",
       "      <td>0.001110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average Query Time (ms/it)</th>\n",
       "      <td>8.945380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total Query Time (s)</th>\n",
       "      <td>2.683614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total Document Embedding Time (s)</th>\n",
       "      <td>12.149655</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Baseline SBERT\n",
       "NDCG@1                                   0.436670\n",
       "NDCG@3                                   0.504440\n",
       "NDCG@5                                   0.523540\n",
       "NDCG@10                                  0.540290\n",
       "NDCG@100                                 0.589090\n",
       "NDCG@1000                                0.601310\n",
       "MAP@1                                    0.410280\n",
       "MAP@3                                    0.477850\n",
       "MAP@5                                    0.490840\n",
       "MAP@10                                   0.499190\n",
       "MAP@100                                  0.509100\n",
       "MAP@1000                                 0.509550\n",
       "Recall@1                                 0.410280\n",
       "Recall@3                                 0.553940\n",
       "Recall@5                                 0.601830\n",
       "Recall@10                                0.650110\n",
       "Recall@100                               0.880330\n",
       "Recall@1000                              0.976670\n",
       "P@1                                      0.436670\n",
       "P@3                                      0.204440\n",
       "P@5                                      0.135330\n",
       "P@10                                     0.074330\n",
       "P@100                                    0.010000\n",
       "P@1000                                   0.001110\n",
       "Average Query Time (ms/it)               8.945380\n",
       "Total Query Time (s)                     2.683614\n",
       "Total Document Embedding Time (s)       12.149655"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scifact_results.all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finetuning SBERT\n",
    "We will finetune `multi-qa-MiniLM-L6-cos-v1` with the generated Title, Questions\n",
    "\n",
    "https://github.com/UKPLab/sentence-transformers/blob/master/examples/unsupervised_learning/query_generation/2_programming_train_bi-encoder.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, InputExample, losses, models, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_scifact_df = pd.read_csv(\"../datasets/scifact/qg/scifact_qg_all.csv\", index_col=0)\n",
    "pids = gen_scifact_df[\"pid\"].tolist()\n",
    "passages = gen_scifact_df[\"passage\"].tolist()\n",
    "titles = gen_scifact_df[\"title\"].tolist()\n",
    "questions = gen_scifact_df[\"question\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-10-31 12:41:50.769\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mzeroqaret.dataset\u001b[0m:\u001b[36mload_dataset\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1mDownloading dataset 'scifact'...\u001b[0m\n",
      "\u001b[32m2023-10-31 12:41:50.772\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mzeroqaret.dataset\u001b[0m:\u001b[36mload_dataset\u001b[0m:\u001b[36m65\u001b[0m - \u001b[1mSaved on '/home/bengsoon/Projects/xcs224u_project/zeroqaret/datasets/scifact'\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2d5bf9c1c2e4d319718509584f64050",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5183 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "corpus, queries, qrels = beir_datasets.load_dataset(dataset_name)\n",
    "corpus_ids, query_ids = list(corpus), list(queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_examples = []\n",
    "for p, t, q in zip(passages, titles, questions):\n",
    "    anchor = str(t) + \" - \" + str(q)\n",
    "    train_examples.append(InputExample(texts=[anchor, p]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mutations in CTLA-4 Cause Complex Immune Dysregulation Syndrome - What is the syndrome associated with mutations in CTLA-4?',\n",
       " 'Autosomal dominant immune dysregulation syndrome in humans with CTLA4 mutations The protein cytotoxic T lymphocyte antigen-4 (CTLA-4) is an essential negative regulator of immune responses, and its loss causes fatal autoimmunity in mice. We studied a large family in which five individuals presented with a complex, autosomal dominant immune dysregulation syndrome characterized by hypogammaglobulinemia, recurrent infections and multiple autoimmune clinical features. We identified a heterozygous nonsense mutation in exon 1 of CTLA4. Screening of 71 unrelated patients with comparable clinical phenotypes identified five additional families (nine individuals) with previously undescribed splice site and missense mutations in CTLA4. Clinical penetrance was incomplete (eight adults of a total of 19 genetically proven CTLA4 mutation carriers were considered unaffected). However, CTLA-4 protein expression was decreased in regulatory T cells (Treg cells) in both patients and carriers with CTLA4 mutations. Whereas Treg cells were generally present at elevated numbers in these individuals, their suppressive function, CTLA-4 ligand binding and transendocytosis of CD80 were impaired. Mutations in CTLA4 were also associated with decreased circulating B cell numbers. Taken together, mutations in CTLA4 resulting in CTLA-4 haploinsufficiency or impaired ligand binding result in disrupted T and B cell homeostasis and a complex immune dysregulation syndrome.']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_examples[158].texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = datasets.NoDuplicatesDataLoader(train_examples, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_model = SentenceTransformer(baseline_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = losses.MultipleNegativesRankingLoss(ft_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c19d1bb634c046ec9852bf7542a2e558",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ba464cad41e401c821ebda9633a8d99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/647 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b25b2d5a0f66448991434bc082dca0fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/647 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5711fb753c749a98d20f8379e059987",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/647 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tune the model\n",
    "model_path = f\"../models/{baseline_model.replace('-', '_')}_ft\"\n",
    "num_epochs = 3\n",
    "warmup_steps = int(len(train_dataloader) * num_epochs * 0.1)\n",
    "ft_model.fit(train_objectives=[(train_dataloader, train_loss)], epochs=num_epochs, warmup_steps=warmup_steps, show_progress_bar=True, checkpoint_path=model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-10-31 12:45:41.498\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mzeroqaret.dataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1mDatasets will be saved in '/home/bengsoon/Projects/xcs224u_project/zeroqaret/datasets'\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "ft_retriever = SBERTEval(model_path, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-10-31 12:45:43.454\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mbeir_retrieval\u001b[0m:\u001b[36m13\u001b[0m - \u001b[1m\n",
      "   \n",
      "****************************************************************************************************   \n",
      "******                                                                                        ******   \n",
      "*                                     Evaluation for 'scifact'                                     *   \n",
      "******                                                                                        ******   \n",
      "****************************************************************************************************\n",
      "\u001b[0m\n",
      "\u001b[32m2023-10-31 12:45:43.456\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mzeroqaret.dataset\u001b[0m:\u001b[36mload_dataset\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1mDownloading dataset 'scifact'...\u001b[0m\n",
      "\u001b[32m2023-10-31 12:45:43.457\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mzeroqaret.dataset\u001b[0m:\u001b[36mload_dataset\u001b[0m:\u001b[36m65\u001b[0m - \u001b[1mSaved on '/home/bengsoon/Projects/xcs224u_project/zeroqaret/datasets/scifact'\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e80249652e7f4161af0722da66bbec44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5183 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-10-31 12:45:43.528\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mbeir_retrieval\u001b[0m:\u001b[36m21\u001b[0m - \u001b[1mPre-computing Document Embeddings for 'scifact' dataset...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00b8a0f72292404c8dfd3b1284b95904",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-10-31 12:45:53.553\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mbeir_retrieval\u001b[0m:\u001b[36m32\u001b[0m - \u001b[1mNumber of documents: 5183, Dim: 384\u001b[0m\n",
      "\u001b[32m2023-10-31 12:45:53.554\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mbeir_retrieval\u001b[0m:\u001b[36m33\u001b[0m - \u001b[1mIndex size (in MB): 7.96MB\u001b[0m\n",
      "\u001b[32m2023-10-31 12:45:53.555\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mbeir_retrieval\u001b[0m:\u001b[36m34\u001b[0m - \u001b[1mTime taken for pre-computing corpus embedding: 10.01 s\u001b[0m\n",
      "\u001b[32m2023-10-31 12:45:53.555\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mbeir_retrieval\u001b[0m:\u001b[36m35\u001b[0m - \u001b[1mPre-computing of Document Embeddings done.\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[32m2023-10-31 12:45:53.556\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mbeir_retrieval\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mStarting query benchmark evaluation ...\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [00:02<00:00, 111.92it/s]\n",
      "\u001b[32m2023-10-31 12:45:56.240\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mbeir_retrieval\u001b[0m:\u001b[36m60\u001b[0m - \u001b[1mAverage time taken: 8.43 ms / query\u001b[0m\n",
      "\u001b[32m2023-10-31 12:45:56.241\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mbeir_retrieval\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mTotal time taken: 2528.64 s\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "ft_results, ft_time = ft_retriever.beir_retrieval(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "scifact_results.collect(f\"{baseline_model}_ft\", ft_retriever, ft_results, ft_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Baseline SBERT</th>\n",
       "      <th>multi-qa-MiniLM-L6-cos-v1_ft</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NDCG@1</th>\n",
       "      <td>0.436670</td>\n",
       "      <td>0.436670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NDCG@3</th>\n",
       "      <td>0.504440</td>\n",
       "      <td>0.506720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NDCG@5</th>\n",
       "      <td>0.523540</td>\n",
       "      <td>0.532380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NDCG@10</th>\n",
       "      <td>0.540290</td>\n",
       "      <td>0.559350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NDCG@100</th>\n",
       "      <td>0.589090</td>\n",
       "      <td>0.599260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NDCG@1000</th>\n",
       "      <td>0.601310</td>\n",
       "      <td>0.611480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAP@1</th>\n",
       "      <td>0.410280</td>\n",
       "      <td>0.416670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAP@3</th>\n",
       "      <td>0.477850</td>\n",
       "      <td>0.482630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAP@5</th>\n",
       "      <td>0.490840</td>\n",
       "      <td>0.499390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAP@10</th>\n",
       "      <td>0.499190</td>\n",
       "      <td>0.511600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAP@100</th>\n",
       "      <td>0.509100</td>\n",
       "      <td>0.520600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAP@1000</th>\n",
       "      <td>0.509550</td>\n",
       "      <td>0.521070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall@1</th>\n",
       "      <td>0.410280</td>\n",
       "      <td>0.416670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall@3</th>\n",
       "      <td>0.553940</td>\n",
       "      <td>0.553280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall@5</th>\n",
       "      <td>0.601830</td>\n",
       "      <td>0.614500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall@10</th>\n",
       "      <td>0.650110</td>\n",
       "      <td>0.694110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall@100</th>\n",
       "      <td>0.880330</td>\n",
       "      <td>0.873670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall@1000</th>\n",
       "      <td>0.976670</td>\n",
       "      <td>0.969330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P@1</th>\n",
       "      <td>0.436670</td>\n",
       "      <td>0.436670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P@3</th>\n",
       "      <td>0.204440</td>\n",
       "      <td>0.201110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P@5</th>\n",
       "      <td>0.135330</td>\n",
       "      <td>0.137330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P@10</th>\n",
       "      <td>0.074330</td>\n",
       "      <td>0.079000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P@100</th>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.009930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P@1000</th>\n",
       "      <td>0.001110</td>\n",
       "      <td>0.001100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average Query Time (ms/it)</th>\n",
       "      <td>8.945380</td>\n",
       "      <td>8.428813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total Query Time (s)</th>\n",
       "      <td>2.683614</td>\n",
       "      <td>2.528644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total Document Embedding Time (s)</th>\n",
       "      <td>12.149655</td>\n",
       "      <td>10.005271</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Baseline SBERT  \\\n",
       "NDCG@1                                   0.436670   \n",
       "NDCG@3                                   0.504440   \n",
       "NDCG@5                                   0.523540   \n",
       "NDCG@10                                  0.540290   \n",
       "NDCG@100                                 0.589090   \n",
       "NDCG@1000                                0.601310   \n",
       "MAP@1                                    0.410280   \n",
       "MAP@3                                    0.477850   \n",
       "MAP@5                                    0.490840   \n",
       "MAP@10                                   0.499190   \n",
       "MAP@100                                  0.509100   \n",
       "MAP@1000                                 0.509550   \n",
       "Recall@1                                 0.410280   \n",
       "Recall@3                                 0.553940   \n",
       "Recall@5                                 0.601830   \n",
       "Recall@10                                0.650110   \n",
       "Recall@100                               0.880330   \n",
       "Recall@1000                              0.976670   \n",
       "P@1                                      0.436670   \n",
       "P@3                                      0.204440   \n",
       "P@5                                      0.135330   \n",
       "P@10                                     0.074330   \n",
       "P@100                                    0.010000   \n",
       "P@1000                                   0.001110   \n",
       "Average Query Time (ms/it)               8.945380   \n",
       "Total Query Time (s)                     2.683614   \n",
       "Total Document Embedding Time (s)       12.149655   \n",
       "\n",
       "                                   multi-qa-MiniLM-L6-cos-v1_ft  \n",
       "NDCG@1                                                 0.436670  \n",
       "NDCG@3                                                 0.506720  \n",
       "NDCG@5                                                 0.532380  \n",
       "NDCG@10                                                0.559350  \n",
       "NDCG@100                                               0.599260  \n",
       "NDCG@1000                                              0.611480  \n",
       "MAP@1                                                  0.416670  \n",
       "MAP@3                                                  0.482630  \n",
       "MAP@5                                                  0.499390  \n",
       "MAP@10                                                 0.511600  \n",
       "MAP@100                                                0.520600  \n",
       "MAP@1000                                               0.521070  \n",
       "Recall@1                                               0.416670  \n",
       "Recall@3                                               0.553280  \n",
       "Recall@5                                               0.614500  \n",
       "Recall@10                                              0.694110  \n",
       "Recall@100                                             0.873670  \n",
       "Recall@1000                                            0.969330  \n",
       "P@1                                                    0.436670  \n",
       "P@3                                                    0.201110  \n",
       "P@5                                                    0.137330  \n",
       "P@10                                                   0.079000  \n",
       "P@100                                                  0.009930  \n",
       "P@1000                                                 0.001100  \n",
       "Average Query Time (ms/it)                             8.428813  \n",
       "Total Query Time (s)                                   2.528644  \n",
       "Total Document Embedding Time (s)                     10.005271  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scifact_results.all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# faiss-gpu\n",
    "# %conda install -c pytorch -c nvidia faiss-gpu=1.7.4 mkl=2021 blas=1.0=mkl\n",
    "\n",
    "# torch\n",
    "# %pip install torch=1.13.1 torchaudio==0.13.1 torchvision==0.14.1\n",
    "\n",
    "# others\n",
    "# %pip install bitarray datasets gitpython ninja scipy spacy tqdm transformers ujson flask python-dotenv\n",
    "\n",
    "## git clone colbert repo into \"../ColBERT\"\n",
    "# !cd .. && git clone https://github.com/stanford-futuredata/ColBERT.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ColBERTv2 Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c29abb28d5940a5a36ff4e1a196c5fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5183 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17cf9b6e32d24bd3ac056102063f0195",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5183 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-10-31 16:44:05.532\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mzeroqaret.dataset\u001b[0m:\u001b[36mconvert_for_colbert\u001b[0m:\u001b[36m98\u001b[0m - \u001b[1mPreprocessing Corpus and Saving to /home/bengsoon/Projects/xcs224u_project/zeroqaret/datasets/scifact/colbert/scifact_collection.tsv ...\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 5183/5183 [00:00<00:00, 33566.24it/s]\n",
      "\u001b[32m2023-10-31 16:44:05.694\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mzeroqaret.dataset\u001b[0m:\u001b[36mconvert_for_colbert\u001b[0m:\u001b[36m105\u001b[0m - \u001b[1mPreprocessing Corpus and Saving to /home/bengsoon/Projects/xcs224u_project/zeroqaret/datasets/scifact/colbert/scifact_queries.tsv ...\u001b[0m\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [00:00<00:00, 315598.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Oct 31, 16:44:05] #> Loading collection...\n",
      "0M \n",
      "[Oct 31, 16:44:05] #> Loading the queries from /home/bengsoon/Projects/xcs224u_project/zeroqaret/datasets/scifact/colbert/scifact_queries.tsv ...\n",
      "[Oct 31, 16:44:05] #> Got 300 queries. All QIDs are unique.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset_name = \"scifact\"\n",
    "corpus, queries, qrels = beir_datasets.load_dataset(dataset_name)\n",
    "\n",
    "# The indices in BeIR datasets may not be monotic, \n",
    "### so we will need a dictionary with enumerated indices (which is used in ColBERT) as keys and BeIR index as values\n",
    "### collection_ids = {colbert_index: beir_index}\n",
    "collection_ids = {idx: str(val) for idx, val in enumerate(list(corpus))}\n",
    "\n",
    "# Load datasets for ColBERT\n",
    "collection_path, queries_path = beir_datasets.convert_for_colbert(dataset_name)\n",
    "collection, queries = Collection(path=collection_path), Queries(path=queries_path)\n",
    "\n",
    "# queries_ids = list(queries)\n",
    "# queries = list(queries.values())\n",
    "\n",
    "checkpoint = 'colbert-ir/colbertv2.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbits = 2   # encode each dimension with 2 bits\n",
    "doc_maxlen = 300 # truncate passages at 300 tokens\n",
    "\n",
    "index_name = f'{dataset_name}.{nbits}bits'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[Oct 31, 16:44:09] #> Creating directory /home/bengsoon/Projects/xcs224u_project/zeroqaret/nbs/experiments/ColBERTRetrievalSearch_test/indexes/scifact.2bits \n",
      "\n",
      "\n",
      "#> Starting...\n",
      "nranks = 1 \t num_gpus = 1 \t device=0\n",
      "{\n",
      "    \"query_token_id\": \"[unused0]\",\n",
      "    \"doc_token_id\": \"[unused1]\",\n",
      "    \"query_token\": \"[Q]\",\n",
      "    \"doc_token\": \"[D]\",\n",
      "    \"ncells\": null,\n",
      "    \"centroid_score_threshold\": null,\n",
      "    \"ndocs\": null,\n",
      "    \"load_index_with_mmap\": false,\n",
      "    \"index_path\": null,\n",
      "    \"nbits\": 2,\n",
      "    \"kmeans_niters\": 4,\n",
      "    \"resume\": false,\n",
      "    \"similarity\": \"cosine\",\n",
      "    \"bsize\": 64,\n",
      "    \"accumsteps\": 1,\n",
      "    \"lr\": 3e-6,\n",
      "    \"maxsteps\": 500000,\n",
      "    \"save_every\": null,\n",
      "    \"warmup\": null,\n",
      "    \"warmup_bert\": null,\n",
      "    \"relu\": false,\n",
      "    \"nway\": 2,\n",
      "    \"use_ib_negatives\": false,\n",
      "    \"reranker\": false,\n",
      "    \"distillation_alpha\": 1.0,\n",
      "    \"ignore_scores\": false,\n",
      "    \"model_name\": null,\n",
      "    \"query_maxlen\": 32,\n",
      "    \"attend_to_mask_tokens\": false,\n",
      "    \"interaction\": \"colbert\",\n",
      "    \"dim\": 128,\n",
      "    \"doc_maxlen\": 300,\n",
      "    \"mask_punctuation\": true,\n",
      "    \"checkpoint\": \"colbert-ir\\/colbertv2.0\",\n",
      "    \"triples\": null,\n",
      "    \"collection\": \"\\/home\\/bengsoon\\/Projects\\/xcs224u_project\\/zeroqaret\\/datasets\\/scifact\\/colbert\\/scifact_collection.tsv\",\n",
      "    \"queries\": null,\n",
      "    \"index_name\": \"scifact.2bits\",\n",
      "    \"overwrite\": false,\n",
      "    \"root\": \"\\/home\\/bengsoon\\/Projects\\/xcs224u_project\\/zeroqaret\\/nbs\\/experiments\",\n",
      "    \"experiment\": \"ColBERTRetrievalSearch_test\",\n",
      "    \"index_root\": null,\n",
      "    \"name\": \"2023-10\\/31\\/12.41.13\",\n",
      "    \"rank\": 0,\n",
      "    \"nranks\": 1,\n",
      "    \"amp\": true,\n",
      "    \"gpus\": 1\n",
      "}\n",
      "[Oct 31, 16:44:16] [0] \t\t # of sampled PIDs = 5183 \t sampled_pids[:3] = [3412, 83, 2446]\n",
      "[Oct 31, 16:44:16] [0] \t\t #> Encoding 5183 passages..\n",
      "[Oct 31, 16:44:28] [0] \t\t avg_doclen_est = 237.2859344482422 \t len(local_sample) = 5,183\n",
      "[Oct 31, 16:44:28] [0] \t\t Creaing 16,384 partitions.\n",
      "[Oct 31, 16:44:28] [0] \t\t *Estimated* 1,229,852 embeddings.\n",
      "[Oct 31, 16:44:28] [0] \t\t #> Saving the indexing plan to /home/bengsoon/Projects/xcs224u_project/zeroqaret/nbs/experiments/ColBERTRetrievalSearch_test/indexes/scifact.2bits/plan.json ..\n",
      "Clustering 1179853 points in 128D to 16384 clusters, redo 1 times, 4 iterations\n",
      "  Preprocessing in 0.10 s\n",
      "  Iteration 3 (2.79 s, search 2.52 s): objective=237901 imbalance=1.394 nsplit=0       \n",
      "[Oct 31, 16:44:32] Loading decompress_residuals_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n",
      "[Oct 31, 16:44:32] Loading packbits_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n",
      "[0.031, 0.034, 0.034, 0.029, 0.03, 0.032, 0.033, 0.03, 0.03, 0.032, 0.03, 0.031, 0.033, 0.033, 0.03, 0.032, 0.029, 0.03, 0.029, 0.03, 0.031, 0.031, 0.031, 0.031, 0.031, 0.031, 0.033, 0.031, 0.03, 0.034, 0.03, 0.035, 0.032, 0.03, 0.031, 0.029, 0.034, 0.032, 0.031, 0.038, 0.032, 0.032, 0.031, 0.032, 0.03, 0.031, 0.032, 0.035, 0.032, 0.03, 0.03, 0.032, 0.033, 0.031, 0.03, 0.031, 0.038, 0.032, 0.036, 0.031, 0.031, 0.034, 0.032, 0.034, 0.033, 0.031, 0.032, 0.033, 0.03, 0.031, 0.033, 0.029, 0.031, 0.033, 0.03, 0.035, 0.033, 0.032, 0.032, 0.034, 0.032, 0.031, 0.032, 0.033, 0.029, 0.032, 0.031, 0.033, 0.029, 0.034, 0.031, 0.034, 0.031, 0.032, 0.032, 0.033, 0.036, 0.032, 0.031, 0.031, 0.033, 0.035, 0.034, 0.03, 0.033, 0.031, 0.032, 0.031, 0.032, 0.03, 0.032, 0.032, 0.032, 0.028, 0.032, 0.03, 0.031, 0.032, 0.03, 0.031, 0.03, 0.032, 0.033, 0.035, 0.03, 0.034, 0.031, 0.03]\n",
      "[Oct 31, 16:44:32] #> Got bucket_cutoffs_quantiles = tensor([0.2500, 0.5000, 0.7500], device='cuda:0') and bucket_weights_quantiles = tensor([0.1250, 0.3750, 0.6250, 0.8750], device='cuda:0')\n",
      "[Oct 31, 16:44:32] #> Got bucket_cutoffs = tensor([-0.0254,  0.0000,  0.0255], device='cuda:0') and bucket_weights = tensor([-0.0447, -0.0118,  0.0118,  0.0449], device='cuda:0')\n",
      "[Oct 31, 16:44:32] avg_residual = 0.03179931640625\n",
      "[Oct 31, 16:44:32] [0] \t\t #> Encoding 5183 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Oct 31, 16:44:44] [0] \t\t #> Saving chunk 0: \t 5,183 passages and 1,229,853 embeddings. From #0 onward.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:11, 11.85s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00, 433.34it/s]\n",
      "  0%|          | 0/16384 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Oct 31, 16:44:44] [0] \t\t #> Checking all files were saved...\n",
      "[Oct 31, 16:44:44] [0] \t\t Found all files!\n",
      "[Oct 31, 16:44:44] [0] \t\t #> Building IVF...\n",
      "[Oct 31, 16:44:44] [0] \t\t #> Loading codes...\n",
      "[Oct 31, 16:44:44] [0] \t\t Sorting codes...\n",
      "[Oct 31, 16:44:44] [0] \t\t Getting unique codes...\n",
      "[Oct 31, 16:44:44] #> Optimizing IVF to store map from centroids to list of pids..\n",
      "[Oct 31, 16:44:44] #> Building the emb2pid mapping..\n",
      "[Oct 31, 16:44:44] len(emb2pid) = 1229853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16384/16384 [00:00<00:00, 72281.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Oct 31, 16:44:44] #> Saved optimized IVF to /home/bengsoon/Projects/xcs224u_project/zeroqaret/nbs/experiments/ColBERTRetrievalSearch_test/indexes/scifact.2bits/ivf.pid.pt\n",
      "[Oct 31, 16:44:44] [0] \t\t #> Saving the indexing metadata to /home/bengsoon/Projects/xcs224u_project/zeroqaret/nbs/experiments/ColBERTRetrievalSearch_test/indexes/scifact.2bits/metadata.json ..\n",
      "#> Joined...\n",
      "[Oct 31, 16:44:50] #> Loading codec...\n",
      "[Oct 31, 16:44:50] Loading decompress_residuals_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n",
      "[Oct 31, 16:44:50] Loading packbits_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n",
      "[Oct 31, 16:44:51] #> Loading IVF...\n",
      "[Oct 31, 16:44:51] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1502.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Oct 31, 16:44:51] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 45.36it/s]\n"
     ]
    }
   ],
   "source": [
    "model = ColBERTRetrievalSearch(checkpoint, \n",
    "                                   index_name, \n",
    "                                   experiment_name=\"ColBERTRetrievalSearch_test\", \n",
    "                                   collection=collection, \n",
    "                                   collection_ids=collection_ids,\n",
    "                                   doc_maxlen=doc_maxlen, \n",
    "                                   nbits=nbits, \n",
    "                                   overwrite_param=\"reuse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = EvaluateRetrieval(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "300it [00:03, 91.29it/s]\n"
     ]
    }
   ],
   "source": [
    "results = retriever.retrieve(collection, queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever.qrels = qrels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "scifact_results.collect(\"ColBERTv2 Baseline\", retriever, results, {'Average Query Time (ms/it)': 10.95, 'Total Query Time (s)': 3.0, 'Total Document Embedding Time (s)': None})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Baseline SBERT</th>\n",
       "      <th>multi-qa-MiniLM-L6-cos-v1_ft</th>\n",
       "      <th>ColBERTv2 Baseline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NDCG@1</th>\n",
       "      <td>0.436670</td>\n",
       "      <td>0.436670</td>\n",
       "      <td>0.58667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NDCG@3</th>\n",
       "      <td>0.504440</td>\n",
       "      <td>0.506720</td>\n",
       "      <td>0.65424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NDCG@5</th>\n",
       "      <td>0.523540</td>\n",
       "      <td>0.532380</td>\n",
       "      <td>0.67280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NDCG@10</th>\n",
       "      <td>0.540290</td>\n",
       "      <td>0.559350</td>\n",
       "      <td>0.69195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NDCG@100</th>\n",
       "      <td>0.589090</td>\n",
       "      <td>0.599260</td>\n",
       "      <td>0.71650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NDCG@1000</th>\n",
       "      <td>0.601310</td>\n",
       "      <td>0.611480</td>\n",
       "      <td>0.72385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAP@1</th>\n",
       "      <td>0.410280</td>\n",
       "      <td>0.416670</td>\n",
       "      <td>0.55717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAP@3</th>\n",
       "      <td>0.477850</td>\n",
       "      <td>0.482630</td>\n",
       "      <td>0.62802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAP@5</th>\n",
       "      <td>0.490840</td>\n",
       "      <td>0.499390</td>\n",
       "      <td>0.64135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAP@10</th>\n",
       "      <td>0.499190</td>\n",
       "      <td>0.511600</td>\n",
       "      <td>0.65074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAP@100</th>\n",
       "      <td>0.509100</td>\n",
       "      <td>0.520600</td>\n",
       "      <td>0.65578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAP@1000</th>\n",
       "      <td>0.509550</td>\n",
       "      <td>0.521070</td>\n",
       "      <td>0.65607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall@1</th>\n",
       "      <td>0.410280</td>\n",
       "      <td>0.416670</td>\n",
       "      <td>0.55717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall@3</th>\n",
       "      <td>0.553940</td>\n",
       "      <td>0.553280</td>\n",
       "      <td>0.69750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall@5</th>\n",
       "      <td>0.601830</td>\n",
       "      <td>0.614500</td>\n",
       "      <td>0.74778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall@10</th>\n",
       "      <td>0.650110</td>\n",
       "      <td>0.694110</td>\n",
       "      <td>0.80289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall@100</th>\n",
       "      <td>0.880330</td>\n",
       "      <td>0.873670</td>\n",
       "      <td>0.91867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall@1000</th>\n",
       "      <td>0.976670</td>\n",
       "      <td>0.969330</td>\n",
       "      <td>0.97667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P@1</th>\n",
       "      <td>0.436670</td>\n",
       "      <td>0.436670</td>\n",
       "      <td>0.58667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P@3</th>\n",
       "      <td>0.204440</td>\n",
       "      <td>0.201110</td>\n",
       "      <td>0.25556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P@5</th>\n",
       "      <td>0.135330</td>\n",
       "      <td>0.137330</td>\n",
       "      <td>0.16667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P@10</th>\n",
       "      <td>0.074330</td>\n",
       "      <td>0.079000</td>\n",
       "      <td>0.09067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P@100</th>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.009930</td>\n",
       "      <td>0.01043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P@1000</th>\n",
       "      <td>0.001110</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>0.00111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average Query Time (ms/it)</th>\n",
       "      <td>8.945380</td>\n",
       "      <td>8.428813</td>\n",
       "      <td>10.95000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total Query Time (s)</th>\n",
       "      <td>2.683614</td>\n",
       "      <td>2.528644</td>\n",
       "      <td>3.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total Document Embedding Time (s)</th>\n",
       "      <td>12.149655</td>\n",
       "      <td>10.005271</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Baseline SBERT  \\\n",
       "NDCG@1                                   0.436670   \n",
       "NDCG@3                                   0.504440   \n",
       "NDCG@5                                   0.523540   \n",
       "NDCG@10                                  0.540290   \n",
       "NDCG@100                                 0.589090   \n",
       "NDCG@1000                                0.601310   \n",
       "MAP@1                                    0.410280   \n",
       "MAP@3                                    0.477850   \n",
       "MAP@5                                    0.490840   \n",
       "MAP@10                                   0.499190   \n",
       "MAP@100                                  0.509100   \n",
       "MAP@1000                                 0.509550   \n",
       "Recall@1                                 0.410280   \n",
       "Recall@3                                 0.553940   \n",
       "Recall@5                                 0.601830   \n",
       "Recall@10                                0.650110   \n",
       "Recall@100                               0.880330   \n",
       "Recall@1000                              0.976670   \n",
       "P@1                                      0.436670   \n",
       "P@3                                      0.204440   \n",
       "P@5                                      0.135330   \n",
       "P@10                                     0.074330   \n",
       "P@100                                    0.010000   \n",
       "P@1000                                   0.001110   \n",
       "Average Query Time (ms/it)               8.945380   \n",
       "Total Query Time (s)                     2.683614   \n",
       "Total Document Embedding Time (s)       12.149655   \n",
       "\n",
       "                                   multi-qa-MiniLM-L6-cos-v1_ft  \\\n",
       "NDCG@1                                                 0.436670   \n",
       "NDCG@3                                                 0.506720   \n",
       "NDCG@5                                                 0.532380   \n",
       "NDCG@10                                                0.559350   \n",
       "NDCG@100                                               0.599260   \n",
       "NDCG@1000                                              0.611480   \n",
       "MAP@1                                                  0.416670   \n",
       "MAP@3                                                  0.482630   \n",
       "MAP@5                                                  0.499390   \n",
       "MAP@10                                                 0.511600   \n",
       "MAP@100                                                0.520600   \n",
       "MAP@1000                                               0.521070   \n",
       "Recall@1                                               0.416670   \n",
       "Recall@3                                               0.553280   \n",
       "Recall@5                                               0.614500   \n",
       "Recall@10                                              0.694110   \n",
       "Recall@100                                             0.873670   \n",
       "Recall@1000                                            0.969330   \n",
       "P@1                                                    0.436670   \n",
       "P@3                                                    0.201110   \n",
       "P@5                                                    0.137330   \n",
       "P@10                                                   0.079000   \n",
       "P@100                                                  0.009930   \n",
       "P@1000                                                 0.001100   \n",
       "Average Query Time (ms/it)                             8.428813   \n",
       "Total Query Time (s)                                   2.528644   \n",
       "Total Document Embedding Time (s)                     10.005271   \n",
       "\n",
       "                                   ColBERTv2 Baseline  \n",
       "NDCG@1                                        0.58667  \n",
       "NDCG@3                                        0.65424  \n",
       "NDCG@5                                        0.67280  \n",
       "NDCG@10                                       0.69195  \n",
       "NDCG@100                                      0.71650  \n",
       "NDCG@1000                                     0.72385  \n",
       "MAP@1                                         0.55717  \n",
       "MAP@3                                         0.62802  \n",
       "MAP@5                                         0.64135  \n",
       "MAP@10                                        0.65074  \n",
       "MAP@100                                       0.65578  \n",
       "MAP@1000                                      0.65607  \n",
       "Recall@1                                      0.55717  \n",
       "Recall@3                                      0.69750  \n",
       "Recall@5                                      0.74778  \n",
       "Recall@10                                     0.80289  \n",
       "Recall@100                                    0.91867  \n",
       "Recall@1000                                   0.97667  \n",
       "P@1                                           0.58667  \n",
       "P@3                                           0.25556  \n",
       "P@5                                           0.16667  \n",
       "P@10                                          0.09067  \n",
       "P@100                                         0.01043  \n",
       "P@1000                                        0.00111  \n",
       "Average Query Time (ms/it)                   10.95000  \n",
       "Total Query Time (s)                          3.00000  \n",
       "Total Document Embedding Time (s)                 NaN  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scifact_results.all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finetune ColBERTv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finetune_colbert(experiment_name: str, \n",
    "                     csv_file: str, # containing at least 'pid', 'passage' and 'question' columns\n",
    "                     mode: str = \"w\", # overwrite the training files (triples.jsonl, {queries,collection}.tsv) previously generated\n",
    "                     replace: bool = False, # if True, will throw error if training files already exists\n",
    "                     nranks: int = 1, # number of GPUs\n",
    "                     bsize: int = 32, # batch size\n",
    "                     lr: float = 1e-05, # learning rate\n",
    "                     doc_maxlen: int = 300, # max length for document\n",
    "                     dim: int = 128, # dimension\n",
    "                     accumsteps: int = 2, \n",
    "                     use_ib_negatives: bool = False, \n",
    "                     checkpoint: str = \"colbert-ir/colbertv2.0\", # finetuning from colbertv2.0\n",
    "                     root_path: str = \"../models/\", # we will save checkpoints to \"../models/{experiment_name}\"                     \n",
    "                    ) -> str:\n",
    "    \"\"\"\n",
    "    Finetunes colbert model from `checkpoint` with data from `csv_file`\n",
    "\n",
    "    Returns best `checkpoint_path`\n",
    "    \"\"\"\n",
    "    \n",
    "    beir_dataset = BEIRDataset()\n",
    "\n",
    "        \n",
    "    triples_path, queries_path, collection_path = beir_datasets.prepare_qg_for_colbert_training(csv_file, mode=mode, replace=replace)  \n",
    "    \n",
    "    with Run().context(RunConfig(nranks=nranks, experiment=experiment_name)):\n",
    "\n",
    "        config = ColBERTConfig(\n",
    "            checkpoint = checkpoint,\n",
    "            bsize=bsize,\n",
    "            experiment=experiment_name,\n",
    "            root=f\"{root_path}\",\n",
    "        )\n",
    "    # config = ColBERTConfig(checkpoint=checkpoint, bsize=bsize, lr=lr, warmup=None, nway=0, doc_maxlen=doc_maxlen, dim=dim, accumsteps=accumsteps, use_ib_negatives=use_ib_negatives)\n",
    "        \n",
    "    trainer = Trainer(\n",
    "        triples=triples_path,\n",
    "        queries=queries_path,\n",
    "        collection=collection_path,\n",
    "        config=config,\n",
    "    )\n",
    "\n",
    "    trainer.train(checkpoint=checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-01 12:46:41.433\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mzeroqaret.dataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1mDatasets will be saved in '/home/bengsoon/Projects/xcs224u_project/zeroqaret/datasets'\u001b[0m\n",
      "\u001b[32m2023-11-01 12:46:41.436\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprepare_qg_for_colbert_training\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mCreating ColBERT training files from ../datasets/scifact/qg/colbert_training...\u001b[0m\n",
      "Training files: : 5183it [00:00, 22564.51it/s]\n",
      "\u001b[32m2023-11-01 12:46:41.777\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprepare_qg_for_colbert_training\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mtriples.jsonl, queries,tsv and collection.tsv files created in ../datasets/scifact/qg/colbert_training.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#> Starting...\n",
      "nranks = 1 \t num_gpus = 1 \t device=0\n",
      "{\n",
      "    \"query_token_id\": \"[unused0]\",\n",
      "    \"doc_token_id\": \"[unused1]\",\n",
      "    \"query_token\": \"[Q]\",\n",
      "    \"doc_token\": \"[D]\",\n",
      "    \"ncells\": null,\n",
      "    \"centroid_score_threshold\": null,\n",
      "    \"ndocs\": null,\n",
      "    \"load_index_with_mmap\": false,\n",
      "    \"index_path\": null,\n",
      "    \"nbits\": 1,\n",
      "    \"kmeans_niters\": 4,\n",
      "    \"resume\": false,\n",
      "    \"similarity\": \"cosine\",\n",
      "    \"bsize\": 32,\n",
      "    \"accumsteps\": 1,\n",
      "    \"lr\": 3e-6,\n",
      "    \"maxsteps\": 500000,\n",
      "    \"save_every\": null,\n",
      "    \"warmup\": null,\n",
      "    \"warmup_bert\": null,\n",
      "    \"relu\": false,\n",
      "    \"nway\": 2,\n",
      "    \"use_ib_negatives\": false,\n",
      "    \"reranker\": false,\n",
      "    \"distillation_alpha\": 1.0,\n",
      "    \"ignore_scores\": false,\n",
      "    \"model_name\": null,\n",
      "    \"query_maxlen\": 32,\n",
      "    \"attend_to_mask_tokens\": false,\n",
      "    \"interaction\": \"colbert\",\n",
      "    \"dim\": 128,\n",
      "    \"doc_maxlen\": 220,\n",
      "    \"mask_punctuation\": true,\n",
      "    \"checkpoint\": \"colbert-ir\\/colbertv2.0\",\n",
      "    \"triples\": \"..\\/datasets\\/scifact\\/qg\\/colbert_training\\/triples.jsonl\",\n",
      "    \"collection\": \"..\\/datasets\\/scifact\\/qg\\/colbert_training\\/collection.tsv\",\n",
      "    \"queries\": \"..\\/datasets\\/scifact\\/qg\\/colbert_training\\/queries.tsv\",\n",
      "    \"index_name\": null,\n",
      "    \"overwrite\": false,\n",
      "    \"root\": \"\\/home\\/bengsoon\\/Projects\\/xcs224u_project\\/zeroqaret\\/nbs\\/experiments\",\n",
      "    \"experiment\": \"default\",\n",
      "    \"index_root\": null,\n",
      "    \"name\": \"2023-10\\/31\\/12.41.13\",\n",
      "    \"rank\": 0,\n",
      "    \"nranks\": 1,\n",
      "    \"amp\": true,\n",
      "    \"gpus\": 1\n",
      "}\n",
      "Using config.bsize = 32 (per process) and config.accumsteps = 1\n",
      "[Nov 01, 12:46:46] #> Loading the queries from ../datasets/scifact/qg/colbert_training/queries.tsv ...\n",
      "[Nov 01, 12:46:46] #> Got 5183 queries. All QIDs are unique.\n",
      "\n",
      "[Nov 01, 12:46:46] #> Loading collection...\n",
      "0M "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bengsoon/conda/envs/xcs224/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: .  Diffusion Tensor Magnetic Resonance Imaging of Human Newborn Cerebral White Matter - What is the purpose of applying a line scan diffusion-weighted magnetic resonance imaging (MRI) sequence with diffusion tensor analysis to measure the apparent diffusion coefficient, calculate relative anisotropy, and delineate three-dimensional fiber architecture in cerebral white matter in preterm and full-term infants?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1, 19241, 23435,  8060, 17011, 12126,  1997,  2529, 20662,\n",
      "        18439,  2317,  3043,  1011,  2054,  2003,  1996,  3800,  1997, 11243,\n",
      "         1037,  2240, 13594, 19241,  1011, 18215,  8060, 17011, 12126,  1006,\n",
      "        27011,   102])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1])\n",
      "\n",
      "#>>>    24.47 9.2 \t\t|\t\t 15.27\n",
      "[Nov 01, 12:46:50] 0 2.961572590720607e-06\n",
      "#>>>    24.31 9.66 \t\t|\t\t 14.649999999999999\n",
      "[Nov 01, 12:46:51] 1 2.9732318057540396e-06\n",
      "#>>>    23.96 10.07 \t\t|\t\t 13.89\n",
      "[Nov 01, 12:46:51] 2 3.02155431523488e-06\n",
      "#>>>    24.44 9.06 \t\t|\t\t 15.38\n",
      "[Nov 01, 12:46:51] 3 3.0959372574706706e-06\n",
      "#>>>    24.45 8.91 \t\t|\t\t 15.54\n",
      "[Nov 01, 12:46:52] 4 3.0978256490384307e-06\n",
      "#>>>    24.42 9.97 \t\t|\t\t 14.450000000000001\n",
      "[Nov 01, 12:46:52] 5 3.0969629887008958e-06\n",
      "#>>>    24.69 9.67 \t\t|\t\t 15.020000000000001\n",
      "[Nov 01, 12:46:52] 6 3.1014578317369156e-06\n",
      "#>>>    24.37 9.67 \t\t|\t\t 14.700000000000001\n",
      "[Nov 01, 12:46:53] 7 3.115575631548043e-06\n",
      "#>>>    24.21 9.7 \t\t|\t\t 14.510000000000002\n",
      "[Nov 01, 12:46:53] 8 3.71681378462065e-06\n",
      "#>>>    24.33 9.24 \t\t|\t\t 15.089999999999998\n",
      "[Nov 01, 12:46:53] 9 3.7181334127981766e-06\n",
      "#>>>    24.86 9.86 \t\t|\t\t 15.0\n",
      "[Nov 01, 12:46:54] 10 3.7166764978547356e-06\n",
      "#>>>    24.16 8.78 \t\t|\t\t 15.38\n",
      "[Nov 01, 12:46:54] 11 3.7148746089742327e-06\n",
      "#>>>    24.52 8.87 \t\t|\t\t 15.65\n",
      "[Nov 01, 12:46:54] 12 3.7131080464120653e-06\n",
      "#>>>    24.99 9.45 \t\t|\t\t 15.54\n",
      "[Nov 01, 12:46:55] 13 3.7138167751859096e-06\n",
      "#>>>    24.09 9.75 \t\t|\t\t 14.34\n",
      "[Nov 01, 12:46:55] 14 3.725729605338282e-06\n",
      "#>>>    23.64 8.41 \t\t|\t\t 15.23\n",
      "[Nov 01, 12:46:56] 15 3.726839138831301e-06\n",
      "#>>>    24.21 8.95 \t\t|\t\t 15.260000000000002\n",
      "[Nov 01, 12:46:56] 16 3.7255672362132047e-06\n",
      "#>>>    24.04 9.12 \t\t|\t\t 14.92\n",
      "[Nov 01, 12:46:56] 17 3.7304725854314134e-06\n",
      "#>>>    24.7 8.83 \t\t|\t\t 15.87\n",
      "[Nov 01, 12:46:57] 18 3.728906483544647e-06\n",
      "#>>>    24.19 8.64 \t\t|\t\t 15.55\n",
      "[Nov 01, 12:46:57] 19 3.739435359883927e-06\n",
      "#>>>    24.38 8.63 \t\t|\t\t 15.749999999999998\n",
      "[Nov 01, 12:46:57] 20 3.744390065412153e-06\n",
      "#>>>    23.85 8.87 \t\t|\t\t 14.980000000000002\n",
      "[Nov 01, 12:46:58] 21 3.7430335595979615e-06\n",
      "#>>>    24.34 8.8 \t\t|\t\t 15.54\n",
      "[Nov 01, 12:46:58] 22 3.7479548573281283e-06\n",
      "#>>>    23.93 9.07 \t\t|\t\t 14.86\n",
      "[Nov 01, 12:46:58] 23 3.8016050221502196e-06\n",
      "#>>>    24.44 9.18 \t\t|\t\t 15.260000000000002\n",
      "[Nov 01, 12:46:59] 24 3.8108470145195845e-06\n",
      "#>>>    23.72 9.36 \t\t|\t\t 14.36\n",
      "[Nov 01, 12:46:59] 25 3.819820721706127e-06\n",
      "#>>>    24.68 8.55 \t\t|\t\t 16.13\n",
      "[Nov 01, 12:46:59] 26 3.817036524866183e-06\n",
      "#>>>    24.35 8.51 \t\t|\t\t 15.840000000000002\n",
      "[Nov 01, 12:47:00] 27 3.8142886429053094e-06\n",
      "#>>>    24.77 8.74 \t\t|\t\t 16.03\n",
      "[Nov 01, 12:47:00] 28 3.813201231063211e-06\n",
      "#>>>    24.43 8.89 \t\t|\t\t 15.54\n",
      "[Nov 01, 12:47:00] 29 3.8104162067712922e-06\n",
      "#>>>    24.32 8.98 \t\t|\t\t 15.34\n",
      "[Nov 01, 12:47:01] 30 3.82321674540903e-06\n",
      "#>>>    23.89 9.04 \t\t|\t\t 14.850000000000001\n",
      "[Nov 01, 12:47:01] 31 3.834140850647653e-06\n",
      "#>>>    24.62 9.09 \t\t|\t\t 15.530000000000001\n",
      "[Nov 01, 12:47:01] 32 3.832515780796021e-06\n",
      "#>>>    24.2 8.94 \t\t|\t\t 15.26\n",
      "[Nov 01, 12:47:02] 33 3.8337681871377025e-06\n",
      "#>>>    24.67 8.56 \t\t|\t\t 16.11\n",
      "[Nov 01, 12:47:02] 34 3.833089661616817e-06\n",
      "#>>>    24.24 9.05 \t\t|\t\t 15.189999999999998\n",
      "[Nov 01, 12:47:02] 35 3.831413503669326e-06\n",
      "#>>>    23.92 8.83 \t\t|\t\t 15.090000000000002\n",
      "[Nov 01, 12:47:03] 36 3.844474215297219e-06\n",
      "#>>>    25.16 9.2 \t\t|\t\t 15.96\n",
      "[Nov 01, 12:47:03] 37 3.8424327726051175e-06\n",
      "#>>>    23.85 9.24 \t\t|\t\t 14.610000000000001\n",
      "[Nov 01, 12:47:04] 38 3.857839924343784e-06\n",
      "#>>>    24.62 8.82 \t\t|\t\t 15.8\n",
      "[Nov 01, 12:47:04] 39 3.856161364919499e-06\n",
      "#>>>    24.2 9.2 \t\t|\t\t 15.0\n",
      "[Nov 01, 12:47:04] 40 3.853866093936859e-06\n",
      "#>>>    24.41 8.76 \t\t|\t\t 15.65\n",
      "[Nov 01, 12:47:05] 41 3.851219217124777e-06\n",
      "#>>>    24.04 8.87 \t\t|\t\t 15.17\n",
      "[Nov 01, 12:47:05] 42 3.853164395452707e-06\n",
      "#>>>    24.24 9.16 \t\t|\t\t 15.079999999999998\n",
      "[Nov 01, 12:47:05] 43 5.59139923414132e-06\n",
      "#>>>    25.06 9.25 \t\t|\t\t 15.809999999999999\n",
      "[Nov 01, 12:47:06] 44 5.587063247278571e-06\n",
      "#>>>    24.54 9.2 \t\t|\t\t 15.34\n",
      "[Nov 01, 12:47:06] 45 5.5840577592764235e-06\n",
      "#>>>    24.87 8.45 \t\t|\t\t 16.42\n",
      "[Nov 01, 12:47:06] 46 5.5794608959429084e-06\n",
      "#>>>    23.99 8.84 \t\t|\t\t 15.149999999999999\n",
      "[Nov 01, 12:47:07] 47 5.579666691736671e-06\n",
      "#>>>    24.34 9.06 \t\t|\t\t 15.28\n",
      "[Nov 01, 12:47:07] 48 5.576445114022351e-06\n",
      "#>>>    23.79 8.63 \t\t|\t\t 15.159999999999998\n",
      "[Nov 01, 12:47:07] 49 5.5893565625208024e-06\n",
      "#>>>    24.83 8.66 \t\t|\t\t 16.169999999999998\n",
      "[Nov 01, 12:47:08] 50 5.5885018011808255e-06\n",
      "#>>>    23.74 8.69 \t\t|\t\t 15.049999999999999\n",
      "[Nov 01, 12:47:08] 51 5.614201565125033e-06\n",
      "#>>>    24.35 9.35 \t\t|\t\t 15.000000000000002\n",
      "[Nov 01, 12:47:08] 52 5.618741104291675e-06\n",
      "#>>>    24.4 8.78 \t\t|\t\t 15.62\n",
      "[Nov 01, 12:47:09] 53 5.614426209789624e-06\n",
      "#>>>    23.87 8.78 \t\t|\t\t 15.090000000000002\n",
      "[Nov 01, 12:47:09] 54 5.61915254643561e-06\n",
      "#>>>    24.43 8.29 \t\t|\t\t 16.14\n",
      "[Nov 01, 12:47:09] 55 5.6140810107672404e-06\n",
      "#>>>    24.3 8.96 \t\t|\t\t 15.34\n",
      "[Nov 01, 12:47:10] 56 5.649933579902067e-06\n",
      "#>>>    23.22 8.45 \t\t|\t\t 14.77\n",
      "[Nov 01, 12:47:10] 57 4.023582061526865e-05\n",
      "#>>>    24.54 8.4 \t\t|\t\t 16.14\n",
      "[Nov 01, 12:47:11] 58 4.019701901504739e-05\n",
      "#>>>    23.92 8.61 \t\t|\t\t 15.310000000000002\n",
      "[Nov 01, 12:47:11] 59 4.0159686714713285e-05\n",
      "#>>>    24.95 8.51 \t\t|\t\t 16.439999999999998\n",
      "[Nov 01, 12:47:11] 60 4.012052912688245e-05\n",
      "#>>>    24.29 8.63 \t\t|\t\t 15.659999999999998\n",
      "[Nov 01, 12:47:12] 61 4.008167146741508e-05\n",
      "#>>>    24.2 8.65 \t\t|\t\t 15.549999999999999\n",
      "[Nov 01, 12:47:12] 62 4.0057162100566795e-05\n",
      "#>>>    24.15 9.03 \t\t|\t\t 15.12\n",
      "[Nov 01, 12:47:12] 63 4.187254910155026e-05\n",
      "#>>>    24.38 8.98 \t\t|\t\t 15.399999999999999\n",
      "[Nov 01, 12:47:13] 64 4.183253918998093e-05\n",
      "#>>>    24.28 8.04 \t\t|\t\t 16.240000000000002\n",
      "[Nov 01, 12:47:13] 65 4.180716553448334e-05\n",
      "#>>>    24.4 8.34 \t\t|\t\t 16.06\n",
      "[Nov 01, 12:47:13] 66 4.176597676634259e-05\n",
      "#>>>    24.61 8.27 \t\t|\t\t 16.34\n",
      "[Nov 01, 12:47:14] 67 4.172460566994998e-05\n",
      "#>>>    24.19 8.73 \t\t|\t\t 15.46\n",
      "[Nov 01, 12:47:14] 68 4.1694305013497746e-05\n",
      "#>>>    24.84 8.37 \t\t|\t\t 16.47\n",
      "[Nov 01, 12:47:14] 69 4.165413805658824e-05\n",
      "#>>>    24.42 8.4 \t\t|\t\t 16.020000000000003\n",
      "[Nov 01, 12:47:15] 70 4.161405224642054e-05\n",
      "#>>>    24.3 9.22 \t\t|\t\t 15.08\n",
      "[Nov 01, 12:47:15] 71 4.1573786742668324e-05\n",
      "#>>>    24.36 8.16 \t\t|\t\t 16.2\n",
      "[Nov 01, 12:47:15] 72 4.153507020924671e-05\n",
      "#>>>    24.0 8.94 \t\t|\t\t 15.06\n",
      "[Nov 01, 12:47:16] 73 4.149474585474649e-05\n",
      "#>>>    24.71 9.07 \t\t|\t\t 15.64\n",
      "[Nov 01, 12:47:16] 74 4.1455840144267166e-05\n",
      "#>>>    24.05 8.5 \t\t|\t\t 15.55\n",
      "[Nov 01, 12:47:16] 75 4.143389174857202e-05\n",
      "#>>>    24.61 8.02 \t\t|\t\t 16.59\n",
      "[Nov 01, 12:47:17] 76 4.139522194719159e-05\n",
      "#>>>    23.78 9.07 \t\t|\t\t 14.71\n",
      "[Nov 01, 12:47:17] 77 4.13632884278196e-05\n",
      "#>>>    24.06 8.56 \t\t|\t\t 15.499999999999998\n",
      "[Nov 01, 12:47:17] 78 4.138059145848335e-05\n",
      "#>>>    24.06 8.6 \t\t|\t\t 15.459999999999999\n",
      "[Nov 01, 12:47:18] 79 4.1343390549516535e-05\n",
      "#>>>    24.48 8.09 \t\t|\t\t 16.39\n",
      "[Nov 01, 12:47:18] 80 4.1303324927286616e-05\n",
      "#>>>    23.84 8.97 \t\t|\t\t 14.87\n",
      "[Nov 01, 12:47:18] 81 4.135318694292308e-05\n",
      "#>>>    23.85 8.4 \t\t|\t\t 15.450000000000001\n",
      "[Nov 01, 12:47:19] 82 4.1417792035144196e-05\n",
      "#>>>    24.09 8.4 \t\t|\t\t 15.69\n",
      "[Nov 01, 12:47:19] 83 4.139359975989446e-05\n",
      "#>>>    24.0 8.66 \t\t|\t\t 15.34\n",
      "[Nov 01, 12:47:20] 84 4.136092267732082e-05\n",
      "#>>>    24.11 8.91 \t\t|\t\t 15.2\n",
      "[Nov 01, 12:47:20] 85 4.132207631127042e-05\n",
      "#>>>    24.6 8.59 \t\t|\t\t 16.01\n",
      "[Nov 01, 12:47:20] 86 4.131131726599137e-05\n",
      "#>>>    24.71 9.22 \t\t|\t\t 15.49\n",
      "[Nov 01, 12:47:21] 87 4.127186857602578e-05\n",
      "#>>>    24.23 8.62 \t\t|\t\t 15.610000000000001\n",
      "[Nov 01, 12:47:21] 88 4.1234742863692976e-05\n",
      "#>>>    24.1 8.58 \t\t|\t\t 15.520000000000001\n",
      "[Nov 01, 12:47:21] 89 4.120858988948101e-05\n",
      "#>>>    23.94 8.65 \t\t|\t\t 15.290000000000001\n",
      "[Nov 01, 12:47:22] 90 4.1169199232162227e-05\n",
      "#>>>    24.56 8.51 \t\t|\t\t 16.049999999999997\n",
      "[Nov 01, 12:47:22] 91 4.112885704419309e-05\n",
      "#>>>    23.78 8.25 \t\t|\t\t 15.530000000000001\n",
      "[Nov 01, 12:47:22] 92 4.108968392703894e-05\n",
      "#>>>    24.56 8.81 \t\t|\t\t 15.749999999999998\n",
      "[Nov 01, 12:47:23] 93 4.104995396474851e-05\n",
      "#>>>    24.37 8.54 \t\t|\t\t 15.830000000000002\n",
      "[Nov 01, 12:47:23] 94 4.1012159862890794e-05\n",
      "#>>>    24.21 7.54 \t\t|\t\t 16.67\n",
      "[Nov 01, 12:47:23] 95 4.0971475528289954e-05\n",
      "#>>>    24.21 8.81 \t\t|\t\t 15.4\n",
      "[Nov 01, 12:47:24] 96 4.0993418588863406e-05\n",
      "#>>>    24.05 8.87 \t\t|\t\t 15.180000000000001\n",
      "[Nov 01, 12:47:24] 97 4.095810981183912e-05\n",
      "#>>>    23.93 8.11 \t\t|\t\t 15.82\n",
      "[Nov 01, 12:47:24] 98 4.091824320787832e-05\n",
      "#>>>    24.18 8.27 \t\t|\t\t 15.91\n",
      "[Nov 01, 12:47:25] 99 4.087882251829644e-05\n",
      "#>>>    24.21 8.46 \t\t|\t\t 15.75\n",
      "[Nov 01, 12:47:25] 100 4.0838871290731876e-05\n",
      "#>>>    24.64 8.66 \t\t|\t\t 15.98\n",
      "[Nov 01, 12:47:25] 101 4.079919470523942e-05\n",
      "#>>>    24.62 8.71 \t\t|\t\t 15.91\n",
      "[Nov 01, 12:47:26] 102 4.077328979594808e-05\n",
      "#>>>    24.11 8.25 \t\t|\t\t 15.86\n",
      "[Nov 01, 12:47:26] 103 4.0739180806751506e-05\n",
      "#>>>    24.64 9.15 \t\t|\t\t 15.49\n",
      "[Nov 01, 12:47:26] 104 4.0699082375307657e-05\n",
      "#>>>    24.3 8.5 \t\t|\t\t 15.8\n",
      "[Nov 01, 12:47:27] 105 4.068666484741022e-05\n",
      "#>>>    24.38 9.15 \t\t|\t\t 15.229999999999999\n",
      "[Nov 01, 12:47:27] 106 4.065554414051568e-05\n",
      "#>>>    24.02 8.28 \t\t|\t\t 15.74\n",
      "[Nov 01, 12:47:27] 107 4.06169263053847e-05\n",
      "#>>>    24.28 8.58 \t\t|\t\t 15.700000000000001\n",
      "[Nov 01, 12:47:28] 108 4.0577676550728094e-05\n",
      "#>>>    24.61 8.55 \t\t|\t\t 16.06\n",
      "[Nov 01, 12:47:28] 109 4.053855917774255e-05\n",
      "#>>>    24.45 9.37 \t\t|\t\t 15.08\n",
      "[Nov 01, 12:47:29] 110 4.050537011610159e-05\n",
      "#>>>    24.36 7.68 \t\t|\t\t 16.68\n",
      "[Nov 01, 12:47:29] 111 4.0465214922904065e-05\n",
      "#>>>    24.34 8.18 \t\t|\t\t 16.16\n",
      "[Nov 01, 12:47:29] 112 4.04255729947497e-05\n",
      "#>>>    23.77 8.62 \t\t|\t\t 15.15\n",
      "[Nov 01, 12:47:30] 113 4.038712553612414e-05\n",
      "#>>>    24.46 8.24 \t\t|\t\t 16.22\n",
      "[Nov 01, 12:47:30] 114 4.034725995049083e-05\n",
      "#>>>    23.93 8.27 \t\t|\t\t 15.66\n",
      "[Nov 01, 12:47:30] 115 4.0308577881888705e-05\n",
      "#>>>    23.96 8.08 \t\t|\t\t 15.88\n",
      "[Nov 01, 12:47:31] 116 4.027063855089261e-05\n",
      "#>>>    24.55 8.15 \t\t|\t\t 16.4\n",
      "[Nov 01, 12:47:31] 117 4.02317537112378e-05\n",
      "#>>>    25.03 8.69 \t\t|\t\t 16.340000000000003\n",
      "[Nov 01, 12:47:31] 118 4.0192430921992924e-05\n",
      "#>>>    24.36 8.96 \t\t|\t\t 15.399999999999999\n",
      "[Nov 01, 12:47:32] 119 4.0159688750616225e-05\n",
      "#>>>    23.85 8.34 \t\t|\t\t 15.510000000000002\n",
      "[Nov 01, 12:47:32] 120 5.93481942200182e-05\n",
      "#>>>    23.97 8.82 \t\t|\t\t 15.149999999999999\n",
      "[Nov 01, 12:47:33] 121 7.746451690289724e-05\n",
      "#>>>    23.95 8.78 \t\t|\t\t 15.17\n",
      "[Nov 01, 12:47:33] 122 7.738912363193887e-05\n",
      "#>>>    24.6 8.11 \t\t|\t\t 16.490000000000002\n",
      "[Nov 01, 12:47:33] 123 7.731205860836395e-05\n",
      "#>>>    23.97 8.48 \t\t|\t\t 15.489999999999998\n",
      "[Nov 01, 12:47:34] 124 7.723695934104269e-05\n",
      "#>>>    25.07 8.37 \t\t|\t\t 16.700000000000003\n",
      "[Nov 01, 12:47:34] 125 7.716008373446268e-05\n",
      "#>>>    24.48 8.98 \t\t|\t\t 15.5\n",
      "[Nov 01, 12:47:34] 126 7.70865519575139e-05\n",
      "#>>>    24.35 9.04 \t\t|\t\t 15.310000000000002\n",
      "[Nov 01, 12:47:35] 127 7.714386148129311e-05\n",
      "#>>>    24.1 9.2 \t\t|\t\t 14.900000000000002\n",
      "[Nov 01, 12:47:35] 128 7.707139649393197e-05\n",
      "#>>>    23.94 8.97 \t\t|\t\t 14.97\n",
      "[Nov 01, 12:47:35] 129 7.71251063319129e-05\n",
      "#>>>    24.0 8.8 \t\t|\t\t 15.2\n",
      "[Nov 01, 12:47:36] 130 7.706174741105609e-05\n",
      "#>>>    24.24 8.68 \t\t|\t\t 15.559999999999999\n",
      "[Nov 01, 12:47:36] 131 7.698692454014968e-05\n",
      "#>>>    24.69 8.48 \t\t|\t\t 16.21\n",
      "[Nov 01, 12:47:36] 132 7.691114460023021e-05\n",
      "#>>>    24.53 8.7 \t\t|\t\t 15.830000000000002\n",
      "[Nov 01, 12:47:37] 133 7.686078168237229e-05\n",
      "#>>>    24.52 8.6 \t\t|\t\t 15.92\n",
      "[Nov 01, 12:47:37] 134 7.678912126588439e-05\n",
      "#>>>    24.44 8.4 \t\t|\t\t 16.04\n",
      "[Nov 01, 12:47:37] 135 7.671316660805375e-05\n",
      "#>>>    24.44 8.79 \t\t|\t\t 15.650000000000002\n",
      "[Nov 01, 12:47:38] 136 7.663782061843776e-05\n",
      "#>>>    24.41 8.24 \t\t|\t\t 16.17\n",
      "[Nov 01, 12:47:38] 137 7.656186079940309e-05\n",
      "#>>>    24.86 8.42 \t\t|\t\t 16.439999999999998\n",
      "[Nov 01, 12:47:39] 138 7.648745956059256e-05\n",
      "#>>>    24.1 8.25 \t\t|\t\t 15.850000000000001\n",
      "[Nov 01, 12:47:39] 139 7.641321469168559e-05\n",
      "#>>>    24.52 8.54 \t\t|\t\t 15.98\n",
      "[Nov 01, 12:47:39] 140 7.633864548193553e-05\n",
      "#>>>    23.98 8.59 \t\t|\t\t 15.39\n",
      "[Nov 01, 12:47:40] 141 7.653540970177515e-05\n",
      "#>>>    23.97 8.71 \t\t|\t\t 15.259999999999998\n",
      "[Nov 01, 12:47:40] 142 7.646180979331635e-05\n",
      "#>>>    24.27 8.42 \t\t|\t\t 15.85\n",
      "[Nov 01, 12:47:40] 143 7.638602598567522e-05\n",
      "#>>>    24.03 8.31 \t\t|\t\t 15.72\n",
      "[Nov 01, 12:47:41] 144 7.631046697299893e-05\n",
      "#>>>    23.99 8.07 \t\t|\t\t 15.919999999999998\n",
      "[Nov 01, 12:47:41] 145 7.630360915215616e-05\n",
      "#>>>    24.55 8.39 \t\t|\t\t 16.16\n",
      "[Nov 01, 12:47:41] 146 7.622821823344278e-05\n",
      "#>>>    23.91 8.83 \t\t|\t\t 15.08\n",
      "[Nov 01, 12:47:42] 147 7.615439653296063e-05\n",
      "#>>>    24.24 7.94 \t\t|\t\t 16.299999999999997\n",
      "[Nov 01, 12:47:42] 148 7.607965028445075e-05\n",
      "#>>>    24.91 7.77 \t\t|\t\t 17.14\n",
      "[Nov 01, 12:47:42] 149 7.600408844855145e-05\n",
      "#>>>    24.43 8.65 \t\t|\t\t 15.78\n",
      "[Nov 01, 12:47:43] 150 7.593545603066576e-05\n",
      "#>>>    24.45 9.06 \t\t|\t\t 15.389999999999999\n",
      "[Nov 01, 12:47:43] 151 7.587671091580342e-05\n",
      "#>>>    24.2 8.85 \t\t|\t\t 15.35\n",
      "[Nov 01, 12:47:43] 152 7.580251430035303e-05\n",
      "#>>>    24.51 8.32 \t\t|\t\t 16.19\n",
      "[Nov 01, 12:47:44] 153 7.572784799425042e-05\n",
      "#>>>    24.18 8.1 \t\t|\t\t 16.08\n",
      "[Nov 01, 12:47:44] 154 7.565336438548515e-05\n",
      "#>>>    24.5 7.9 \t\t|\t\t 16.6\n",
      "[Nov 01, 12:47:44] 155 7.557831079153032e-05\n",
      "#>>>    24.49 8.62 \t\t|\t\t 15.87\n",
      "[Nov 01, 12:47:45] 156 7.550700513950957e-05\n",
      "#>>>    24.49 8.24 \t\t|\t\t 16.25\n",
      "[Nov 01, 12:47:45] 157 7.543507055407056e-05\n",
      "#>>>    24.23 7.66 \t\t|\t\t 16.57\n",
      "[Nov 01, 12:47:45] 158 7.53606189565173e-05\n",
      "#>>>    24.03 7.78 \t\t|\t\t 16.25\n",
      "[Nov 01, 12:47:46] 159 7.528676334370006e-05\n",
      "#>>>    24.25 7.49 \t\t|\t\t 16.759999999999998\n",
      "[Nov 01, 12:47:46] 160 7.521225516057176e-05\n",
      "[Nov 01, 12:47:46] #> Done with all triples!\n",
      "#> Saving a checkpoint to /home/bengsoon/Projects/xcs224u_project/zeroqaret/nbs/experiments/default/none/2023-10/31/12.41.13/checkpoints/colbert ..\n",
      "#> Joined...\n"
     ]
    }
   ],
   "source": [
    "finetune_colbert(experiment_name=\"scifact_colbertv2_finetuned\",\n",
    "                          csv_file=\"../datasets/scifact/qg/scifact_qg_all.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6a2cb0165c145038fdef632f41ac5b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5183 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cee54e75d7604e9bbdf4507bb6bab077",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5183 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-01 12:48:32.289\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mzeroqaret.dataset\u001b[0m:\u001b[36mconvert_for_colbert\u001b[0m:\u001b[36m98\u001b[0m - \u001b[1mPreprocessing Corpus and Saving to /home/bengsoon/Projects/xcs224u_project/zeroqaret/datasets/scifact/colbert/scifact_collection.tsv ...\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 5183/5183 [00:00<00:00, 34289.09it/s]\n",
      "\u001b[32m2023-11-01 12:48:32.446\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mzeroqaret.dataset\u001b[0m:\u001b[36mconvert_for_colbert\u001b[0m:\u001b[36m105\u001b[0m - \u001b[1mPreprocessing Corpus and Saving to /home/bengsoon/Projects/xcs224u_project/zeroqaret/datasets/scifact/colbert/scifact_queries.tsv ...\u001b[0m\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [00:00<00:00, 303788.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Nov 01, 12:48:32] #> Loading collection...\n",
      "0M \n",
      "[Nov 01, 12:48:32] #> Loading the queries from /home/bengsoon/Projects/xcs224u_project/zeroqaret/datasets/scifact/colbert/scifact_queries.tsv ...\n",
      "[Nov 01, 12:48:32] #> Got 300 queries. All QIDs are unique.\n",
      "\n",
      "\n",
      "\n",
      "[Nov 01, 12:48:32] #> Creating directory /home/bengsoon/Projects/xcs224u_project/zeroqaret/nbs/experiments/scifact_colbertv2_ft/indexes/scifact.2bits \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#> Starting...\n",
      "nranks = 1 \t num_gpus = 1 \t device=0\n",
      "{\n",
      "    \"query_token_id\": \"[unused0]\",\n",
      "    \"doc_token_id\": \"[unused1]\",\n",
      "    \"query_token\": \"[Q]\",\n",
      "    \"doc_token\": \"[D]\",\n",
      "    \"ncells\": null,\n",
      "    \"centroid_score_threshold\": null,\n",
      "    \"ndocs\": null,\n",
      "    \"load_index_with_mmap\": false,\n",
      "    \"index_path\": null,\n",
      "    \"nbits\": 2,\n",
      "    \"kmeans_niters\": 4,\n",
      "    \"resume\": false,\n",
      "    \"similarity\": \"cosine\",\n",
      "    \"bsize\": 64,\n",
      "    \"accumsteps\": 1,\n",
      "    \"lr\": 3e-6,\n",
      "    \"maxsteps\": 500000,\n",
      "    \"save_every\": null,\n",
      "    \"warmup\": null,\n",
      "    \"warmup_bert\": null,\n",
      "    \"relu\": false,\n",
      "    \"nway\": 2,\n",
      "    \"use_ib_negatives\": false,\n",
      "    \"reranker\": false,\n",
      "    \"distillation_alpha\": 1.0,\n",
      "    \"ignore_scores\": false,\n",
      "    \"model_name\": null,\n",
      "    \"query_maxlen\": 32,\n",
      "    \"attend_to_mask_tokens\": false,\n",
      "    \"interaction\": \"colbert\",\n",
      "    \"dim\": 128,\n",
      "    \"doc_maxlen\": 300,\n",
      "    \"mask_punctuation\": true,\n",
      "    \"checkpoint\": \"\\/home\\/bengsoon\\/Projects\\/xcs224u_project\\/zeroqaret\\/nbs\\/experiments\\/default\\/none\\/2023-10\\/31\\/12.41.13\\/checkpoints\\/colbert\",\n",
      "    \"triples\": \"..\\/datasets\\/scifact\\/qg\\/colbert_training\\/triples.jsonl\",\n",
      "    \"collection\": \"\\/home\\/bengsoon\\/Projects\\/xcs224u_project\\/zeroqaret\\/datasets\\/scifact\\/colbert\\/scifact_collection.tsv\",\n",
      "    \"queries\": \"..\\/datasets\\/scifact\\/qg\\/colbert_training\\/queries.tsv\",\n",
      "    \"index_name\": \"scifact.2bits\",\n",
      "    \"overwrite\": false,\n",
      "    \"root\": \"\\/home\\/bengsoon\\/Projects\\/xcs224u_project\\/zeroqaret\\/nbs\\/experiments\",\n",
      "    \"experiment\": \"scifact_colbertv2_ft\",\n",
      "    \"index_root\": null,\n",
      "    \"name\": \"2023-10\\/31\\/12.41.13\",\n",
      "    \"rank\": 0,\n",
      "    \"nranks\": 1,\n",
      "    \"amp\": true,\n",
      "    \"gpus\": 1\n",
      "}\n",
      "[Nov 01, 12:48:37] [0] \t\t # of sampled PIDs = 5183 \t sampled_pids[:3] = [3412, 83, 2446]\n",
      "[Nov 01, 12:48:37] [0] \t\t #> Encoding 5183 passages..\n",
      "[Nov 01, 12:48:49] [0] \t\t avg_doclen_est = 237.2859344482422 \t len(local_sample) = 5,183\n",
      "[Nov 01, 12:48:49] [0] \t\t Creaing 16,384 partitions.\n",
      "[Nov 01, 12:48:49] [0] \t\t *Estimated* 1,229,852 embeddings.\n",
      "[Nov 01, 12:48:49] [0] \t\t #> Saving the indexing plan to /home/bengsoon/Projects/xcs224u_project/zeroqaret/nbs/experiments/scifact_colbertv2_ft/indexes/scifact.2bits/plan.json ..\n",
      "Clustering 1179853 points in 128D to 16384 clusters, redo 1 times, 4 iterations\n",
      "  Preprocessing in 0.09 s\n",
      "  Iteration 3 (3.03 s, search 2.62 s): objective=248223 imbalance=1.390 nsplit=0       \n",
      "[Nov 01, 12:48:53] Loading decompress_residuals_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n",
      "[Nov 01, 12:48:53] Loading packbits_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n",
      "[0.032, 0.034, 0.035, 0.03, 0.031, 0.033, 0.035, 0.031, 0.031, 0.032, 0.031, 0.032, 0.033, 0.033, 0.03, 0.033, 0.029, 0.031, 0.029, 0.031, 0.032, 0.032, 0.032, 0.032, 0.032, 0.032, 0.034, 0.032, 0.031, 0.035, 0.031, 0.036, 0.033, 0.031, 0.032, 0.03, 0.034, 0.033, 0.031, 0.039, 0.032, 0.032, 0.032, 0.032, 0.031, 0.031, 0.033, 0.036, 0.033, 0.031, 0.031, 0.033, 0.034, 0.032, 0.031, 0.032, 0.04, 0.033, 0.037, 0.033, 0.032, 0.035, 0.032, 0.035, 0.033, 0.032, 0.033, 0.034, 0.03, 0.032, 0.034, 0.03, 0.031, 0.033, 0.031, 0.036, 0.034, 0.033, 0.033, 0.035, 0.033, 0.032, 0.032, 0.034, 0.03, 0.033, 0.031, 0.034, 0.03, 0.035, 0.031, 0.035, 0.031, 0.033, 0.033, 0.034, 0.036, 0.032, 0.032, 0.031, 0.034, 0.036, 0.035, 0.031, 0.034, 0.031, 0.032, 0.031, 0.033, 0.031, 0.033, 0.033, 0.033, 0.029, 0.033, 0.031, 0.032, 0.033, 0.031, 0.032, 0.031, 0.032, 0.034, 0.035, 0.031, 0.035, 0.032, 0.031]\n",
      "[Nov 01, 12:48:54] #> Got bucket_cutoffs_quantiles = tensor([0.2500, 0.5000, 0.7500], device='cuda:0') and bucket_weights_quantiles = tensor([0.1250, 0.3750, 0.6250, 0.8750], device='cuda:0')\n",
      "[Nov 01, 12:48:54] #> Got bucket_cutoffs = tensor([-0.0259,  0.0000,  0.0260], device='cuda:0') and bucket_weights = tensor([-0.0458, -0.0120,  0.0121,  0.0460], device='cuda:0')\n",
      "[Nov 01, 12:48:54] avg_residual = 0.03253173828125\n",
      "[Nov 01, 12:48:54] [0] \t\t #> Encoding 5183 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Nov 01, 12:49:05] [0] \t\t #> Saving chunk 0: \t 5,183 passages and 1,229,853 embeddings. From #0 onward.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:12, 12.02s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00, 458.44it/s]\n",
      "  0%|          | 0/16384 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Nov 01, 12:49:06] [0] \t\t #> Checking all files were saved...\n",
      "[Nov 01, 12:49:06] [0] \t\t Found all files!\n",
      "[Nov 01, 12:49:06] [0] \t\t #> Building IVF...\n",
      "[Nov 01, 12:49:06] [0] \t\t #> Loading codes...\n",
      "[Nov 01, 12:49:06] [0] \t\t Sorting codes...\n",
      "[Nov 01, 12:49:06] [0] \t\t Getting unique codes...\n",
      "[Nov 01, 12:49:06] #> Optimizing IVF to store map from centroids to list of pids..\n",
      "[Nov 01, 12:49:06] #> Building the emb2pid mapping..\n",
      "[Nov 01, 12:49:06] len(emb2pid) = 1229853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16384/16384 [00:00<00:00, 97233.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Nov 01, 12:49:06] #> Saved optimized IVF to /home/bengsoon/Projects/xcs224u_project/zeroqaret/nbs/experiments/scifact_colbertv2_ft/indexes/scifact.2bits/ivf.pid.pt\n",
      "[Nov 01, 12:49:06] [0] \t\t #> Saving the indexing metadata to /home/bengsoon/Projects/xcs224u_project/zeroqaret/nbs/experiments/scifact_colbertv2_ft/indexes/scifact.2bits/metadata.json ..\n",
      "#> Joined...\n",
      "[Nov 01, 12:49:08] #> Loading codec...\n",
      "[Nov 01, 12:49:08] #> Loading IVF...\n",
      "[Nov 01, 12:49:08] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 2256.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Nov 01, 12:49:08] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 66.47it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset_name = \"scifact\"\n",
    "corpus, queries, qrels = beir_datasets.load_dataset(dataset_name)\n",
    "\n",
    "# The indices in BeIR datasets may not be monotic, \n",
    "### so we will need a dictionary with enumerated indices (which is used in ColBERT) as keys and BeIR index as values\n",
    "### collection_ids = {colbert_index: beir_index}\n",
    "collection_ids = {idx: str(val) for idx, val in enumerate(list(corpus))}\n",
    "\n",
    "# Load datasets for ColBERT\n",
    "collection_path, queries_path = beir_datasets.convert_for_colbert(dataset_name)\n",
    "collection, queries = Collection(path=collection_path), Queries(path=queries_path)\n",
    "\n",
    "# queries_ids = list(queries)\n",
    "# queries = list(queries.values())\n",
    "\n",
    "checkpoint = '/home/bengsoon/Projects/xcs224u_project/zeroqaret/nbs/experiments/default/none/2023-10/31/12.41.13/checkpoints/colbert'\n",
    "\n",
    "\n",
    "colbert_model_ft = ColBERTRetrievalSearch(checkpoint, \n",
    "                                   index_name, \n",
    "                                   experiment_name=\"scifact_colbertv2_ft\", \n",
    "                                   collection=collection, \n",
    "                                   collection_ids=collection_ids,\n",
    "                                   doc_maxlen=doc_maxlen, \n",
    "                                   nbits=nbits, \n",
    "                                   overwrite_param=\"reuse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "300it [00:03, 86.55it/s]\n"
     ]
    }
   ],
   "source": [
    "colbert_retriever_ft = EvaluateRetrieval(colbert_model_ft)\n",
    "results = colbert_retriever_ft.retrieve(collection, queries)\n",
    "colbert_retriever_ft.qrels = qrels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "scifact_results.collect(\"ColBERTv2_ft\", retriever, results, {'Average Query Time (ms/it)': 12.0, 'Total Query Time (s)': 3.0, 'Total Document Embedding Time (s)': None})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7318ba9e0934341804583a9664b00bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5183 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scifact_corpus, scifact_queries, _ = beir_datasets.load_dataset(\"scifact\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': '0-dimensional biomaterials show inductive properties.',\n",
       " '3': '1,000 genomes project enables mapping of genetic sequence variation consisting of rare variants with larger penetrance effects than common variants.',\n",
       " '5': '1/2000 in UK have abnormal PrP positivity.',\n",
       " '13': '5% of perinatal mortality is due to low birth weight.',\n",
       " '36': 'A deficiency of vitamin B12 increases blood levels of homocysteine.',\n",
       " '42': 'A high microerythrocyte count raises vulnerability to severe anemia in homozygous alpha (+)- thalassemia trait subjects.',\n",
       " '48': 'A total of 1,000 people in the UK are asymptomatic carriers of vCJD infection.',\n",
       " '49': 'ADAR1 binds to Dicer to cleave pre-miRNA.',\n",
       " '50': 'AIRE is expressed in some skin tumors.',\n",
       " '51': 'ALDH1 expression is associated with better breast cancer outcomes.',\n",
       " '53': 'ALDH1 expression is associated with poorer prognosis in breast cancer.',\n",
       " '54': 'AMP-activated protein kinase (AMPK) activation increases inflammation-related fibrosis in the lungs.',\n",
       " '56': 'APOE4 expression in iPSC-derived neurons increases AlphaBeta production and tau phosphorylation causing GABA neuron degeneration.',\n",
       " '57': 'APOE4 expression in iPSC-derived neurons increases AlphaBeta production and tau phosphorylation, delaying GABA neuron degeneration.',\n",
       " '70': 'Activation of PPM1D suppresses p53 function.',\n",
       " '72': 'Activator-inhibitor pairs are provided dorsally by Admpchordin.',\n",
       " '75': 'Active H. pylori urease has a polymeric structure that compromises two subunits, UreA and UreB.',\n",
       " '94': 'Albendazole is used to treat lymphatic filariasis.',\n",
       " '99': 'Alizarin forms hydrogen bonds with residues involved in PGAM1 substrate binding.',\n",
       " '100': 'All hematopoietic stem cells segregate their chromosomes randomly.',\n",
       " '113': 'Angiotensin converting enzyme inhibitors are associated with increased risk for functional renal insufficiency.',\n",
       " '115': 'Anthrax spores can be disposed of easily after they are dispersed.',\n",
       " '118': 'Antibiotic induced alterations in the gut microbiome reduce resistance against Clostridium difficile',\n",
       " '124': 'Antiretroviral therapy reduces rates of tuberculosis across a broad range of CD4 strata.',\n",
       " '127': 'Arginine 90 in p150n is important for interaction with EB1.',\n",
       " '128': 'Arterioles have a larger lumen diameter than venules.',\n",
       " '129': 'Articles published in open access format are less likely to be cited than traditional journals.',\n",
       " '130': 'Articles published in open access format are more likely to be cited than traditional journals.',\n",
       " '132': 'Aspirin inhibits the production of PGE2.',\n",
       " '133': 'Assembly of invadopodia is triggered by focal generation of phosphatidylinositol-3,4-biphosphate and the activation of the nonreceptor tyrosine kinase Src.',\n",
       " '137': 'Asymptomatic visual impairment screening in elderly populations does not lead to improved vision.',\n",
       " '141': 'Auditory entrainment is strengthened when people see congruent visual and auditory information.',\n",
       " '142': 'Autologous transplantation of mesenchymal stem cells causes a higher rate of opportunistic infections than induction therapy with anti-interleukin-2 receptor antibodies.',\n",
       " '143': 'Autologous transplantation of mesenchymal stem cells causes fewer opportunistic infections than induction therapy with anti-interleukin-2 receptor antibodies.',\n",
       " '146': 'Autologous transplantation of mesenchymal stem cells has lower rates of rejection than induction therapy with anti-interleukin-2 receptor antibodies.',\n",
       " '148': 'Autophagy declines in aged organisms.',\n",
       " '163': 'Bariatric surgery has a positive impact on mental health.',\n",
       " '171': 'Basophils counteract disease development in patients with systemic lupus erythematosus (SLE).',\n",
       " '179': 'Birth-weight is positively associated with breast cancer.',\n",
       " '180': 'Blocking the interaction between TDP-43 and respiratory complex I proteins ND3 and ND6 leads to increased TDP-43-induced neuronal loss.',\n",
       " '183': 'Bone marrow cells contribute to adult macrophage compartments.',\n",
       " '185': 'Breast cancer development is determined exclusively by genetic factors.',\n",
       " '198': 'CCL19 is absent within dLNs.',\n",
       " '208': 'CHEK2 is not associated with breast cancer.',\n",
       " '212': 'CR is associated with higher methylation age.',\n",
       " '213': 'CRP is not predictive of postoperative mortality following Coronary Artery Bypass Graft (CABG) surgery.',\n",
       " '216': 'CX3CR1 on the Th2 cells impairs T cell survival',\n",
       " '217': 'CX3CR1 on the Th2 cells promotes T cell survival',\n",
       " '218': 'CX3CR1 on the Th2 cells promotes airway inflammation.',\n",
       " '219': 'CX3CR1 on the Th2 cells suppresses airway inflammation.',\n",
       " '230': 'Carriers of the alcohol aldehyde dehydrogenase deficiency mutation drink less that non-carries.',\n",
       " '232': 'Cataract and trachoma are the primary cause of blindness in Southern Sudan.',\n",
       " '233': 'Cell autonomous sex determination in somatic cells does not occur in Galliformes.',\n",
       " '236': 'Cell autonomous sex determination in somatic cells occurs in Passeriformes.',\n",
       " '237': 'Cells lacking clpC have a defect in sporulation efficiency in Bacillus subtilis.',\n",
       " '238': 'Cells undergoing methionine restriction may activate miRNAs.',\n",
       " '239': 'Cellular aging closely links to an older appearance.',\n",
       " '248': 'Chenodeosycholic acid treatment increases whole-body energy expenditure.',\n",
       " '249': 'Chenodeosycholic acid treatment reduces whole-body energy expenditure.',\n",
       " '261': 'Chronic aerobic exercise alters endothelial function, improving vasodilating mechanisms mediated by NO.',\n",
       " '268': 'Cold exposure increases BAT recruitment.',\n",
       " '269': 'Cold exposure reduces BAT recruitment.',\n",
       " '274': 'Combination nicotine replacement therapies with varenicline or bupropion lead to significantly higher long-term abstinence rates at 52 weeks than varenicline monotherapy.',\n",
       " '275': 'Combining phosphatidylinositide 3-kinase and MEK 1/2 inhibitors is effective at treating KRAS mutant tumors.',\n",
       " '279': \"Commelina yellow mottle virus' (ComYMV) genome consists of 7489 baise pairs.\",\n",
       " '294': 'Crossover hot spots are not found within gene promoters in Saccharomyces cerevisiae.',\n",
       " '295': 'Crosstalk between dendritic cells (DCs) and innate lymphoid cells (ILCs) is important in the regulation of intestinal homeostasis.',\n",
       " '298': 'Cytochrome c is released from the mitochondrial intermembrane space to cytosol during apoptosis.',\n",
       " '300': 'Cytosolic proteins bind to iron-responsive elements on mRNAs coding for DMT1. Cytosolic proteins bind to iron-responsive elements on mRNAs coding for proteins involved in iron uptake.',\n",
       " '303': 'DMRT1 is a sex-determining gene that is epigenetically regulated by the MHM region.',\n",
       " '312': 'De novo assembly of sequence data has more specific contigs than unassembled sequence data.',\n",
       " '314': 'Deamination of cytidine to uridine on the minus strand of viral DNA results in catastrophic G-to-A mutations in the viral genome.',\n",
       " '324': 'Deleting Raptor reduces G-CSF levels.',\n",
       " '327': 'Deletion of αvβ8 does not result in a spontaneous inflammatory phenotype.',\n",
       " '338': 'Dexamethasone decreases risk of postoperative bleeding.',\n",
       " '343': 'Diabetic patients with acute coronary syndrome experience increased short-term and long-term risk for bleeding events.',\n",
       " '350': 'Discrimination between the initiator and elongation tRNAs depends on the translation initiation factor IF3.',\n",
       " '354': 'Downregulation and mislocalization of Scribble prevents cell transformation and mammary tumorigenesis.',\n",
       " '362': 'During the primary early antibody response activated B cells migrate toward the inner-and outer paracortical areas where oxysterol accumulation is generated by stromal cells.',\n",
       " '380': 'Enhanced early production of inflammatory chemokines improves viral control in the lung.',\n",
       " '384': 'Epidemiological disease burden from noncommunicable diseases is more prevalent in low economic settings.',\n",
       " '385': 'Epigenetic modulating agents (EMAs) modulate antitumor immune response in a cancer model system.',\n",
       " '386': 'Errors in peripheral IV drug administration are most common during bolus administration and multiple-step medicine preparations.',\n",
       " '388': 'Ethanol stress decreases the expression of IBP in bacteria.',\n",
       " '399': 'Exposure to fine particulate air pollution is relate to anxiety prevalence.',\n",
       " '410': 'Febrile seizures increase the threshold for development of epilepsy.',\n",
       " '411': 'Febrile seizures reduce the threshold for development of epilepsy.',\n",
       " '415': 'Female carriers of the Apolipoprotein E4 (APOE4) allele have increased risk for dementia.',\n",
       " '421': 'Flexible molecules experience greater steric hindrance in the tumor microenviroment than rigid molecules.',\n",
       " '431': 'FoxO3a activation in neuronal death is mediated by reactive oxygen species (ROS).',\n",
       " '436': 'Free histones are degraded by a Rad53-dependent mechanism once DNA has been replicated.',\n",
       " '437': 'Functional consequences of genomic alterations due to Myelodysplastic syndrome (MDS) are poorly understood due to the lack of an animal model.',\n",
       " '439': 'Fz/PCP-dependent Pk localizes to the anterior membrane of neuroectoderm cells during zebrafish neuralation',\n",
       " '440': 'Fz/PCP-dependent Pk localizes to the anterior membrane of notochord cells during zebrafish neuralation.',\n",
       " '443': 'GATA-3 is important for hematopoietic stem cell (HSC) function.',\n",
       " '452': 'Gene expression does not vary appreciably across genetically identical cells.',\n",
       " '475': 'Glycolysis is one of the primary glycometabolic pathways in cells.',\n",
       " '478': 'Golli-deficient T-cells prefer to differentiate into an anergic phenotype in the adaptive immune response when there are increased levels of Ca2+ in the cytosol.',\n",
       " '491': 'HNF4A mutations can cause diabetes in mutant carriers by the age of 14 years',\n",
       " '501': 'Headaches are not correlated with cognitive impairment.',\n",
       " '502': 'Healthcare delivery efficiency in crowded delivery centers is impaired by improving structural, logistical, and interpersonal elements.',\n",
       " '507': 'Helminths interfere with immune system control of macrophages activated by IL-4 favor Mycobacterium tuberculosis replication.',\n",
       " '508': 'Hematopoietic Stem Cell purification reaches purity rate of up to 50%.',\n",
       " '513': 'High cardiopulmonary fitness causes increased mortality rate.',\n",
       " '514': 'High dietary calcium intakes are unnecessary for prevention of secondary hyperparathyroidism in subjects with 25(OH)D levels above 75 nmol/liter.',\n",
       " '516': 'High levels of CRP reduces the risk of exacerbations in chronic obstructive pulmonary disease (COPD).',\n",
       " '517': 'High levels of copeptin decrease risk of diabetes.',\n",
       " '521': 'High-sensitivity cardiac troponin T (HSCT-T) dosage may not be diagnostic if the onset of symptoms occurs less than 3 hours before acute myocardial injury (AMI).',\n",
       " '525': 'Histone demethylase recruitment and a transient decrease in histone methylation is necessary for ligand-dependent induction of transcription by nuclear receptors.',\n",
       " '527': 'Homozygous deletion of murine Sbds gene from osterix-expressing mesenchymal stem and progenitor cells (MPCs) prevents oxidative stress.',\n",
       " '528': 'Human T-lymphotropic virus type-I-associated myelopathy / tropical spastic paraparesis (HAM/TSP) patients produce Immunoglobulin G (IgG) antibodies which cross-react with an immunodominant epitope in Tax.',\n",
       " '532': 'Hyperfibrinogenemia decreases rates of femoropopliteal bypass thrombosis.',\n",
       " '533': 'Hyperfibrinogenemia increases rates of femoropopliteal bypass thrombosis.',\n",
       " '535': 'Hypertension is frequently observed in type 1 diabetes patients.',\n",
       " '536': 'Hypocretin neurones induce panicprone state in rats.',\n",
       " '539': 'Hypoglycemia increases the risk of dementia.',\n",
       " '540': 'Hypothalamic glutamate neurotransmission is crucial to energy balance.',\n",
       " '544': 'IFIT1 restricts viral replication by sequestrating mis-capped viral RNAs.',\n",
       " '549': 'IRG1 has antiviral effects against neurotropic viruses.',\n",
       " '551': 'ITAM phosphorylation prevents the transfer of the T cell receptor (TCR) signal from the echo-domain to the cytoplasmic tail of the T cell receptor (TCR).',\n",
       " '552': 'IgA plasma cells that are specific for transglutaminase 2 accumulate in the duodenal mucosa on commencement of a gluten-free diet.',\n",
       " '554': 'Immune complex triggered cell death leads to extracellular release of neutrophil protein HMGB1.',\n",
       " '560': 'Immune responses result in the development of inflammatory Th17 cells and anti-inflammatory iTregs.',\n",
       " '569': 'In adult tissue, most T cells are memory T cells.',\n",
       " '575': 'In domesticated populations of Saccharomyces cerevisiae, whole chromosome aneuploidy is very uncommon.',\n",
       " '577': 'In mice, P. chabaudi parasites are able to proliferate faster early in infection when inoculated at lower numbers than when inoculated at high numbers.',\n",
       " '578': 'In mouse models, the loss of CSF1R facilitates MOZ-TIF2-induced leuekmogenesis.',\n",
       " '587': 'In transgenic mice harboring green florescent protein under the control of the Sox2 promoter, less than ten percent of the cells with green florescent colocalize with cell proliferation markers.',\n",
       " '589': 'In young and middle-aged adults, current or remote uses of ADHD medications do not increase the risk of serious cardiovascular events.',\n",
       " '593': 'Incidence of heart failure decreased by 10% in women since 1979.',\n",
       " '597': 'Incidence rates of cervical cancer have decreased.',\n",
       " '598': 'Incidence rates of cervical cancer have increased due to nationwide screening programs based primarily on cytology to detect uterine cervical cancer.',\n",
       " '613': 'Increased microtubule acetylation repairs LRRK2 Roc-COR domain mutation induced locomotor deficits.',\n",
       " '619': 'Increased vessel density along with a reduction in fibrosis decreases the efficacy of chemotherapy treatments.',\n",
       " '623': 'Individuals with low serum vitamin D concentrations have increased risk of multiple sclerosis.',\n",
       " '628': 'Infection of human T-cell lymphotropic virus type 1 is most frequent in individuals of African origin.',\n",
       " '636': 'Inositol lipid 3-phosphatase PTEN converts Ptdlns(3,4)P 2 into phosphatidylinositol 4-phosphate.',\n",
       " '637': 'Input from  mental and physical health care professionals is effective at decreasing homelessness.',\n",
       " '641': 'Insomnia can be effectively treated with cognitive behavioral therapy.',\n",
       " '644': 'Insulin increases risk of severe kidney failure.',\n",
       " '649': 'Integrating classroom-based collaborative learning with Web-based collaborative learning leads to subpar class performance',\n",
       " '659': 'Ivermectin is used to treat lymphatic filariasis.',\n",
       " '660': 'Ivermectin is used to treat onchocerciasis.',\n",
       " '674': 'LDL cholesterol has no involvement in the development of cardiovascular disease.',\n",
       " '684': 'Lack of clpC does not affect sporulation efficiency in Bacillus subtilis cells.',\n",
       " '690': 'Less than 10% of the gabonese children with Schimmelpenning-Feuerstein-Mims syndrome (SFM) had a plasma lactate of more than 5mmol/L.',\n",
       " '691': 'Leukemia associated Rho guanine nucleotide-exchange factor represses RhoA in response to SRC activation.',\n",
       " '692': 'Leuko-increased blood increases infectious complications in red blood cell transfusion.',\n",
       " '693': 'Leuko-reduced blood reduces infectious complications in red blood cell transfusion.',\n",
       " '700': 'Localization of PIN1 in the Arabidopsis embryo does not require VPS9a',\n",
       " '702': 'Localization of PIN1 in the roots of Arabidopsis does not require VPS9a',\n",
       " '715': 'Low expression of miR7a does represses target genes and exerts a biological function in ovaries.',\n",
       " '716': 'Low expression of miR7a exerts a biological function in testis.',\n",
       " '718': 'Low nucleosome occupancy correlates with low methylation levels across species.',\n",
       " '721': 'Lupus-prone mice infected with curliproducing bacteria have higher autoantibody titers compared to controls.',\n",
       " '723': 'Ly49Q directs the organization of neutrophil migration to inflammation sites by regulating membrane raft functions.',\n",
       " '727': 'Ly6C hi monocytes have a lower inflammatory capacity compared to their Ly6C lo counterparts.',\n",
       " '728': 'Ly6C hi monocytes have a lower inflammatory capacity than Ly6C lo monocytes.',\n",
       " '729': 'Lymphadenopathy is observed in knockin mouse lacking the SHP-2 MAPK pathway.',\n",
       " '742': 'Macrolides have no protective effect against myocardial infarction.',\n",
       " '743': 'Macrolides protect against myocardial infarction.',\n",
       " '744': \"Macropinocytosis contributes to a cell's supply of amino acids via the intracellular uptake of protein.\",\n",
       " '756': 'Many proteins in human cells can be post-translationally modified at lysine residues via acetylation.',\n",
       " '759': 'Mathematical models predict that using Artemisinin-based combination therapy over nongametocytocidal drugs have a dramatic impact in reducing malaria transmission.',\n",
       " '768': 'Mercaptopurine is anabolized into the inactive methylmercaptopurine by thiopurine methyltrasnferase (TPMT).',\n",
       " '770': 'Metastatic colorectal cancer treated with a single agent fluoropyrimidines resulted in reduced efficacy and lower quality of life when compared with oxaliplatin-based chemotherapy in elderly patients.',\n",
       " '775': 'Mice defective for deoxyribonucleic acid (DNA) polymerase I (polI) reveal increased sensitivity to ionizing radiation (IR).',\n",
       " '781': 'Mice that lack Interferon-γ or its receptor exhibit high resistance to experimental autoimmune myocarditis.',\n",
       " '783': 'Mice without IFN-γ or its receptor are resistant to EAM induced with α-MyHC/CFA.',\n",
       " '784': 'MicroRNA is involved in the regulation of Neural Stem Cell (NSC) differentiation and proliferation dynamic homeostasis',\n",
       " '785': 'Microarray results from culture-amplified mixtures of serotypes correlate poorly with microarray results from uncultured mixtures.',\n",
       " '793': 'Mitochondria are uninvolved in apoptosis.',\n",
       " '800': 'Modifying the epigenome in the brain affects the normal human aging process by affecting certain genes related to neurogenesis.',\n",
       " '805': 'Monoclonal antibody targeting of N-cadherin inhibits metastasis.',\n",
       " '808': 'Most termination events in Okazaki fragments are sequence specific.',\n",
       " '811': 'Mutant mice lacking SVCT2 have greatly increased ascorbic acid levels in both brain and adrenals.',\n",
       " '814': 'Mutations in G-Beta protein GNB2 are present in many cancers, resulting in loss of interaction with G-alpha subunits and concomitant activation of AKT pathway.',\n",
       " '820': 'N-terminal cleavage increases success identifying transcription start sites.',\n",
       " '821': 'N-terminal cleavage reduces success identifying transcription start sites.',\n",
       " '823': 'N348I mutations cause resistance to zidovudine (AZT).',\n",
       " '830': 'NF2 (Merlin) causes phosphorylation and subsequent cytoplasmic sequestration of YAP in Drosophila by activating LATS1/2 kinases.',\n",
       " '831': 'NF2 (Merlin) prevents phosphorylation and subsequent cytoplasmic sequestration of YAP in Drosophila.',\n",
       " '832': 'NFAT4 activation requires IP3R-mediated Ca2+ mobilization.',\n",
       " '834': 'NOX2-independent pathways can generate peroxynitrite by reacting with nitrogen intermediates.',\n",
       " '837': 'NR5A2 is important in development of endometrial tissues.',\n",
       " '839': 'Nanoparticles can be targeted against specific cell types by incorporating aptamers into lipid nanoparticles.',\n",
       " '845': 'Neutrophil extracellular traps (NETs) are released by ANCA-stimulated neutrophils.',\n",
       " '847': 'New drugs for tuberculosis often do not penetrate the necrotic portion of a tuberculosis lesion in high concentrations.',\n",
       " '852': 'Non-invasive ventilation use should be decreased if there is inadequate response to conventional treatment.',\n",
       " '859': 'Normal expression of RUNX1 has tumor-promoting effects.',\n",
       " '870': 'Obesity decreases life quality.',\n",
       " '873': 'Obesity is determined solely by environmental factors.',\n",
       " '879': 'Occupancy of ribosomes by IncRNAs do not make functional peptides.',\n",
       " '880': 'Occupancy of ribosomes by IncRNAs mirror 5 0-UTRs',\n",
       " '882': 'Omnivores produce less trimethylamine N-oxide from dietary I-carnitine than vegetarians.',\n",
       " '887': 'Only a minority of cells survive development after differentiation into stress-resistant spores.',\n",
       " '903': 'PD-1 triggering on monocytes reduces IL-10 production by monocytes.',\n",
       " '904': 'PDPN promotes efficient motility along stromal surfaces by activating the C-type lectin receptor to rearrange the actin cytoskeleton in dendritic cells.',\n",
       " '907': 'PGE 2 promotes intestinal tumor growth by altering the expression of tumor suppressing and DNA repair genes.',\n",
       " '911': 'PKG-la plays an essential role in expression of pain hypersensitivity in PGK-la knockout mice.',\n",
       " '913': 'PPAR-RXRs are inhibited by PPAR ligands.',\n",
       " '914': 'PPAR-RXRs can be activated by PPAR ligands.',\n",
       " '921': 'Participating in six months of physical activity improves cognitive functioning.',\n",
       " '922': 'Patients in stable partnerships have a faster progression from HIV to AIDS.',\n",
       " '936': 'Peroxynitrite is required for nitration of TCR/CD8.',\n",
       " '956': 'Pleiotropic coupling of GLP-1R to intracellular effectors promotes distinct profiles of cellular signaling.',\n",
       " '957': 'Podocytes are motile and migrate in the presence of injury.',\n",
       " '960': 'Polymeal nutrition reduces cardiovascular mortality.',\n",
       " '967': 'Pretreatment with the Arp2/3 inhibitor CK-666 affects lamelliopodia formation.',\n",
       " '971': 'Primary cervical cancer screening with HPV detection has higher longitudinal sensitivity than conventional cytology to detect cervical intraepithelial neoplasia grade 2.',\n",
       " '975': 'Primary pro-inflammatory cytokines induce secondary pro- and anti-inflammatory mediators.',\n",
       " '982': 'Proteins synthesized at the growth cone are ubiquitinated at a higher rate than proteins from the cell body.',\n",
       " '985': 'Pseudogene PTENP1 regulates the expression of PTEN by functioning as an miRNA decoy.',\n",
       " '993': 'Pyridostatin destabilizes the G - quadruplex in the telomeric region.',\n",
       " '1012': 'Radioiodine treatment of non-toxic multinodular goitre reduces thyroid volume.',\n",
       " '1014': 'Rapamycin decreases the concentration of triacylglycerols in fruit flies.',\n",
       " '1019': 'Rapid phosphotransfer rates govern fidelity in two component systems',\n",
       " '1020': 'Rapid up-regulation and higher basal expression of interferon-induced genes increase survival of granule cell neurons that are infected by West Nile virus.',\n",
       " '1021': 'Rapid up-regulation and higher basal expression of interferon-induced genes reduce survival of granule cell neurons that are infected by West Nile virus.',\n",
       " '1024': 'Recurrent mutations occur frequently within CTCF anchor sites adjacent to oncogenes.',\n",
       " '1029': 'Reduced responsiveness to interleukin-2 in regulatory T cells is associated with greater resistance to autoimmune diseases such as Type 1 Diabetes.',\n",
       " '1041': 'Replacement of histone H2A with H2A.Z slows gene activation in yeasts by stabilizing +1 nucleosomes.',\n",
       " '1049': 'Ribosomopathies have a low degree of cell and tissue specific pathology.',\n",
       " '1062': 'S-nitrosylated GAPDH physiologically transnitrosylates histone deacetylases.',\n",
       " '1086': 'Sildenafil improves erectile function in men who experience sexual dysfunction as a result of the use of SSRI antidepressants.',\n",
       " '1088': 'Silencing of Bcl2 is important for the maintenance and progression of tumors.',\n",
       " '1089': 'Smc5/6 engagment drives the activation of SUMO E3 ligase Mms21 by ATP-dependent remolding.',\n",
       " '1099': 'Statins decrease blood cholesterol.',\n",
       " '1100': 'Statins increase blood cholesterol.',\n",
       " '1104': 'Stroke patients with prior use of direct oral anticoagulants have a lower risk of in-hospital mortality than stroke patients with prior use of warfarin.',\n",
       " '1107': 'Subcutaneous fat depots undergo extensive browning processes after cold exposure.',\n",
       " '1110': 'Suboptimal nutrition is not predictive of chronic disease',\n",
       " '1121': 'Synaptic activity enhances local release of brain derived neurotrophic factor from postsynaptic dendrites.',\n",
       " '1130': 'T regulatory cells (tTregs) lacking αvβ8 are more adept at suppressing pathogenic T-cell responses during active inflammation.',\n",
       " '1132': 'TCR/CD3 microdomains are a required to induce the immunologic synapse to activate T cells.',\n",
       " '1137': 'TNFAIP3 is a tumor suppressor in glioblastoma.',\n",
       " '1140': 'Taking 400mg of α-tocopheryl acetate helps to prevent prostate cancer.',\n",
       " '1144': 'Taxation of sugar-sweetened beverages had no effect on the incidence rate of type II diabetes in India.',\n",
       " '1146': 'Teaching hospitals do not provide better care than non-teaching hospitals.',\n",
       " '1150': 'Tetraspanin-3 is a causative factor in the development of acute myelogenous leukemia',\n",
       " '1163': 'The DdrB protein from Deinococcus radiodurans is an alternative SSB.',\n",
       " '1175': 'The PPR MDA5 has two N-terminal CARD domains.',\n",
       " '1179': 'The PRR MDA5 has a central DExD/H RNA helices domain.',\n",
       " '1180': 'The PRR MDA5 is a sensor of RNA virus infection.',\n",
       " '1185': 'The US health care system can save up to $750 million if 7% of patients waiting for kidney transplants participate in the optimized national kidney paired donation program.',\n",
       " '1187': 'The YAP1 and TEAD complex tanslocates into the nucleus where it interacts with transcription factors and DNA-binding proteins that modulate target gene transcription.',\n",
       " '1191': 'The amount of publicly available DNA data doubles every 10 years.',\n",
       " '1194': \"The arm density of TatAd complexes is due to structural rearrangements within Class1 TatAd complexes such as the 'charge zipper mechanism'.\",\n",
       " '1196': 'The availability of safe places to study is effective at decreasing homelessness.',\n",
       " '1197': 'The availability of safe places to study is not effective at decreasing homelessness.',\n",
       " '1199': 'The benefits of colchicine were achieved with effective widespread use of secondary prevention strategies such as high-dose statins.',\n",
       " '1200': 'The binding orientation of the ML-SA1 activator at hTRPML2 is different from the binding orientation of the ML-SA1 activator at hTRPML1.',\n",
       " '1202': 'The center of the granuloma in an immune cell induces a pro-inflammatory immune response.',\n",
       " '1204': 'The combination of H3K4me3 and H3K79me2 is found in quiescent hair follicle stem cells.',\n",
       " '1207': 'The composition of myosin-II isoform switches from the polarizable B isoform to the more homogenous A isoform during hematopoietic differentiation.',\n",
       " '1213': 'The deregulated and prolonged activation of monocytes has deleterious effects in inflammatory diseases.',\n",
       " '1216': 'The extracellular domain of TMEM27 is cleaved in human beta cells.',\n",
       " '1221': 'The genomic aberrations found in matasteses are very similar to those found in the primary tumor.',\n",
       " '1225': 'The locus rs647161 is associated with colorectal carcinoma.',\n",
       " '1226': 'The loss of the TET protein functions may have dire biological consequences, such as myeloid cancers.',\n",
       " '1232': \"The minor G allele of FOXO3 is related to more severe symptoms of Crohn's Disease.\",\n",
       " '1241': 'The myocardial lineage develops from cardiac progenitors of mesodermal origin.',\n",
       " '1245': 'The one-child policy has been successful in lowering population growth.',\n",
       " '1259': \"The relationship between a breast cancer patient's capacity to metabolize tamoxifen and treatment outcome is dependent on the patient's genetic make-up.\",\n",
       " '1262': 'The repair of Cas9-induced double strand breaks in human DNA is error-prone.',\n",
       " '1266': 'The risk of breast cancer among parous women increases with placental weight of pregnancies, and this association is strongest for premenopausal breast cancer.',\n",
       " '1270': 'The risk of male prisoners harming themselves is ten times that of female prisoners.',\n",
       " '1271': 'The severity of cardiac involvement in amyloidosis can be described by the degree of transmurality of late gadolinium enhancement in MRI.',\n",
       " '1272': 'The single flash-evoked ERG b-wave is generated by activity of ON-bipolar cells.',\n",
       " '1273': 'The sliding activity of kinesin-8 protein Kip3 promotes bipolar spindle assembly.',\n",
       " '1274': 'The tip of the inner tube of the toxic type VI secretion system (T6SS) antibacterial effector in Escherichia coli (E. coli) carries toxic effector proteins.',\n",
       " '1278': 'The treatment of cancer patients with co-IR blockade does not cause any adverse autoimmune events.',\n",
       " '1279': 'The treatment of cancer patients with co-IR blockade precipitates adverse autoimmune events.',\n",
       " '1280': 'The ureABIEFGH gene cluster encodes urease maturation proteins : UreD/UreH, UreE, UreF, and UreG.',\n",
       " '1281': 'The ureABIEFGH gene cluster is induced by nickel (II) ion.',\n",
       " '1282': 'Therapeutic use of the drug Dapsone to treat pyoderma gangrenous is based on anecdotal evidence.',\n",
       " '1290': 'There is an inverse relationship between hip fractures and statin use.',\n",
       " '1292': 'There is no association between HNF4A mutations and diabetes risks.',\n",
       " '1298': 'Thigh-length graduated compression stockings (GCS) did not reduce deep vein thrombosis in patients admitted to hospital who are immobile because of acute stroke.',\n",
       " '1303': 'Tirasemtiv has no effect on fast-twitch muscle.',\n",
       " '1316': 'Transferred UCB T cells acquire a memory-like phenotype in recipients.',\n",
       " '1319': 'Transplanted human glial cells can differentiate within the host animal.',\n",
       " '1320': \"Transplanted human glial progenitor cells are incapable of forming a neural network with host animals' neurons.\",\n",
       " '1332': 'Tumor necrosis factor alpha (TNF-α) and interleukin-1 (IL-1) are pro-inflammatory cytokines that inhibit IL-6 and IL-10.',\n",
       " '1335': 'UCB T cells maintain high TCR diversity after transplantation.',\n",
       " '1336': 'UCB T cells reduce TCR diversity after transplantation.',\n",
       " '1337': 'Ubiquitin ligase UBC13 generates a K63-linked polyubiquitin moiety at PCNA K164.',\n",
       " '1339': 'Ultrasound guidance significantly raises the number of traumatic procedures when attempting needle insertion.',\n",
       " '1344': 'Up-regulation of the p53 pathway and related molecular events casues cancer resistance and results in a significantly shortened lifespan marked by senescent cells and accelerated organismal aging.',\n",
       " '1352': 'Upregulation of mosGCTL-1 is induced upon infection with West Nile virus.',\n",
       " '1359': 'Varenicline monotherapy is more effective after 12 weeks of treatment compared to combination nicotine replacement therapies with varenicline or bupropion.',\n",
       " '1362': 'Venules have a larger lumen diameter than arterioles.',\n",
       " '1363': 'Venules have a thinner or absent smooth layer compared to arterioles.',\n",
       " '1368': 'Vitamin D deficiency effects the term of delivery.',\n",
       " '1370': 'Vitamin D deficiency is unrelated to birth weight.',\n",
       " '1379': 'Women with a higher birth weight are more likely to develop breast cancer later in life.',\n",
       " '1382': 'aPKCz causes tumour enhancement by affecting glutamine metabolism.',\n",
       " '1385': 'cSMAC formation enhances weak ligand signalling.',\n",
       " '1389': 'mTORC2 regulates intracellular cysteine levels through xCT inhibition.',\n",
       " '1395': 'p16INK4A accumulation is  linked to an abnormal wound response caused by the microinvasive step of advanced Oral Potentially Malignant Lesions (OPMLs).'}"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scifact_queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Baseline SBERT</th>\n",
       "      <th>multi-qa-MiniLM-L6-cos-v1_ft</th>\n",
       "      <th>ColBERTv2 Baseline</th>\n",
       "      <th>ColBERTv2_ft</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NDCG@1</th>\n",
       "      <td>0.436670</td>\n",
       "      <td>0.436670</td>\n",
       "      <td>0.58667</td>\n",
       "      <td>0.58000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NDCG@3</th>\n",
       "      <td>0.504440</td>\n",
       "      <td>0.506720</td>\n",
       "      <td>0.65424</td>\n",
       "      <td>0.64954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NDCG@5</th>\n",
       "      <td>0.523540</td>\n",
       "      <td>0.532380</td>\n",
       "      <td>0.67280</td>\n",
       "      <td>0.66908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NDCG@10</th>\n",
       "      <td>0.540290</td>\n",
       "      <td>0.559350</td>\n",
       "      <td>0.69195</td>\n",
       "      <td>0.69023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NDCG@100</th>\n",
       "      <td>0.589090</td>\n",
       "      <td>0.599260</td>\n",
       "      <td>0.71650</td>\n",
       "      <td>0.71544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NDCG@1000</th>\n",
       "      <td>0.601310</td>\n",
       "      <td>0.611480</td>\n",
       "      <td>0.72385</td>\n",
       "      <td>0.72109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAP@1</th>\n",
       "      <td>0.410280</td>\n",
       "      <td>0.416670</td>\n",
       "      <td>0.55717</td>\n",
       "      <td>0.55050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAP@3</th>\n",
       "      <td>0.477850</td>\n",
       "      <td>0.482630</td>\n",
       "      <td>0.62802</td>\n",
       "      <td>0.62367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAP@5</th>\n",
       "      <td>0.490840</td>\n",
       "      <td>0.499390</td>\n",
       "      <td>0.64135</td>\n",
       "      <td>0.63747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAP@10</th>\n",
       "      <td>0.499190</td>\n",
       "      <td>0.511600</td>\n",
       "      <td>0.65074</td>\n",
       "      <td>0.64757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAP@100</th>\n",
       "      <td>0.509100</td>\n",
       "      <td>0.520600</td>\n",
       "      <td>0.65578</td>\n",
       "      <td>0.65284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAP@1000</th>\n",
       "      <td>0.509550</td>\n",
       "      <td>0.521070</td>\n",
       "      <td>0.65607</td>\n",
       "      <td>0.65306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall@1</th>\n",
       "      <td>0.410280</td>\n",
       "      <td>0.416670</td>\n",
       "      <td>0.55717</td>\n",
       "      <td>0.55050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall@3</th>\n",
       "      <td>0.553940</td>\n",
       "      <td>0.553280</td>\n",
       "      <td>0.69750</td>\n",
       "      <td>0.69306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall@5</th>\n",
       "      <td>0.601830</td>\n",
       "      <td>0.614500</td>\n",
       "      <td>0.74778</td>\n",
       "      <td>0.74444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall@10</th>\n",
       "      <td>0.650110</td>\n",
       "      <td>0.694110</td>\n",
       "      <td>0.80289</td>\n",
       "      <td>0.80622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall@100</th>\n",
       "      <td>0.880330</td>\n",
       "      <td>0.873670</td>\n",
       "      <td>0.91867</td>\n",
       "      <td>0.92533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall@1000</th>\n",
       "      <td>0.976670</td>\n",
       "      <td>0.969330</td>\n",
       "      <td>0.97667</td>\n",
       "      <td>0.97000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P@1</th>\n",
       "      <td>0.436670</td>\n",
       "      <td>0.436670</td>\n",
       "      <td>0.58667</td>\n",
       "      <td>0.58000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P@3</th>\n",
       "      <td>0.204440</td>\n",
       "      <td>0.201110</td>\n",
       "      <td>0.25556</td>\n",
       "      <td>0.25333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P@5</th>\n",
       "      <td>0.135330</td>\n",
       "      <td>0.137330</td>\n",
       "      <td>0.16667</td>\n",
       "      <td>0.16600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P@10</th>\n",
       "      <td>0.074330</td>\n",
       "      <td>0.079000</td>\n",
       "      <td>0.09067</td>\n",
       "      <td>0.09100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P@100</th>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.009930</td>\n",
       "      <td>0.01043</td>\n",
       "      <td>0.01050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P@1000</th>\n",
       "      <td>0.001110</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>0.00111</td>\n",
       "      <td>0.00110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average Query Time (ms/it)</th>\n",
       "      <td>8.945380</td>\n",
       "      <td>8.428813</td>\n",
       "      <td>10.95000</td>\n",
       "      <td>12.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total Query Time (s)</th>\n",
       "      <td>2.683614</td>\n",
       "      <td>2.528644</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>3.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total Document Embedding Time (s)</th>\n",
       "      <td>12.149655</td>\n",
       "      <td>10.005271</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Baseline SBERT  \\\n",
       "NDCG@1                                   0.436670   \n",
       "NDCG@3                                   0.504440   \n",
       "NDCG@5                                   0.523540   \n",
       "NDCG@10                                  0.540290   \n",
       "NDCG@100                                 0.589090   \n",
       "NDCG@1000                                0.601310   \n",
       "MAP@1                                    0.410280   \n",
       "MAP@3                                    0.477850   \n",
       "MAP@5                                    0.490840   \n",
       "MAP@10                                   0.499190   \n",
       "MAP@100                                  0.509100   \n",
       "MAP@1000                                 0.509550   \n",
       "Recall@1                                 0.410280   \n",
       "Recall@3                                 0.553940   \n",
       "Recall@5                                 0.601830   \n",
       "Recall@10                                0.650110   \n",
       "Recall@100                               0.880330   \n",
       "Recall@1000                              0.976670   \n",
       "P@1                                      0.436670   \n",
       "P@3                                      0.204440   \n",
       "P@5                                      0.135330   \n",
       "P@10                                     0.074330   \n",
       "P@100                                    0.010000   \n",
       "P@1000                                   0.001110   \n",
       "Average Query Time (ms/it)               8.945380   \n",
       "Total Query Time (s)                     2.683614   \n",
       "Total Document Embedding Time (s)       12.149655   \n",
       "\n",
       "                                   multi-qa-MiniLM-L6-cos-v1_ft  \\\n",
       "NDCG@1                                                 0.436670   \n",
       "NDCG@3                                                 0.506720   \n",
       "NDCG@5                                                 0.532380   \n",
       "NDCG@10                                                0.559350   \n",
       "NDCG@100                                               0.599260   \n",
       "NDCG@1000                                              0.611480   \n",
       "MAP@1                                                  0.416670   \n",
       "MAP@3                                                  0.482630   \n",
       "MAP@5                                                  0.499390   \n",
       "MAP@10                                                 0.511600   \n",
       "MAP@100                                                0.520600   \n",
       "MAP@1000                                               0.521070   \n",
       "Recall@1                                               0.416670   \n",
       "Recall@3                                               0.553280   \n",
       "Recall@5                                               0.614500   \n",
       "Recall@10                                              0.694110   \n",
       "Recall@100                                             0.873670   \n",
       "Recall@1000                                            0.969330   \n",
       "P@1                                                    0.436670   \n",
       "P@3                                                    0.201110   \n",
       "P@5                                                    0.137330   \n",
       "P@10                                                   0.079000   \n",
       "P@100                                                  0.009930   \n",
       "P@1000                                                 0.001100   \n",
       "Average Query Time (ms/it)                             8.428813   \n",
       "Total Query Time (s)                                   2.528644   \n",
       "Total Document Embedding Time (s)                     10.005271   \n",
       "\n",
       "                                   ColBERTv2 Baseline  ColBERTv2_ft  \n",
       "NDCG@1                                        0.58667       0.58000  \n",
       "NDCG@3                                        0.65424       0.64954  \n",
       "NDCG@5                                        0.67280       0.66908  \n",
       "NDCG@10                                       0.69195       0.69023  \n",
       "NDCG@100                                      0.71650       0.71544  \n",
       "NDCG@1000                                     0.72385       0.72109  \n",
       "MAP@1                                         0.55717       0.55050  \n",
       "MAP@3                                         0.62802       0.62367  \n",
       "MAP@5                                         0.64135       0.63747  \n",
       "MAP@10                                        0.65074       0.64757  \n",
       "MAP@100                                       0.65578       0.65284  \n",
       "MAP@1000                                      0.65607       0.65306  \n",
       "Recall@1                                      0.55717       0.55050  \n",
       "Recall@3                                      0.69750       0.69306  \n",
       "Recall@5                                      0.74778       0.74444  \n",
       "Recall@10                                     0.80289       0.80622  \n",
       "Recall@100                                    0.91867       0.92533  \n",
       "Recall@1000                                   0.97667       0.97000  \n",
       "P@1                                           0.58667       0.58000  \n",
       "P@3                                           0.25556       0.25333  \n",
       "P@5                                           0.16667       0.16600  \n",
       "P@10                                          0.09067       0.09100  \n",
       "P@100                                         0.01043       0.01050  \n",
       "P@1000                                        0.00111       0.00110  \n",
       "Average Query Time (ms/it)                   10.95000      12.00000  \n",
       "Total Query Time (s)                          3.00000       3.00000  \n",
       "Total Document Embedding Time (s)                 NaN           NaN  "
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scifact_results.all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-01 18:14:39.462\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msave_as_csv\u001b[0m:\u001b[36m8\u001b[0m - \u001b[1mTable 'all' saved as '../datasets/scifact/20231101_scifact_results.csv'.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "scifact_results.save_as_csv(f\"../datasets/{dataset_name}/20231101_{dataset_name}_results.csv\", \"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `nfcorpus`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'nfcorpus'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-01 14:51:22.852\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m12\u001b[0m - \u001b[1mResultsCollector object initialized.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "nfcorpus_results = ResultsCollector(dataset_name=dataset_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SBERT Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model = \"multi-qa-MiniLM-L6-cos-v1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-01 14:52:03.040\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mzeroqaret.dataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1mDatasets will be saved in '/home/bengsoon/Projects/xcs224u_project/zeroqaret/datasets'\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "baseline_retriever = SBERTEval(model_path = baseline_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-01 14:52:05.558\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mbeir_retrieval\u001b[0m:\u001b[36m13\u001b[0m - \u001b[1m\n",
      "   \n",
      "****************************************************************************************************   \n",
      "******                                                                                        ******   \n",
      "                                     Evaluation for 'nfcorpus'                                     *   \n",
      "******                                                                                        ******   \n",
      "****************************************************************************************************\n",
      "\u001b[0m\n",
      "\u001b[32m2023-11-01 14:52:05.560\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mzeroqaret.dataset\u001b[0m:\u001b[36mload_dataset\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1mDownloading dataset 'nfcorpus'...\u001b[0m\n",
      "\u001b[32m2023-11-01 14:52:05.561\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mzeroqaret.dataset\u001b[0m:\u001b[36mload_dataset\u001b[0m:\u001b[36m65\u001b[0m - \u001b[1mSaved on '/home/bengsoon/Projects/xcs224u_project/zeroqaret/datasets/nfcorpus'\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7d7fc1138df466d95d48a2e63b281ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3633 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-01 14:52:05.639\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mbeir_retrieval\u001b[0m:\u001b[36m21\u001b[0m - \u001b[1mPre-computing Document Embeddings for 'nfcorpus' dataset...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73aed3e18818443e9dbaedd41d9d1964",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/29 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-01 14:52:13.047\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mbeir_retrieval\u001b[0m:\u001b[36m32\u001b[0m - \u001b[1mNumber of documents: 3633, Dim: 384\u001b[0m\n",
      "\u001b[32m2023-11-01 14:52:13.049\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mbeir_retrieval\u001b[0m:\u001b[36m33\u001b[0m - \u001b[1mIndex size (in MB): 5.58MB\u001b[0m\n",
      "\u001b[32m2023-11-01 14:52:13.049\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mbeir_retrieval\u001b[0m:\u001b[36m34\u001b[0m - \u001b[1mTime taken for pre-computing corpus embedding: 7.40 s\u001b[0m\n",
      "\u001b[32m2023-11-01 14:52:13.050\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mbeir_retrieval\u001b[0m:\u001b[36m35\u001b[0m - \u001b[1mPre-computing of Document Embeddings done.\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[32m2023-11-01 14:52:13.051\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mbeir_retrieval\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mStarting query benchmark evaluation ...\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 323/323 [00:02<00:00, 123.01it/s]\n",
      "\u001b[32m2023-11-01 14:52:15.681\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mbeir_retrieval\u001b[0m:\u001b[36m60\u001b[0m - \u001b[1mAverage time taken: 7.60 ms / query\u001b[0m\n",
      "\u001b[32m2023-11-01 14:52:15.682\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mbeir_retrieval\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mTotal time taken: 2454.02 s\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "results, results_time = baseline_retriever.beir_retrieval(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "nfcorpus_results.collect(experiment_name=\"Baseline SBERT\", retriever=baseline_retriever, results=results, results_time=results_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Baseline SBERT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NDCG@1</th>\n",
       "      <td>0.388540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NDCG@3</th>\n",
       "      <td>0.348380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NDCG@5</th>\n",
       "      <td>0.324230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NDCG@10</th>\n",
       "      <td>0.296740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NDCG@100</th>\n",
       "      <td>0.266600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NDCG@1000</th>\n",
       "      <td>0.350880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAP@1</th>\n",
       "      <td>0.050240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAP@3</th>\n",
       "      <td>0.079710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAP@5</th>\n",
       "      <td>0.091500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAP@10</th>\n",
       "      <td>0.105330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAP@100</th>\n",
       "      <td>0.129700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAP@1000</th>\n",
       "      <td>0.141630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall@1</th>\n",
       "      <td>0.050240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall@3</th>\n",
       "      <td>0.090630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall@5</th>\n",
       "      <td>0.108830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall@10</th>\n",
       "      <td>0.139960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall@100</th>\n",
       "      <td>0.266360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall@1000</th>\n",
       "      <td>0.578160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P@1</th>\n",
       "      <td>0.402480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P@3</th>\n",
       "      <td>0.324050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P@5</th>\n",
       "      <td>0.277400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P@10</th>\n",
       "      <td>0.218270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P@100</th>\n",
       "      <td>0.067800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P@1000</th>\n",
       "      <td>0.018890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average Query Time (ms/it)</th>\n",
       "      <td>7.597585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total Query Time (s)</th>\n",
       "      <td>2.454020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total Document Embedding Time (s)</th>\n",
       "      <td>7.395014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Baseline SBERT\n",
       "NDCG@1                                   0.388540\n",
       "NDCG@3                                   0.348380\n",
       "NDCG@5                                   0.324230\n",
       "NDCG@10                                  0.296740\n",
       "NDCG@100                                 0.266600\n",
       "NDCG@1000                                0.350880\n",
       "MAP@1                                    0.050240\n",
       "MAP@3                                    0.079710\n",
       "MAP@5                                    0.091500\n",
       "MAP@10                                   0.105330\n",
       "MAP@100                                  0.129700\n",
       "MAP@1000                                 0.141630\n",
       "Recall@1                                 0.050240\n",
       "Recall@3                                 0.090630\n",
       "Recall@5                                 0.108830\n",
       "Recall@10                                0.139960\n",
       "Recall@100                               0.266360\n",
       "Recall@1000                              0.578160\n",
       "P@1                                      0.402480\n",
       "P@3                                      0.324050\n",
       "P@5                                      0.277400\n",
       "P@10                                     0.218270\n",
       "P@100                                    0.067800\n",
       "P@1000                                   0.018890\n",
       "Average Query Time (ms/it)               7.597585\n",
       "Total Query Time (s)                     2.454020\n",
       "Total Document Embedding Time (s)        7.395014"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nfcorpus_results.all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Finetuning SBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, InputExample, losses, models, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_nfcorpus_df = pd.read_csv(\"../datasets/nfcorpus/qg/nfcorpus_qg_all.csv\", index_col=0)\n",
    "pids = gen_nfcorpus_df[\"pid\"].tolist()\n",
    "passages = gen_nfcorpus_df[\"passage\"].tolist()\n",
    "titles = gen_nfcorpus_df[\"title\"].tolist()\n",
    "questions = gen_nfcorpus_df[\"question\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-01 14:53:58.663\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mzeroqaret.dataset\u001b[0m:\u001b[36mload_dataset\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1mDownloading dataset 'nfcorpus'...\u001b[0m\n",
      "\u001b[32m2023-11-01 14:53:58.666\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mzeroqaret.dataset\u001b[0m:\u001b[36mload_dataset\u001b[0m:\u001b[36m65\u001b[0m - \u001b[1mSaved on '/home/bengsoon/Projects/xcs224u_project/zeroqaret/datasets/nfcorpus'\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "053a0680f70841c1929e543ba4791fdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3633 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "corpus, queries, qrels = beir_datasets.load_dataset(dataset_name)\n",
    "corpus_ids, query_ids = list(corpus), list(queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_examples = []\n",
    "for p, t, q in zip(passages, titles, questions):\n",
    "    anchor = str(t) + \" - \" + str(q)\n",
    "    train_examples.append(InputExample(texts=[anchor, p]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PLAIN-2': 'Do Cholesterol Statin Drugs Cause Breast Cancer?',\n",
       " 'PLAIN-12': 'Exploiting Autophagy to Live Longer',\n",
       " 'PLAIN-23': 'How to Reduce Exposure to Alkylphenols Through Your Diet',\n",
       " 'PLAIN-33': 'What’s Driving America’s Obesity Problem?',\n",
       " 'PLAIN-44': 'Who Should be Careful About Curcumin?',\n",
       " 'PLAIN-56': 'Foods for Glaucoma',\n",
       " 'PLAIN-68': 'What is Actually in Chicken Nuggets?',\n",
       " 'PLAIN-78': 'What Do Meat Purge and Cola Have in Common?',\n",
       " 'PLAIN-91': 'Chronic Headaches and Pork Parasites',\n",
       " 'PLAIN-102': 'Stopping Heart Disease in Childhood',\n",
       " 'PLAIN-112': 'Food Dyes and ADHD',\n",
       " 'PLAIN-123': 'How Citrus Might Help Keep Your Hands Warm',\n",
       " 'PLAIN-133': 'Starving Tumors of Their Blood Supply',\n",
       " 'PLAIN-143': 'Are Dental X-Rays Safe?',\n",
       " 'PLAIN-153': 'How Should I Take Probiotics?',\n",
       " 'PLAIN-165': 'Breast Cancer & Alcohol: How Much is Safe?',\n",
       " 'PLAIN-175': 'Diet and Cellulite',\n",
       " 'PLAIN-186': 'Best Treatment for Constipation',\n",
       " 'PLAIN-196': 'Should We Avoid Titanium Dioxide?',\n",
       " 'PLAIN-207': 'Avoiding Cooked Meat Carcinogens',\n",
       " 'PLAIN-217': 'Plant-Based Diets for Psoriasis',\n",
       " 'PLAIN-227': 'Increasing Muscle Strength with Fenugreek',\n",
       " 'PLAIN-238': 'How Chemically Contaminated Are We?',\n",
       " 'PLAIN-248': 'Treating an Enlarged Prostate With Diet',\n",
       " 'PLAIN-259': 'Optimal Phytosterol Dose and Source',\n",
       " 'PLAIN-270': 'Is Caffeinated Tea Really Dehydrating?',\n",
       " 'PLAIN-280': 'Mercury Testing Recommended Before Pregnancy',\n",
       " 'PLAIN-291': 'Stool Size and Breast Cancer Risk',\n",
       " 'PLAIN-307': 'Vitamin D: Shedding some light on the new recommendations',\n",
       " 'PLAIN-320': 'Breast Cancer and Diet',\n",
       " 'PLAIN-332': 'Can antioxidant-rich spices counteract the effects of a high-fat meal?',\n",
       " 'PLAIN-344': 'Dioxins Stored in Our Own Fat May Increase Diabetes Risk',\n",
       " 'PLAIN-358': \"Didn't another study show carnitine was good for the heart?\",\n",
       " 'PLAIN-371': 'Any update on the scary in vitro avocado data?',\n",
       " 'PLAIN-383': \"What do you think of Dr. Jenkins' take on paleolithic diets?\",\n",
       " 'PLAIN-395': 'What about pepper plus turmeric in V8 juice?',\n",
       " 'PLAIN-407': 'Is annatto food coloring safe?',\n",
       " 'PLAIN-418': 'Fresh fruit versus frozen--which is better?',\n",
       " 'PLAIN-430': 'Are krill oil supplements better than fish oil capsules?',\n",
       " 'PLAIN-441': 'Is apple cider vinegar good for you?',\n",
       " 'PLAIN-457': 'How can you believe in any scientific study?',\n",
       " 'PLAIN-468': 'Is vitamin D3 (cholecalciferol) preferable to D2 (ergocalciferol)?',\n",
       " 'PLAIN-478': 'accidents',\n",
       " 'PLAIN-488': 'adenovirus 36',\n",
       " 'PLAIN-499': 'African-American',\n",
       " 'PLAIN-510': 'airport scanners',\n",
       " 'PLAIN-520': 'Alli',\n",
       " 'PLAIN-531': 'alternative medicine',\n",
       " 'PLAIN-541': 'American Dental Association',\n",
       " 'PLAIN-551': 'amnesia',\n",
       " 'PLAIN-561': 'aneurysm',\n",
       " 'PLAIN-571': 'anisakis',\n",
       " 'PLAIN-583': 'antinutrients',\n",
       " 'PLAIN-593': 'apnea',\n",
       " 'PLAIN-603': 'Arkansas',\n",
       " 'PLAIN-613': 'ascorbic acid',\n",
       " 'PLAIN-623': 'Atkins diet',\n",
       " 'PLAIN-634': 'avocados',\n",
       " 'PLAIN-645': 'bagels',\n",
       " 'PLAIN-660': 'beans',\n",
       " 'PLAIN-671': 'benzene',\n",
       " 'PLAIN-681': 'betel nuts',\n",
       " 'PLAIN-691': 'bioavailability',\n",
       " 'PLAIN-701': 'black raspberries',\n",
       " 'PLAIN-711': 'blood clots',\n",
       " 'PLAIN-721': 'BMAA',\n",
       " 'PLAIN-731': 'bone fractures',\n",
       " 'PLAIN-741': 'BPH',\n",
       " 'PLAIN-751': 'BRCA genes',\n",
       " 'PLAIN-761': 'breast pain',\n",
       " 'PLAIN-771': 'bronchiolitis obliterans',\n",
       " 'PLAIN-782': 'Bush administration',\n",
       " 'PLAIN-792': 'cadaverine',\n",
       " 'PLAIN-806': 'caloric restriction',\n",
       " 'PLAIN-817': 'canker sores',\n",
       " 'PLAIN-827': 'carcinogens',\n",
       " 'PLAIN-838': 'carrageenan',\n",
       " 'PLAIN-850': 'cauliflower',\n",
       " 'PLAIN-872': 'chanterelle mushrooms',\n",
       " 'PLAIN-882': 'Chernobyl',\n",
       " 'PLAIN-892': 'chickpeas',\n",
       " 'PLAIN-902': 'chlorophyll',\n",
       " 'PLAIN-913': 'cinnamon',\n",
       " 'PLAIN-924': 'cocaine',\n",
       " 'PLAIN-934': 'coffee',\n",
       " 'PLAIN-946': 'coma',\n",
       " 'PLAIN-956': 'cooking methods',\n",
       " 'PLAIN-966': 'cortisol',\n",
       " 'PLAIN-977': 'crib death',\n",
       " 'PLAIN-987': 'cumin',\n",
       " 'PLAIN-997': 'Czechoslovakia',\n",
       " 'PLAIN-1008': 'deafness',\n",
       " 'PLAIN-1018': 'DHA',\n",
       " 'PLAIN-1028': 'dietary scoring',\n",
       " 'PLAIN-1039': 'domoic acid',\n",
       " 'PLAIN-1050': 'Dr. Dean Ornish',\n",
       " 'PLAIN-1066': 'Dr. Walter Willett',\n",
       " 'PLAIN-1088': 'ECMO',\n",
       " 'PLAIN-1098': 'eggnog',\n",
       " 'PLAIN-1109': 'endocrine disruptors',\n",
       " 'PLAIN-1119': 'energy drinks',\n",
       " 'PLAIN-1130': 'ergothioneine',\n",
       " 'PLAIN-1141': 'Evidence-based medicine',\n",
       " 'PLAIN-1151': 'factory farming practices',\n",
       " 'PLAIN-1161': 'fava beans',\n",
       " 'PLAIN-1172': 'fenugreek',\n",
       " 'PLAIN-1183': 'Finland',\n",
       " 'PLAIN-1193': 'flax oil',\n",
       " 'PLAIN-1203': 'folic acid',\n",
       " 'PLAIN-1214': 'Fosamax',\n",
       " 'PLAIN-1225': 'fructose',\n",
       " 'PLAIN-1236': 'galactosemia',\n",
       " 'PLAIN-1249': 'genetic manipulation',\n",
       " 'PLAIN-1262': 'Global Burden of Disease Study',\n",
       " 'PLAIN-1275': 'goji berries',\n",
       " 'PLAIN-1288': 'grapes',\n",
       " 'PLAIN-1299': 'growth promoters',\n",
       " 'PLAIN-1309': 'halibut',\n",
       " 'PLAIN-1320': 'Harvard Physicians’ Study II',\n",
       " 'PLAIN-1331': 'hearing',\n",
       " 'PLAIN-1342': 'heme iron',\n",
       " 'PLAIN-1353': 'hernia',\n",
       " 'PLAIN-1363': 'Hiroshima',\n",
       " 'PLAIN-1374': 'hormonal dysfunction',\n",
       " 'PLAIN-1387': 'hyperactivity',\n",
       " 'PLAIN-1398': 'IGF-1',\n",
       " 'PLAIN-1409': 'industrial toxins',\n",
       " 'PLAIN-1419': 'insects',\n",
       " 'PLAIN-1429': 'Iowa Women’s Health Study',\n",
       " 'PLAIN-1441': 'Japan',\n",
       " 'PLAIN-1453': 'junk food',\n",
       " 'PLAIN-1463': 'kidney beans',\n",
       " 'PLAIN-1473': 'kohlrabi',\n",
       " 'PLAIN-1485': 'lard',\n",
       " 'PLAIN-1496': 'leeks',\n",
       " 'PLAIN-1506': 'leucine',\n",
       " 'PLAIN-1516': 'Lindane',\n",
       " 'PLAIN-1527': 'liver disease',\n",
       " 'PLAIN-1537': 'low-carb diets',\n",
       " 'PLAIN-1547': 'lyme disease',\n",
       " 'PLAIN-1557': 'magnesium',\n",
       " 'PLAIN-1568': 'maple syrup',\n",
       " 'PLAIN-1579': 'mastitis',\n",
       " 'PLAIN-1590': 'medical ethics',\n",
       " 'PLAIN-1601': 'memory',\n",
       " 'PLAIN-1611': 'mesquite',\n",
       " 'PLAIN-1621': 'Mevacor',\n",
       " 'PLAIN-1635': 'milk',\n",
       " 'PLAIN-1645': 'molasses',\n",
       " 'PLAIN-1656': 'mouth cancer',\n",
       " 'PLAIN-1667': 'muscle health',\n",
       " 'PLAIN-1679': 'myelopathy',\n",
       " 'PLAIN-1690': 'National Academy of Sciences',\n",
       " 'PLAIN-1700': 'Native Americans',\n",
       " 'PLAIN-1710': 'neurocysticercosis',\n",
       " 'PLAIN-1721': 'NIH-AARP study',\n",
       " 'PLAIN-1731': 'norovirus',\n",
       " 'PLAIN-1741': 'nuts',\n",
       " 'PLAIN-1752': 'okra',\n",
       " 'PLAIN-1762': 'oral intraepithelial neoplasia',\n",
       " 'PLAIN-1772': 'organotins',\n",
       " 'PLAIN-1784': 'oxen meat',\n",
       " 'PLAIN-1794': 'Panama',\n",
       " 'PLAIN-1805': \"Parkinson's disease\",\n",
       " 'PLAIN-1817': 'peanut butter',\n",
       " 'PLAIN-1827': 'Peoria',\n",
       " 'PLAIN-1837': 'pesticides',\n",
       " 'PLAIN-1847': 'philippines',\n",
       " 'PLAIN-1857': 'phytic acid',\n",
       " 'PLAIN-1867': 'pineapples',\n",
       " 'PLAIN-1877': 'plant-based diet',\n",
       " 'PLAIN-1887': 'poisonous plants',\n",
       " 'PLAIN-1897': 'polypropylene plastic',\n",
       " 'PLAIN-1909': 'pork',\n",
       " 'PLAIN-1919': 'poultry workers',\n",
       " 'PLAIN-1929': 'prenatal vitamins',\n",
       " 'PLAIN-1940': 'prolactin',\n",
       " 'PLAIN-1950': 'prunes',\n",
       " 'PLAIN-1962': 'pumpkin',\n",
       " 'PLAIN-1972': 'quinine',\n",
       " 'PLAIN-1983': 'rapamycin',\n",
       " 'PLAIN-1995': 'red tea',\n",
       " 'PLAIN-2009': 'rhabdomyolysis',\n",
       " 'PLAIN-2019': 'rickets',\n",
       " 'PLAIN-2030': 'Rutin',\n",
       " 'PLAIN-2040': 'salmon',\n",
       " 'PLAIN-2051': 'saturated fat',\n",
       " 'PLAIN-2061': 'seafood',\n",
       " 'PLAIN-2071': 'serotonin',\n",
       " 'PLAIN-2081': 'shelf life',\n",
       " 'PLAIN-2092': 'sirtuins',\n",
       " 'PLAIN-2102': 'smoking',\n",
       " 'PLAIN-2113': 'soil health',\n",
       " 'PLAIN-2124': 'spearmint',\n",
       " 'PLAIN-2134': 'Splenda',\n",
       " 'PLAIN-2145': \"St. John's wort\",\n",
       " 'PLAIN-2156': 'stevia',\n",
       " 'PLAIN-2167': 'subsidies',\n",
       " 'PLAIN-2177': 'sulfur',\n",
       " 'PLAIN-2187': 'suppositories',\n",
       " 'PLAIN-2197': 'sweeteners',\n",
       " 'PLAIN-2209': 'taro',\n",
       " 'PLAIN-2220': 'tempeh',\n",
       " 'PLAIN-2230': 'thiamine',\n",
       " 'PLAIN-2240': 'titanium dioxide',\n",
       " 'PLAIN-2250': 'tongue worm',\n",
       " 'PLAIN-2261': 'trans fats',\n",
       " 'PLAIN-2271': 'Tufts',\n",
       " 'PLAIN-2281': 'turnips',\n",
       " 'PLAIN-2291': 'ultra-processed foods',\n",
       " 'PLAIN-2301': 'uterine health',\n",
       " 'PLAIN-2311': 'veal',\n",
       " 'PLAIN-2321': 'veggie chicken',\n",
       " 'PLAIN-2332': 'viral infections',\n",
       " 'PLAIN-2343': 'vitamin K',\n",
       " 'PLAIN-2354': 'walnut oil',\n",
       " 'PLAIN-2364': 'weight gain',\n",
       " 'PLAIN-2375': 'whiting',\n",
       " 'PLAIN-2386': 'worms',\n",
       " 'PLAIN-2396': 'Yale',\n",
       " 'PLAIN-2408': 'Zoloft',\n",
       " 'PLAIN-2430': 'Preventing Brain Loss with B Vitamins?',\n",
       " 'PLAIN-2440': 'More Than an Apple a Day: Combating Common Diseases',\n",
       " 'PLAIN-2450': 'Are Organic Foods Safer?',\n",
       " 'PLAIN-2460': 'Diabetes as a Disease of Fat Toxicity',\n",
       " 'PLAIN-2470': 'Is Milk Good for Our Bones?',\n",
       " 'PLAIN-2480': 'Preventing Ulcerative Colitis with Diet',\n",
       " 'PLAIN-2490': 'The Actual Benefit of Diet vs. Drugs',\n",
       " 'PLAIN-2500': 'The Saturated Fat Studies: Buttering Up the Public',\n",
       " 'PLAIN-2510': 'Coffee and Artery Function',\n",
       " 'PLAIN-2520': 'Caloric Restriction vs. Plant-Based Diets',\n",
       " 'PLAIN-2530': 'Infectobesity: Adenovirus 36 and Childhood Obesity',\n",
       " 'PLAIN-2540': 'Does Cholesterol Size Matter?',\n",
       " 'PLAIN-2550': 'Barriers to Heart Disease Prevention',\n",
       " 'PLAIN-2560': 'Childhood Constipation and Cow’s Milk',\n",
       " 'PLAIN-2570': 'Diabetics Should Take Their Pulses',\n",
       " 'PLAIN-2580': 'Academy of Nutrition and Dietetics Conflicts of Interest',\n",
       " 'PLAIN-2590': 'Do Vegetarians Get Enough Protein?',\n",
       " 'PLAIN-2600': 'Eggs and Arterial Function',\n",
       " 'PLAIN-2610': 'Treating Asthma With Plants vs. Supplements?',\n",
       " 'PLAIN-2620': 'Phytates for the Treatment of Cancer',\n",
       " 'PLAIN-2630': 'Alkylphenol Endocrine Disruptors and Allergies',\n",
       " 'PLAIN-2640': 'Chicken Salmonella Thanks to Meat Industry Lawsuit',\n",
       " 'PLAIN-2650': 'Turmeric Curcumin and Osteoarthritis',\n",
       " 'PLAIN-2660': 'How Long to Detox From Fish Before Pregnancy?',\n",
       " 'PLAIN-2670': 'Is Caramel Color Carcinogenic?',\n",
       " 'PLAIN-2680': 'Counteracting the Effects of Dioxins Through Diet',\n",
       " 'PLAIN-2690': 'Chronic Headaches and Pork Tapeworms',\n",
       " 'PLAIN-2700': 'Heart Disease Starts in Childhood',\n",
       " 'PLAIN-2710': 'Artificial Food Colors and ADHD',\n",
       " 'PLAIN-2720': 'Keeping Your Hands Warm With Citrus',\n",
       " 'PLAIN-2730': 'Anti-Angiogenesis: Cutting Off Tumor Supply Lines',\n",
       " 'PLAIN-2740': 'Cancer Risk From CT Scan Radiation',\n",
       " 'PLAIN-2750': 'Preventing the Common Cold with Probiotics?',\n",
       " 'PLAIN-2760': 'Eating Healthy on a Budget',\n",
       " 'PLAIN-2770': 'Flaxseeds & Breast Cancer Survival: Clinical Evidence',\n",
       " 'PLAIN-2780': 'Do Fruit & Nut Bars Cause Weight Gain?',\n",
       " 'PLAIN-2790': 'Titanium Dioxide & Inflammatory Bowel Disease',\n",
       " 'PLAIN-2800': 'Prolonged Liver Function Enhancement From Broccoli',\n",
       " 'PLAIN-2810': 'Apple Juice May Be Worse Than Sugar Water',\n",
       " 'PLAIN-2820': 'Preventing Strokes with Diet',\n",
       " 'PLAIN-2830': 'Neurobiology of Artificial Sweeteners',\n",
       " 'PLAIN-2840': 'Benefits of Fenugreek Seeds',\n",
       " 'PLAIN-2850': 'More Antibiotics In White Meat or Dark Meat?',\n",
       " 'PLAIN-2860': 'BPA Plastic and Male Sexual Dysfunction',\n",
       " 'PLAIN-2870': 'Filled Full of Lead',\n",
       " 'PLAIN-2880': 'The Answer to the Pritikin Puzzle',\n",
       " 'PLAIN-2890': 'To Snack or Not to Snack?',\n",
       " 'PLAIN-2900': 'Boosting Good Bacteria in the Colon Without Probiotics',\n",
       " 'PLAIN-2910': 'Optimal Phytosterol Dose',\n",
       " 'PLAIN-2920': 'Human Neurotransmitters in Plants',\n",
       " 'PLAIN-2930': 'Kiwifruit for Irritable Bowel Syndrome',\n",
       " 'PLAIN-2940': \"Dietary Treatment of Crohn's Disease\",\n",
       " 'PLAIN-2950': 'Unsafe at Any Feed',\n",
       " 'PLAIN-2960': 'Pharmacists Versus Health Food Store Employees: Who Gives Better Advice?',\n",
       " 'PLAIN-2970': 'Preventing Cataracts with Diet',\n",
       " 'PLAIN-2981': 'Cheese Mites and Maggots',\n",
       " 'PLAIN-2991': 'Cholesterol and Lower Back Pain',\n",
       " 'PLAIN-3001': 'EPIC Findings on Lymphoma',\n",
       " 'PLAIN-3014': 'Sometimes the Enzyme Myth Is True',\n",
       " 'PLAIN-3026': 'Vitamin C-Enriched Bacon',\n",
       " 'PLAIN-3037': 'Out of the Lab Onto the Track',\n",
       " 'PLAIN-3053': \"Dragon's Blood\",\n",
       " 'PLAIN-3063': 'Better Than Goji Berries',\n",
       " 'PLAIN-3074': 'How to Help Prevent Abdominal Aortic Aneurysms',\n",
       " 'PLAIN-3085': 'The Difficulty of Arriving at a Vitamin D Recommendation',\n",
       " 'PLAIN-3097': 'Amyloid and Apple Juice',\n",
       " 'PLAIN-3116': 'Dietary Guidelines: From Dairies to Berries',\n",
       " 'PLAIN-3131': 'Are Avocados Good for You?',\n",
       " 'PLAIN-3141': 'Relieving Yourself of Excess Estrogen',\n",
       " 'PLAIN-3151': 'Too Much Iodine Can Be as Bad as Too Little',\n",
       " 'PLAIN-3161': 'Is Milk and Mucus a Myth?',\n",
       " 'PLAIN-3171': 'Convergence of Evidence',\n",
       " 'PLAIN-3181': 'Is Dragon Fruit Good For You?',\n",
       " 'PLAIN-3191': 'Is Distilled Fish Oil Toxin-Free?',\n",
       " 'PLAIN-3201': 'Acne & Cancer Connection',\n",
       " 'PLAIN-3211': 'Overdosing on Greens',\n",
       " 'PLAIN-3221': \"Dietary Theory of Alzheimer's\",\n",
       " 'PLAIN-3231': 'Meat & Multiple Myeloma',\n",
       " 'PLAIN-3241': 'Apthous Ulcer Mystery Solved',\n",
       " 'PLAIN-3251': 'EPIC Study',\n",
       " 'PLAIN-3261': 'Update on Herbalife®',\n",
       " 'PLAIN-3271': 'Saturated Fat & Cancer Progression',\n",
       " 'PLAIN-3281': 'Aluminum in Vaccines vs. Food',\n",
       " 'PLAIN-3292': 'Are Multivitamins Good For You?',\n",
       " 'PLAIN-3302': 'Fish Fog',\n",
       " 'PLAIN-3312': 'Sexually Transmitted Fish Toxin',\n",
       " 'PLAIN-3322': 'Veggies vs. Cancer',\n",
       " 'PLAIN-3332': 'Alcohol Risks vs. Benefits',\n",
       " 'PLAIN-3342': 'Is Coconut Milk Good For You?',\n",
       " 'PLAIN-3352': 'Boosting Heart Nerve Control',\n",
       " 'PLAIN-3362': 'Kuna Indian Secret',\n",
       " 'PLAIN-3372': 'The Healthiest Sweetener',\n",
       " 'PLAIN-3382': 'Are Artificial Colors Bad for You?',\n",
       " 'PLAIN-3392': 'Healthiest Airplane Beverage',\n",
       " 'PLAIN-3402': 'Antioxidant Content of 300 Foods',\n",
       " 'PLAIN-3412': 'Plant vs. Cow Calcium',\n",
       " 'PLAIN-3422': 'Vitamin Supplements Worth Taking',\n",
       " 'PLAIN-3432': 'Healthy Chocolate Milkshakes',\n",
       " 'PLAIN-3442': 'The Healthiest Vegetables',\n",
       " 'PLAIN-3452': 'Bowel Movement Frequency',\n",
       " 'PLAIN-3462': 'Olive Oil and Artery Function',\n",
       " 'PLAIN-3472': 'How Doctors Responded to Being Named a Leading Killer'}"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Association between multivitamin use and breast cancer risk - Is there a significant association between multivitamin use and the risk of breast cancer?',\n",
       " 'Multivitamin supplement use and risk of breast cancer: a meta-analysis. BACKGROUND: The association between consumption of multivitamins and breast cancer is inconsistent in epidemiologic studies. OBJECTIVE: To perform a meta-analysis of cohort and case-control studies to evaluate multivitamin intake and its relationship with breast cancer risk. METHODS: The published literature was systematically searched and reviewed using MEDLINE (1950 through July 2010), EMBASE (1980 through July 2010), and the Cochrane Central Register of Controlled Trials (The Cochrane Library 2010 issue 1). Studies that included specific risk estimates were pooled using a random-effects model. The bias and quality of these studies were assessed with REVMAN statistical software (version 5.0) and the GRADE method of the Cochrane Collaboration. RESULTS: Eight of 27 studies that included 355,080 subjects were available for analysis. The total duration of multivitamin use in these trials ranged from 3 to 10 years. The frequency of current use in these studies ranged from 2 to 6 times/week. In analyses by duration of use 10 years or longer or 3 years or longer and by frequency 7 or more times/week that were reported in these studies, multivitamin use was not significantly associated with the risk of breast cancer. Only 1 recent Swedish cohort study concluded that multivitamin use is associated with an increased risk of breast cancer. The results of a meta-analysis that pooled data from 5 cohort studies and 3 case-control studies indicated that the overall multivariable relative risk and odds ratio were 0.10 (95% CI 0.60 to 1.63; p = 0.98) and 1.00 (95% CI 0.51 to 1.00; p = 1.00), respectively. The association was not statistically significant. CONCLUSIONS: Multivitamin use is likely not associated with a significant increased or decreased risk of breast cancer, but these results highlight the need for more case-control studies or randomized controlled clinical trials to further examine this relationship.']"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_examples[158].texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = datasets.NoDuplicatesDataLoader(train_examples, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_model = SentenceTransformer(baseline_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = losses.MultipleNegativesRankingLoss(ft_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09deef7ef7a94d1c90db318cfe720885",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48d6a7800ed340f98735e877e9e2b91f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/454 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21810b00104d490d918e77006e8e7123",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/454 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a46fb933a1d74277b9c12e9f76ab23c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/454 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tune the model\n",
    "model_path = f\"../models/{dataset_name}_{baseline_model.replace('-', '_')}_ft\"\n",
    "num_epochs = 3\n",
    "warmup_steps = int(len(train_dataloader) * num_epochs * 0.1)\n",
    "ft_model.fit(train_objectives=[(train_dataloader, train_loss)], epochs=num_epochs, warmup_steps=warmup_steps, show_progress_bar=True, checkpoint_path=model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-01 14:57:19.525\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mzeroqaret.dataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1mDatasets will be saved in '/home/bengsoon/Projects/xcs224u_project/zeroqaret/datasets'\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "ft_retriever = SBERTEval(model_path, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excessive milk consumption has a long association with increased respiratory tract mucus production and asthma. Such an association cannot be explained using a conventional allergic paradigm and there is limited medical evidence showing causality. In the human colon, beta-casomorphin-7 (beta-CM-7), an exorphin derived from the breakdown of A1 milk, stimulates mucus production from gut MUC5AC glands. In the presence of inflammation similar mucus overproduction from respiratory tract MUC5AC glands characterises many respiratory tract diseases. beta-CM-7 from the blood stream could stimulate the production and secretion of mucus production from these respiratory glands. Such a hypothesis could be tested in vitro using quantitative RT-PCR to show that the addition of beta-CM-7 into an incubation medium of respiratory goblet cells elicits an increase in MUC5AC mRNA and by identifying beta-CM-7 in the blood of asthmatic patients. This association may not necessarily be simply cause and effect as the person has to be consuming A1 milk, beta-CM-7 must pass into the systemic circulation and the tissues have to be actively inflamed. These prerequisites could explain why only a subgroup of the population, who have increased respiratory tract mucus production, find that many of their symptoms, including asthma, improve on a dairy elimination diet. (c) 2009 Elsevier Ltd. All rights reserved.\n",
      "\n",
      "Twenty-seven consecutive infants (mean age, 20.6 months) with chronic \"idiopathic\" constipation were studied to investigate the possible relation between constipation and cow milk protein allergy (CMPA). The infants were initially observed on an unrestricted diet, and the number of stools per day was recorded. Subsequently the infants were put on a diet free of cow milk protein (CMP) for two periods of 1 month each, separated by two challenges with CMP. During the CMP-free diet, there was a resolution of symptoms in 21 patients; during the two consecutive challenges, constipation reappeared within 48 to 72 hours. In another six patients the CMP-free diet did not lead to improvement of constipation. Only four of the patients who improved on the CMP-free diet had concomitant symptoms of suspected CMPA, but a medical history of CMPA was found in 15 of the 21 patients cured and in only one of the six patients whose condition had not improved (p < 0.05); in addition, in 15 of the 21 cured patients, results of one or more laboratory tests (specific IgE, IgG, anti-beta-lactoglobulin, circulating eosinophils) were positive at the time of diagnosis, indicating hypersensitivity, compared with one of the six patients whose condition did not improve (p < 0.05). The endoscopic and histologic findings at the time of diagnosis showed proctitis with monocytic infiltration in two patients cured with the CMP-free diet; after 1 month on this diet, they were completely normal. We conclude that constipation in infants may have an allergic pathogenesis.\n",
      "\n",
      "To determine whether cow's milk allergy (CMA) in infancy is associated with recurrent otitis media (ROM) or other chronic ear infections, we conducted a cohort study by enrolling 56 milk-allergic and 204 control schoolchildren. We also studied the association between ear problems and different atopic manifestations. A higher proportion of children with CMA had had ROM. defined as at least 15 acute otitis media episodes by the age of 10 years (27%, vs 12%, p = 0.009), and had undergone adenoidectomy and or tympanostomy compared with the controls (48%, vs 28%, p = 0.005). However, this was only true of the children who had developed respiratory atopy. Asthma and/or allergic rhinitis, but not atopic dermatitis, posed a significant risk for ROM, while all the three atopic manifestations enhanced the risk for secretory otitis media. Positive skin prick tests with food, but not with inhaled allergens, tended to be associated with ear problems. In conclusion, we found that children with CMA in infancy, even when properly treated, had experienced significantly more ROM, the risk associating with concomitant development of respiratory atopy.\n",
      "\n",
      "Consumption of cow's milk and cow's milk protein result in changes of the hormonal axis of insulin, growth hormone and insulin-like growth factor-1(IGF-1) in humans. Milk consumption raises IGF-1 serum levels in the perinatal period, adolescence and adulthood. During puberty with the physiological onset of increased secretion of growth hormone, IGF-1 serum levels increase and are further enhanced by milk consumption. IGF-1 is a potent mitogen; after binding to its receptor in various tissues, it induces cell proliferation and inhibits apoptosis. Keratinocytes and sebocytes, as well as the androgen-synthesizing adrenals and gonads, are stimulated by IGF-1. The epidemic incidence of adolescent acne in Western milk-consuming societies can be explained by the increased insulin- and IGF-1-stimulation of sebaceous glands mediated by milk consumption. Acne can be regarded as a model for chronic Western diseases with pathologically increased IGF-1-stimulation. Many other organs, such as the thymus, bones, all glands, and vascular smooth muscle cells as well as neurons are subject to this abnormally increased hormonal stimulation. The milk-induced change of the IGF-1-axis most likely contributes to the development of fetal macrosomia, induction of atopy, accelerated linear growth, atherosclerosis, carcinogenesis and neurodegenerative diseases. Observations of molecular biology are supported by epidemiologic data and unmask milk consumption as a promoter of chronic diseases of Western societies.\n",
      "\n",
      "Milk has been recognized to represent a functionally active nutrient system promoting neonatal growth of mammals. Cell growth is regulated by the nutrient-sensitive kinase mechanistic target of rapamycin complex 1 (mTORC1). There is still a lack of information on the mechanisms of mTORC1 up-regulation by milk consumption. This review presents milk as a materno-neonatal relay system functioning by transfer of preferential amino acids, which increase plasma levels of glucose-dependent insulinotropic polypeptide (GIP), glucagon-like peptide-1 (GLP-1), insulin, growth hormone (GH) and insulin-like growth factor-1 (IGF-1) for mTORC1 activation. Importantly, milk exosomes, which regularly contain microRNA-21, most likely represent a genetic transfection system enhancing mTORC1-driven metabolic processes. Whereas human breast milk is the ideal food for infants allowing appropriate postnatal growth and species-specific metabolic programming, persistent high milk signaling during adolescence and adulthood by continued cow´s milk consumption may promote mTORC1-driven diseases of civilization.\n",
      "\n",
      "Milk has been recognized to represent a functionally active nutrient system promoting neonatal growth of mammals. Cell growth is regulated by the nutrient-sensitive kinase mechanistic target of rapamycin complex 1 (mTORC1). There is still a lack of information on the mechanisms of mTORC1 up-regulation by milk consumption. This review presents milk as a materno-neonatal relay system functioning by transfer of preferential amino acids, which increase plasma levels of glucose-dependent insulinotropic polypeptide (GIP), glucagon-like peptide-1 (GLP-1), insulin, growth hormone (GH) and insulin-like growth factor-1 (IGF-1) for mTORC1 activation. Importantly, milk exosomes, which regularly contain microRNA-21, most likely represent a genetic transfection system enhancing mTORC1-driven metabolic processes. Whereas human breast milk is the ideal food for infants allowing appropriate postnatal growth and species-specific metabolic programming, persistent high milk signaling during adolescence and adulthood by continued cow´s milk consumption may promote mTORC1-driven diseases of civilization.\n",
      "\n",
      "There has been a remarkable paucity of evidence for an association between diet and acne. Our previous studies suggest that there is an association between milk intake and teenage acne. This is a prospective cohort study to evaluate that relationship. We studied 6,094 girls, aged 9-15 years in 1996, who reported dietary intake on up to three food frequency questionnaires from 1996 to 1998. Presence and severity of acne was assessed by questionnaire in 1999. We computed multivariate prevalence ratios (PR) and 95 percent confidence intervals for acne. After accounting for age at baseline, height and energy intake, the multivariate PRs (95 % CI; p-value for test of trend) for acne comparing highest (2 or more servings per day) to lowest (<1 per week) intake categories in 1996, were 1.20 (1.09, 1.31; <0.001) for total milk, 1.19 (1.06, 1.32; <0.001) for whole milk, 1.17 (1.04, 1.31; 0.002) for low fat milk and 1.19 (1.08, 1.31; <0.001) for skim milk. This result did not change appreciably when we excluded girls who reported use of contraceptives and when we restricted our analysis to those younger than 11 years of age at baseline. We found a positive association between intake of milk and acne. This finding supports earlier studies and suggests that the metabolic effects of milk are sufficient to elicit biological responses in consumers.\n",
      "\n",
      "Acne vulgaris, the most common skin disease of western civilization, has evolved to an epidemic affecting more than 85% of adolescents. Acne can be regarded as an indicator disease of exaggerated insulinotropic western nutrition. Especially milk and whey protein-based products contribute to elevations of postprandial insulin and basal insulin-like growth factor-I (IGF-I) plasma levels. It is the evolutional principle of mammalian milk to promote growth and support anabolic conditions for the neonate during the nursing period. Whey proteins are most potent inducers of glucose-dependent insulinotropic polypeptide secreted by enteroendocrine K cells which in concert with hydrolyzed whey protein-derived essential amino acids stimulate insulin secretion of pancreatic β-cells. Increased insulin/IGF-I signaling activates the phosphoinositide-3 kinase/Akt pathway, thereby reducing the nuclear content of the transcription factor FoxO1, the key nutrigenomic regulator of acne target genes. Nuclear FoxO1 deficiency has been linked to all major factors of acne pathogenesis, i.e. androgen receptor transactivation, comedogenesis, increased sebaceous lipogenesis, and follicular inflammation. The elimination of the whey protein-based insulinotropic mechanisms of milk will be the most important future challenge for nutrition research. Both, restriction of milk consumption or generation of less insulinotropic milk will have an enormous impact on the prevention of epidemic western diseases like obesity, diabetes mellitus, cancer, neurodegenerative diseases and acne. Copyright © 2011 S. Karger AG, Basel.\n",
      "\n",
      "The effect of alternative dietary habits and prolonged lactation on the nutrient and contaminant concentrations in human milk was studied. The study sample consisted of mothers on macrobiotic diets, containing little or no diary products and meat, at 2-3 months postpartum (n = 9) and 9-13 months postpartum (n = 12), and mothers on omnivorous diets at 2-3 months postpartum (n = 10). Protein and zinc concentrations in breast-milk from macrobiotic mothers decreased with stage of lactation. After adjustment for stage of lactation, milk from macrobiotic mothers contained less calcium, magnesium and saturated fatty acids C15:0-C20:0, and more polyunsaturated fatty acids. Observed tendencies for lower protein and fat and higher lactose concentrations in the macrobiotic group were not statistically significant. Concentrations of vitamin B12, HCB and polychlorinated biphenyls (PCB 118, PCB 138, PCB 153 and PCB 180) were lower in the macrobiotic group. After adjustment for confounding variables, meat and fish consumption, but not dairy products, contributed to vitamin B12 concentrations. Meat and diary products strongly contributed to breast-milk concentrations of dieldrin and PCBs, fish to PCB 118, and smoking to DDT and dieldrin. Our findings suggest that breast-milk contamination could be reduced by abstinence from smoking and a moderate intake of animal products. However, risk of nutritional deficiencies rules out complete avoidance of meat, fish or diary products. Quantitative research on the effects of a reduced consumption of animal products, as well as smoking, on breast-milk contamination is warranted.\n",
      "\n",
      "Objective We sought to examine the association between dietary dairy intake and teenaged acne among boys. Methods This was a prospective cohort study. We studied 4273 boys, members of a prospective cohort study of youths and of lifestyle factors, who reported dietary intake on up to 3 food frequency questionnaires from 1996 to 1998 and teenaged acne in 1999. We computed multivariate prevalence ratios and 95% confidence intervals for acne. Results After adjusting for age at baseline, height, and energy intake, the multivariate prevalence ratios (95% confidence interval; P value for test of trend) for acne comparing highest (>2 servings/d) with lowest (<1/wk) intake categories in 1996 were 1.16 (1.01, 1.34; 0.77) for total milk, 1.10 (0.94, 1.28; 0.83) for whole/2% milk, 1.17 (0.99, 1.39; 0.08) for low-fat (1%) milk, and 1.19 (1.01, 1.40; 0.02) for skim milk. Limitations Not all members of the cohort responded to the questionnaire. Acne assessment was by self-report and boys whose symptoms might have been part of an underlying disorder were not excluded. We did not adjust for steroid use and other lifestyle factors that may affect occurrence of acne. Conclusion We found a positive association between intake of skim milk and acne. This finding suggests that skim milk contains hormonal constituents, or factors that influence endogenous hormones, in sufficient quantities to have biological effects in consumers.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\n\".join([corpus[corpus_ids[i]][\"text\"] for i in ft_retriever.search_queries(\"Is Milk and Mucus a Myth?\", 10)[0][0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-01 14:57:19.531\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mbeir_retrieval\u001b[0m:\u001b[36m13\u001b[0m - \u001b[1m\n",
      "   \n",
      "****************************************************************************************************   \n",
      "******                                                                                        ******   \n",
      "                                     Evaluation for 'nfcorpus'                                     *   \n",
      "******                                                                                        ******   \n",
      "****************************************************************************************************\n",
      "\u001b[0m\n",
      "\u001b[32m2023-11-01 14:57:19.532\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mzeroqaret.dataset\u001b[0m:\u001b[36mload_dataset\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1mDownloading dataset 'nfcorpus'...\u001b[0m\n",
      "\u001b[32m2023-11-01 14:57:19.533\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mzeroqaret.dataset\u001b[0m:\u001b[36mload_dataset\u001b[0m:\u001b[36m65\u001b[0m - \u001b[1mSaved on '/home/bengsoon/Projects/xcs224u_project/zeroqaret/datasets/nfcorpus'\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fd657d0bffb4769866ad3cd215522e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3633 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-01 14:57:19.615\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mbeir_retrieval\u001b[0m:\u001b[36m21\u001b[0m - \u001b[1mPre-computing Document Embeddings for 'nfcorpus' dataset...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7163284683d841158eb9277653b71589",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/29 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-01 14:57:27.296\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mbeir_retrieval\u001b[0m:\u001b[36m32\u001b[0m - \u001b[1mNumber of documents: 3633, Dim: 384\u001b[0m\n",
      "\u001b[32m2023-11-01 14:57:27.297\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mbeir_retrieval\u001b[0m:\u001b[36m33\u001b[0m - \u001b[1mIndex size (in MB): 5.58MB\u001b[0m\n",
      "\u001b[32m2023-11-01 14:57:27.298\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mbeir_retrieval\u001b[0m:\u001b[36m34\u001b[0m - \u001b[1mTime taken for pre-computing corpus embedding: 7.67 s\u001b[0m\n",
      "\u001b[32m2023-11-01 14:57:27.299\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mbeir_retrieval\u001b[0m:\u001b[36m35\u001b[0m - \u001b[1mPre-computing of Document Embeddings done.\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[32m2023-11-01 14:57:27.300\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mbeir_retrieval\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mStarting query benchmark evaluation ...\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 323/323 [00:02<00:00, 130.77it/s]\n",
      "\u001b[32m2023-11-01 14:57:29.772\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mbeir_retrieval\u001b[0m:\u001b[36m60\u001b[0m - \u001b[1mAverage time taken: 7.20 ms / query\u001b[0m\n",
      "\u001b[32m2023-11-01 14:57:29.773\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mbeir_retrieval\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mTotal time taken: 2324.40 s\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "ft_results, ft_time = ft_retriever.beir_retrieval(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "nfcorpus_results.collect(f\"{baseline_model}_ft\", ft_retriever, ft_results, ft_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Baseline SBERT</th>\n",
       "      <th>multi-qa-MiniLM-L6-cos-v1_ft</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NDCG@1</th>\n",
       "      <td>0.388540</td>\n",
       "      <td>0.385450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NDCG@3</th>\n",
       "      <td>0.348380</td>\n",
       "      <td>0.339320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NDCG@5</th>\n",
       "      <td>0.324230</td>\n",
       "      <td>0.312470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NDCG@10</th>\n",
       "      <td>0.296740</td>\n",
       "      <td>0.287040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NDCG@100</th>\n",
       "      <td>0.266600</td>\n",
       "      <td>0.254110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NDCG@1000</th>\n",
       "      <td>0.350880</td>\n",
       "      <td>0.335650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAP@1</th>\n",
       "      <td>0.050240</td>\n",
       "      <td>0.041510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAP@3</th>\n",
       "      <td>0.079710</td>\n",
       "      <td>0.071340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAP@5</th>\n",
       "      <td>0.091500</td>\n",
       "      <td>0.082020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAP@10</th>\n",
       "      <td>0.105330</td>\n",
       "      <td>0.096700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAP@100</th>\n",
       "      <td>0.129700</td>\n",
       "      <td>0.118850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAP@1000</th>\n",
       "      <td>0.141630</td>\n",
       "      <td>0.129740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall@1</th>\n",
       "      <td>0.050240</td>\n",
       "      <td>0.041510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall@3</th>\n",
       "      <td>0.090630</td>\n",
       "      <td>0.084550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall@5</th>\n",
       "      <td>0.108830</td>\n",
       "      <td>0.101320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall@10</th>\n",
       "      <td>0.139960</td>\n",
       "      <td>0.131930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall@100</th>\n",
       "      <td>0.266360</td>\n",
       "      <td>0.262240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall@1000</th>\n",
       "      <td>0.578160</td>\n",
       "      <td>0.559680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P@1</th>\n",
       "      <td>0.402480</td>\n",
       "      <td>0.402480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P@3</th>\n",
       "      <td>0.324050</td>\n",
       "      <td>0.318890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P@5</th>\n",
       "      <td>0.277400</td>\n",
       "      <td>0.266870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P@10</th>\n",
       "      <td>0.218270</td>\n",
       "      <td>0.213930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P@100</th>\n",
       "      <td>0.067800</td>\n",
       "      <td>0.064610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P@1000</th>\n",
       "      <td>0.018890</td>\n",
       "      <td>0.018310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average Query Time (ms/it)</th>\n",
       "      <td>7.597585</td>\n",
       "      <td>7.196279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total Query Time (s)</th>\n",
       "      <td>2.454020</td>\n",
       "      <td>2.324398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total Document Embedding Time (s)</th>\n",
       "      <td>7.395014</td>\n",
       "      <td>7.668651</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Baseline SBERT  \\\n",
       "NDCG@1                                   0.388540   \n",
       "NDCG@3                                   0.348380   \n",
       "NDCG@5                                   0.324230   \n",
       "NDCG@10                                  0.296740   \n",
       "NDCG@100                                 0.266600   \n",
       "NDCG@1000                                0.350880   \n",
       "MAP@1                                    0.050240   \n",
       "MAP@3                                    0.079710   \n",
       "MAP@5                                    0.091500   \n",
       "MAP@10                                   0.105330   \n",
       "MAP@100                                  0.129700   \n",
       "MAP@1000                                 0.141630   \n",
       "Recall@1                                 0.050240   \n",
       "Recall@3                                 0.090630   \n",
       "Recall@5                                 0.108830   \n",
       "Recall@10                                0.139960   \n",
       "Recall@100                               0.266360   \n",
       "Recall@1000                              0.578160   \n",
       "P@1                                      0.402480   \n",
       "P@3                                      0.324050   \n",
       "P@5                                      0.277400   \n",
       "P@10                                     0.218270   \n",
       "P@100                                    0.067800   \n",
       "P@1000                                   0.018890   \n",
       "Average Query Time (ms/it)               7.597585   \n",
       "Total Query Time (s)                     2.454020   \n",
       "Total Document Embedding Time (s)        7.395014   \n",
       "\n",
       "                                   multi-qa-MiniLM-L6-cos-v1_ft  \n",
       "NDCG@1                                                 0.385450  \n",
       "NDCG@3                                                 0.339320  \n",
       "NDCG@5                                                 0.312470  \n",
       "NDCG@10                                                0.287040  \n",
       "NDCG@100                                               0.254110  \n",
       "NDCG@1000                                              0.335650  \n",
       "MAP@1                                                  0.041510  \n",
       "MAP@3                                                  0.071340  \n",
       "MAP@5                                                  0.082020  \n",
       "MAP@10                                                 0.096700  \n",
       "MAP@100                                                0.118850  \n",
       "MAP@1000                                               0.129740  \n",
       "Recall@1                                               0.041510  \n",
       "Recall@3                                               0.084550  \n",
       "Recall@5                                               0.101320  \n",
       "Recall@10                                              0.131930  \n",
       "Recall@100                                             0.262240  \n",
       "Recall@1000                                            0.559680  \n",
       "P@1                                                    0.402480  \n",
       "P@3                                                    0.318890  \n",
       "P@5                                                    0.266870  \n",
       "P@10                                                   0.213930  \n",
       "P@100                                                  0.064610  \n",
       "P@1000                                                 0.018310  \n",
       "Average Query Time (ms/it)                             7.196279  \n",
       "Total Query Time (s)                                   2.324398  \n",
       "Total Document Embedding Time (s)                      7.668651  "
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nfcorpus_results.all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ColBERTv2 Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc6622dda0a94f0da2a6e008e14846b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3633 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "047587cc8384465e90280feb1ba2274d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3633 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-01 18:29:40.094\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mconvert_for_colbert\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mPreprocessing Corpus and Saving to /home/bengsoon/Projects/xcs224u_project/zeroqaret/datasets/nfcorpus/colbert/nfcorpus_collection.tsv ...\u001b[0m\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 3633/3633 [00:00<00:00, 30834.29it/s]\n",
      "\u001b[32m2023-11-01 18:29:40.217\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mconvert_for_colbert\u001b[0m:\u001b[36m34\u001b[0m - \u001b[1mPreprocessing Corpus and Saving to /home/bengsoon/Projects/xcs224u_project/zeroqaret/datasets/nfcorpus/colbert/nfcorpus_queries.tsv ...\u001b[0m\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 323/323 [00:00<00:00, 468127.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Nov 01, 18:29:40] #> Loading collection...\n",
      "0M \n",
      "[Nov 01, 18:29:40] #> Loading the queries from /home/bengsoon/Projects/xcs224u_project/zeroqaret/datasets/nfcorpus/colbert/nfcorpus_queries.tsv ...\n",
      "[Nov 01, 18:29:40] #> Got 323 queries. All QIDs are unique.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "corpus, queries, qrels = beir_datasets.load_dataset(dataset_name)\n",
    "\n",
    "# The indices in BeIR datasets may not be monotic, \n",
    "### so we will need a dictionary with enumerated indices (which is used in ColBERT) as keys and BeIR index as values\n",
    "### collection_ids = {colbert_index: beir_index}\n",
    "collection_ids = list(corpus)\n",
    "queries_ids = list(queries)\n",
    "\n",
    "# Load datasets for ColBERT\n",
    "collection_path, queries_path = beir_datasets.convert_for_colbert(dataset_name)\n",
    "collection, queries = Collection(path=collection_path), Queries(path=queries_path)\n",
    "\n",
    "# queries = list(queries.values())\n",
    "\n",
    "checkpoint = 'colbert-ir/colbertv2.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbits = 2   # encode each dimension with 2 bits\n",
    "doc_maxlen = 300 # truncate passages at 300 tokens\n",
    "\n",
    "index_name = f'{dataset_name}.{nbits}bits'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[Nov 01, 18:21:28] #> Creating directory /home/bengsoon/Projects/xcs224u_project/zeroqaret/nbs/experiments/ColBERTv2Base_nfcorpus/indexes/nfcorpus.2bits \n",
      "\n",
      "\n",
      "#> Starting...\n",
      "nranks = 1 \t num_gpus = 1 \t device=0\n",
      "{\n",
      "    \"query_token_id\": \"[unused0]\",\n",
      "    \"doc_token_id\": \"[unused1]\",\n",
      "    \"query_token\": \"[Q]\",\n",
      "    \"doc_token\": \"[D]\",\n",
      "    \"ncells\": null,\n",
      "    \"centroid_score_threshold\": null,\n",
      "    \"ndocs\": null,\n",
      "    \"load_index_with_mmap\": false,\n",
      "    \"index_path\": null,\n",
      "    \"nbits\": 2,\n",
      "    \"kmeans_niters\": 4,\n",
      "    \"resume\": false,\n",
      "    \"similarity\": \"cosine\",\n",
      "    \"bsize\": 64,\n",
      "    \"accumsteps\": 1,\n",
      "    \"lr\": 3e-6,\n",
      "    \"maxsteps\": 500000,\n",
      "    \"save_every\": null,\n",
      "    \"warmup\": null,\n",
      "    \"warmup_bert\": null,\n",
      "    \"relu\": false,\n",
      "    \"nway\": 2,\n",
      "    \"use_ib_negatives\": false,\n",
      "    \"reranker\": false,\n",
      "    \"distillation_alpha\": 1.0,\n",
      "    \"ignore_scores\": false,\n",
      "    \"model_name\": null,\n",
      "    \"query_maxlen\": 32,\n",
      "    \"attend_to_mask_tokens\": false,\n",
      "    \"interaction\": \"colbert\",\n",
      "    \"dim\": 128,\n",
      "    \"doc_maxlen\": 300,\n",
      "    \"mask_punctuation\": true,\n",
      "    \"checkpoint\": \"colbert-ir\\/colbertv2.0\",\n",
      "    \"triples\": null,\n",
      "    \"collection\": \"\\/home\\/bengsoon\\/Projects\\/xcs224u_project\\/zeroqaret\\/datasets\\/nfcorpus\\/colbert\\/nfcorpus_collection.tsv\",\n",
      "    \"queries\": null,\n",
      "    \"index_name\": \"nfcorpus.2bits\",\n",
      "    \"overwrite\": false,\n",
      "    \"root\": \"\\/home\\/bengsoon\\/Projects\\/xcs224u_project\\/zeroqaret\\/nbs\\/experiments\",\n",
      "    \"experiment\": \"ColBERTv2Base_nfcorpus\",\n",
      "    \"index_root\": null,\n",
      "    \"name\": \"2023-10\\/31\\/12.41.13\",\n",
      "    \"rank\": 0,\n",
      "    \"nranks\": 1,\n",
      "    \"amp\": true,\n",
      "    \"gpus\": 1\n",
      "}\n",
      "[Nov 01, 18:21:35] [0] \t\t # of sampled PIDs = 3633 \t sampled_pids[:3] = [1706, 3001, 41]\n",
      "[Nov 01, 18:21:35] [0] \t\t #> Encoding 3633 passages..\n",
      "[Nov 01, 18:21:44] [0] \t\t avg_doclen_est = 235.5755615234375 \t len(local_sample) = 3,633\n",
      "[Nov 01, 18:21:44] [0] \t\t Creaing 8,192 partitions.\n",
      "[Nov 01, 18:21:44] [0] \t\t *Estimated* 855,846 embeddings.\n",
      "[Nov 01, 18:21:44] [0] \t\t #> Saving the indexing plan to /home/bengsoon/Projects/xcs224u_project/zeroqaret/nbs/experiments/ColBERTv2Base_nfcorpus/indexes/nfcorpus.2bits/plan.json ..\n",
      "Clustering 813054 points in 128D to 8192 clusters, redo 1 times, 4 iterations\n",
      "  Preprocessing in 0.06 s\n",
      "  Iteration 3 (1.01 s, search 0.91 s): objective=194024 imbalance=1.359 nsplit=0       \n",
      "[Nov 01, 18:21:46] Loading decompress_residuals_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n",
      "[Nov 01, 18:21:46] Loading packbits_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n",
      "[0.032, 0.037, 0.035, 0.033, 0.034, 0.035, 0.037, 0.032, 0.031, 0.034, 0.033, 0.033, 0.036, 0.037, 0.032, 0.035, 0.031, 0.034, 0.032, 0.033, 0.034, 0.035, 0.033, 0.035, 0.033, 0.032, 0.037, 0.034, 0.032, 0.038, 0.032, 0.038, 0.035, 0.034, 0.034, 0.032, 0.038, 0.035, 0.033, 0.041, 0.034, 0.034, 0.034, 0.035, 0.033, 0.034, 0.035, 0.038, 0.035, 0.033, 0.032, 0.035, 0.034, 0.033, 0.032, 0.034, 0.043, 0.034, 0.039, 0.035, 0.034, 0.036, 0.035, 0.038, 0.036, 0.035, 0.035, 0.038, 0.033, 0.034, 0.037, 0.032, 0.033, 0.036, 0.034, 0.037, 0.035, 0.034, 0.035, 0.038, 0.035, 0.034, 0.034, 0.037, 0.031, 0.034, 0.033, 0.037, 0.032, 0.038, 0.033, 0.038, 0.034, 0.034, 0.035, 0.036, 0.04, 0.035, 0.034, 0.034, 0.036, 0.039, 0.036, 0.033, 0.035, 0.034, 0.034, 0.034, 0.035, 0.033, 0.035, 0.036, 0.035, 0.031, 0.035, 0.035, 0.033, 0.033, 0.034, 0.035, 0.033, 0.035, 0.035, 0.036, 0.033, 0.035, 0.034, 0.033]\n",
      "[Nov 01, 18:21:46] #> Got bucket_cutoffs_quantiles = tensor([0.2500, 0.5000, 0.7500], device='cuda:0') and bucket_weights_quantiles = tensor([0.1250, 0.3750, 0.6250, 0.8750], device='cuda:0')\n",
      "[Nov 01, 18:21:46] #> Got bucket_cutoffs = tensor([-0.0273,  0.0002,  0.0277], device='cuda:0') and bucket_weights = tensor([-0.0485, -0.0126,  0.0129,  0.0490], device='cuda:0')\n",
      "[Nov 01, 18:21:46] avg_residual = 0.03460693359375\n",
      "[Nov 01, 18:21:46] [0] \t\t #> Encoding 3633 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Nov 01, 18:21:54] [0] \t\t #> Saving chunk 0: \t 3,633 passages and 855,846 embeddings. From #0 onward.\n",
      "[Nov 01, 18:21:54] [0] \t\t #> Checking all files were saved...\n",
      "[Nov 01, 18:21:54] [0] \t\t Found all files!\n",
      "[Nov 01, 18:21:54] [0] \t\t #> Building IVF...\n",
      "[Nov 01, 18:21:54] [0] \t\t #> Loading codes...\n",
      "[Nov 01, 18:21:54] [0] \t\t Sorting codes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:08,  8.20s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00, 708.98it/s]\n",
      "100%|██████████| 8192/8192 [00:00<00:00, 83510.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Nov 01, 18:21:54] [0] \t\t Getting unique codes...\n",
      "[Nov 01, 18:21:54] #> Optimizing IVF to store map from centroids to list of pids..\n",
      "[Nov 01, 18:21:54] #> Building the emb2pid mapping..\n",
      "[Nov 01, 18:21:54] len(emb2pid) = 855846\n",
      "[Nov 01, 18:21:55] #> Saved optimized IVF to /home/bengsoon/Projects/xcs224u_project/zeroqaret/nbs/experiments/ColBERTv2Base_nfcorpus/indexes/nfcorpus.2bits/ivf.pid.pt\n",
      "[Nov 01, 18:21:55] [0] \t\t #> Saving the indexing metadata to /home/bengsoon/Projects/xcs224u_project/zeroqaret/nbs/experiments/ColBERTv2Base_nfcorpus/indexes/nfcorpus.2bits/metadata.json ..\n",
      "#> Joined...\n",
      "[Nov 01, 18:21:58] #> Loading codec...\n",
      "[Nov 01, 18:21:58] #> Loading IVF...\n",
      "[Nov 01, 18:21:58] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 2044.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Nov 01, 18:21:59] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 89.83it/s]\n"
     ]
    }
   ],
   "source": [
    "model = ColBERTRetrievalSearch(checkpoint, \n",
    "                                   index_name, \n",
    "                                   experiment_name=f\"ColBERTv2Base_{dataset_name}\", \n",
    "                                   collection=collection, \n",
    "                                   collection_ids=collection_ids,\n",
    "                                   doc_maxlen=doc_maxlen, \n",
    "                                   nbits=nbits, \n",
    "                                   overwrite_param=\"reuse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = EvaluateRetrieval(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mretriever\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcorpus\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mqueries\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m <no docstring>\n",
       "\u001b[0;31mSource:\u001b[0m   \n",
       "    \u001b[0;32mdef\u001b[0m \u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqueries\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretriever\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Model/Technique has not been provided!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretriever\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqueries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtop_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mFile:\u001b[0m      ~/conda/envs/xcs224/lib/python3.9/site-packages/beir/retrieval/evaluation.py\n",
       "\u001b[0;31mType:\u001b[0m      method"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "retriever.retrieve??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "323it [00:02, 108.39it/s]\n"
     ]
    }
   ],
   "source": [
    "results = retriever.retrieve(collection, queries)\n",
    "\n",
    "# the keys in results need to be converted back to original qids\n",
    "results = {queries_ids[int(k)]:v   for k, v in results.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever.qrels = qrels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "nfcorpus_results.collect(\"ColBERTv2 Baseline\", retriever, results, {'Average Query Time (ms/it)': 9.39, 'Total Query Time (s)': 3.0, 'Total Document Embedding Time (s)': None})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Baseline SBERT</th>\n",
       "      <th>multi-qa-MiniLM-L6-cos-v1_ft</th>\n",
       "      <th>ColBERTv2 Baseline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NDCG@1</th>\n",
       "      <td>0.388540</td>\n",
       "      <td>0.385450</td>\n",
       "      <td>0.47214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NDCG@3</th>\n",
       "      <td>0.348380</td>\n",
       "      <td>0.339320</td>\n",
       "      <td>0.41224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NDCG@5</th>\n",
       "      <td>0.324230</td>\n",
       "      <td>0.312470</td>\n",
       "      <td>0.38223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NDCG@10</th>\n",
       "      <td>0.296740</td>\n",
       "      <td>0.287040</td>\n",
       "      <td>0.34323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NDCG@100</th>\n",
       "      <td>0.266600</td>\n",
       "      <td>0.254110</td>\n",
       "      <td>0.30330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NDCG@1000</th>\n",
       "      <td>0.350880</td>\n",
       "      <td>0.335650</td>\n",
       "      <td>0.35523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAP@1</th>\n",
       "      <td>0.050240</td>\n",
       "      <td>0.041510</td>\n",
       "      <td>0.06371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAP@3</th>\n",
       "      <td>0.079710</td>\n",
       "      <td>0.071340</td>\n",
       "      <td>0.10011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAP@5</th>\n",
       "      <td>0.091500</td>\n",
       "      <td>0.082020</td>\n",
       "      <td>0.11375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAP@10</th>\n",
       "      <td>0.105330</td>\n",
       "      <td>0.096700</td>\n",
       "      <td>0.12995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAP@100</th>\n",
       "      <td>0.129700</td>\n",
       "      <td>0.118850</td>\n",
       "      <td>0.15842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAP@1000</th>\n",
       "      <td>0.141630</td>\n",
       "      <td>0.129740</td>\n",
       "      <td>0.16677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall@1</th>\n",
       "      <td>0.050240</td>\n",
       "      <td>0.041510</td>\n",
       "      <td>0.06371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall@3</th>\n",
       "      <td>0.090630</td>\n",
       "      <td>0.084550</td>\n",
       "      <td>0.10706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall@5</th>\n",
       "      <td>0.108830</td>\n",
       "      <td>0.101320</td>\n",
       "      <td>0.12936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall@10</th>\n",
       "      <td>0.139960</td>\n",
       "      <td>0.131930</td>\n",
       "      <td>0.16009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall@100</th>\n",
       "      <td>0.266360</td>\n",
       "      <td>0.262240</td>\n",
       "      <td>0.28271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall@1000</th>\n",
       "      <td>0.578160</td>\n",
       "      <td>0.559680</td>\n",
       "      <td>0.49210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P@1</th>\n",
       "      <td>0.402480</td>\n",
       "      <td>0.402480</td>\n",
       "      <td>0.48916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P@3</th>\n",
       "      <td>0.324050</td>\n",
       "      <td>0.318890</td>\n",
       "      <td>0.38493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P@5</th>\n",
       "      <td>0.277400</td>\n",
       "      <td>0.266870</td>\n",
       "      <td>0.32384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P@10</th>\n",
       "      <td>0.218270</td>\n",
       "      <td>0.213930</td>\n",
       "      <td>0.24272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P@100</th>\n",
       "      <td>0.067800</td>\n",
       "      <td>0.064610</td>\n",
       "      <td>0.07480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P@1000</th>\n",
       "      <td>0.018890</td>\n",
       "      <td>0.018310</td>\n",
       "      <td>0.01434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average Query Time (ms/it)</th>\n",
       "      <td>7.597585</td>\n",
       "      <td>7.196279</td>\n",
       "      <td>9.39000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total Query Time (s)</th>\n",
       "      <td>2.454020</td>\n",
       "      <td>2.324398</td>\n",
       "      <td>3.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total Document Embedding Time (s)</th>\n",
       "      <td>7.395014</td>\n",
       "      <td>7.668651</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Baseline SBERT  \\\n",
       "NDCG@1                                   0.388540   \n",
       "NDCG@3                                   0.348380   \n",
       "NDCG@5                                   0.324230   \n",
       "NDCG@10                                  0.296740   \n",
       "NDCG@100                                 0.266600   \n",
       "NDCG@1000                                0.350880   \n",
       "MAP@1                                    0.050240   \n",
       "MAP@3                                    0.079710   \n",
       "MAP@5                                    0.091500   \n",
       "MAP@10                                   0.105330   \n",
       "MAP@100                                  0.129700   \n",
       "MAP@1000                                 0.141630   \n",
       "Recall@1                                 0.050240   \n",
       "Recall@3                                 0.090630   \n",
       "Recall@5                                 0.108830   \n",
       "Recall@10                                0.139960   \n",
       "Recall@100                               0.266360   \n",
       "Recall@1000                              0.578160   \n",
       "P@1                                      0.402480   \n",
       "P@3                                      0.324050   \n",
       "P@5                                      0.277400   \n",
       "P@10                                     0.218270   \n",
       "P@100                                    0.067800   \n",
       "P@1000                                   0.018890   \n",
       "Average Query Time (ms/it)               7.597585   \n",
       "Total Query Time (s)                     2.454020   \n",
       "Total Document Embedding Time (s)        7.395014   \n",
       "\n",
       "                                   multi-qa-MiniLM-L6-cos-v1_ft  \\\n",
       "NDCG@1                                                 0.385450   \n",
       "NDCG@3                                                 0.339320   \n",
       "NDCG@5                                                 0.312470   \n",
       "NDCG@10                                                0.287040   \n",
       "NDCG@100                                               0.254110   \n",
       "NDCG@1000                                              0.335650   \n",
       "MAP@1                                                  0.041510   \n",
       "MAP@3                                                  0.071340   \n",
       "MAP@5                                                  0.082020   \n",
       "MAP@10                                                 0.096700   \n",
       "MAP@100                                                0.118850   \n",
       "MAP@1000                                               0.129740   \n",
       "Recall@1                                               0.041510   \n",
       "Recall@3                                               0.084550   \n",
       "Recall@5                                               0.101320   \n",
       "Recall@10                                              0.131930   \n",
       "Recall@100                                             0.262240   \n",
       "Recall@1000                                            0.559680   \n",
       "P@1                                                    0.402480   \n",
       "P@3                                                    0.318890   \n",
       "P@5                                                    0.266870   \n",
       "P@10                                                   0.213930   \n",
       "P@100                                                  0.064610   \n",
       "P@1000                                                 0.018310   \n",
       "Average Query Time (ms/it)                             7.196279   \n",
       "Total Query Time (s)                                   2.324398   \n",
       "Total Document Embedding Time (s)                      7.668651   \n",
       "\n",
       "                                   ColBERTv2 Baseline  \n",
       "NDCG@1                                        0.47214  \n",
       "NDCG@3                                        0.41224  \n",
       "NDCG@5                                        0.38223  \n",
       "NDCG@10                                       0.34323  \n",
       "NDCG@100                                      0.30330  \n",
       "NDCG@1000                                     0.35523  \n",
       "MAP@1                                         0.06371  \n",
       "MAP@3                                         0.10011  \n",
       "MAP@5                                         0.11375  \n",
       "MAP@10                                        0.12995  \n",
       "MAP@100                                       0.15842  \n",
       "MAP@1000                                      0.16677  \n",
       "Recall@1                                      0.06371  \n",
       "Recall@3                                      0.10706  \n",
       "Recall@5                                      0.12936  \n",
       "Recall@10                                     0.16009  \n",
       "Recall@100                                    0.28271  \n",
       "Recall@1000                                   0.49210  \n",
       "P@1                                           0.48916  \n",
       "P@3                                           0.38493  \n",
       "P@5                                           0.32384  \n",
       "P@10                                          0.24272  \n",
       "P@100                                         0.07480  \n",
       "P@1000                                        0.01434  \n",
       "Average Query Time (ms/it)                    9.39000  \n",
       "Total Query Time (s)                          3.00000  \n",
       "Total Document Embedding Time (s)                 NaN  "
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nfcorpus_results.all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finetuning ColBERTv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mfinetune_colbert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mexperiment_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcsv_file\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mreplace\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mnranks\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mbsize\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mlr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-05\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdoc_maxlen\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdim\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0maccumsteps\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0muse_ib_negatives\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcheckpoint\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'colbert-ir/colbertv2.0'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mroot_path\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'../models/'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mSource:\u001b[0m   \n",
       "\u001b[0;32mdef\u001b[0m \u001b[0mfinetune_colbert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperiment_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                     \u001b[0mcsv_file\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# containing at least 'pid', 'passage' and 'question' columns\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                     \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# overwrite the training files (triples.jsonl, {queries,collection}.tsv) previously generated\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                     \u001b[0mreplace\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# if True, will throw error if training files already exists\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                     \u001b[0mnranks\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# number of GPUs\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                     \u001b[0mbsize\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# batch size\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                     \u001b[0mlr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-05\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# learning rate\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                     \u001b[0mdoc_maxlen\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# max length for document\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                     \u001b[0mdim\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# dimension\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                     \u001b[0maccumsteps\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                     \u001b[0muse_ib_negatives\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                     \u001b[0mcheckpoint\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"colbert-ir/colbertv2.0\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# finetuning from colbertv2.0\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                     \u001b[0mroot_path\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"../models/\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# we will save checkpoints to \"../models/{experiment_name}\"                     \u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"\u001b[0m\n",
       "\u001b[0;34m    Finetunes colbert model from `checkpoint` with data from `csv_file`\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Returns best `checkpoint_path`\u001b[0m\n",
       "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mbeir_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBEIRDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtriples_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqueries_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollection_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbeir_datasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_qg_for_colbert_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mwith\u001b[0m \u001b[0mRun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRunConfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnranks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnranks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperiment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexperiment_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mColBERTConfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mbsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbsize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mexperiment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexperiment_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"{root_path}\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;31m# config = ColBERTConfig(checkpoint=checkpoint, bsize=bsize, lr=lr, warmup=None, nway=0, doc_maxlen=doc_maxlen, dim=dim, accumsteps=accumsteps, use_ib_negatives=use_ib_negatives)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mtriples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtriples_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mqueries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mqueries_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mcollection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollection_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mFile:\u001b[0m      /tmp/ipykernel_873496/965257086.py\n",
       "\u001b[0;31mType:\u001b[0m      function"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "??finetune_colbert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-01 18:37:14.683\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mzeroqaret.dataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1mDatasets will be saved in '/home/bengsoon/Projects/xcs224u_project/zeroqaret/datasets'\u001b[0m\n",
      "\u001b[32m2023-11-01 18:37:14.685\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprepare_qg_for_colbert_training\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mCreating ColBERT training files from ../datasets/nfcorpus/qg/colbert_training...\u001b[0m\n",
      "Training files: : 3633it [00:00, 22149.57it/s]\n",
      "\u001b[32m2023-11-01 18:37:14.934\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprepare_qg_for_colbert_training\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mtriples.jsonl, queries,tsv and collection.tsv files created in ../datasets/nfcorpus/qg/colbert_training.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#> Starting...\n",
      "nranks = 1 \t num_gpus = 1 \t device=0\n",
      "{\n",
      "    \"query_token_id\": \"[unused0]\",\n",
      "    \"doc_token_id\": \"[unused1]\",\n",
      "    \"query_token\": \"[Q]\",\n",
      "    \"doc_token\": \"[D]\",\n",
      "    \"ncells\": null,\n",
      "    \"centroid_score_threshold\": null,\n",
      "    \"ndocs\": null,\n",
      "    \"load_index_with_mmap\": false,\n",
      "    \"index_path\": null,\n",
      "    \"nbits\": 1,\n",
      "    \"kmeans_niters\": 4,\n",
      "    \"resume\": false,\n",
      "    \"similarity\": \"cosine\",\n",
      "    \"bsize\": 32,\n",
      "    \"accumsteps\": 1,\n",
      "    \"lr\": 3e-6,\n",
      "    \"maxsteps\": 500000,\n",
      "    \"save_every\": null,\n",
      "    \"warmup\": null,\n",
      "    \"warmup_bert\": null,\n",
      "    \"relu\": false,\n",
      "    \"nway\": 2,\n",
      "    \"use_ib_negatives\": false,\n",
      "    \"reranker\": false,\n",
      "    \"distillation_alpha\": 1.0,\n",
      "    \"ignore_scores\": false,\n",
      "    \"model_name\": null,\n",
      "    \"query_maxlen\": 32,\n",
      "    \"attend_to_mask_tokens\": false,\n",
      "    \"interaction\": \"colbert\",\n",
      "    \"dim\": 128,\n",
      "    \"doc_maxlen\": 220,\n",
      "    \"mask_punctuation\": true,\n",
      "    \"checkpoint\": \"colbert-ir\\/colbertv2.0\",\n",
      "    \"triples\": \"..\\/datasets\\/nfcorpus\\/qg\\/colbert_training\\/triples.jsonl\",\n",
      "    \"collection\": \"..\\/datasets\\/nfcorpus\\/qg\\/colbert_training\\/collection.tsv\",\n",
      "    \"queries\": \"..\\/datasets\\/nfcorpus\\/qg\\/colbert_training\\/queries.tsv\",\n",
      "    \"index_name\": null,\n",
      "    \"overwrite\": false,\n",
      "    \"root\": \"\\/home\\/bengsoon\\/Projects\\/xcs224u_project\\/zeroqaret\\/nbs\\/experiments\",\n",
      "    \"experiment\": \"default\",\n",
      "    \"index_root\": null,\n",
      "    \"name\": \"2023-10\\/31\\/12.41.13\",\n",
      "    \"rank\": 0,\n",
      "    \"nranks\": 1,\n",
      "    \"amp\": true,\n",
      "    \"gpus\": 1\n",
      "}\n",
      "Using config.bsize = 32 (per process) and config.accumsteps = 1\n",
      "[Nov 01, 18:37:18] #> Loading the queries from ../datasets/nfcorpus/qg/colbert_training/queries.tsv ...\n",
      "[Nov 01, 18:37:18] #> Got 3633 queries. All QIDs are unique.\n",
      "\n",
      "[Nov 01, 18:37:18] #> Loading collection...\n",
      "0M "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bengsoon/conda/envs/xcs224/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: .  Association of Statin Use with Breast Cancer Survival - What was the association between statin use and breast cancer survival in a population-based cohort of breast cancer patients from Finland?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2523,  1997, 28093,  2378,  2224,  2007,  7388,  4456,\n",
      "         7691,  1011,  2054,  2001,  1996,  2523,  2090, 28093,  2378,  2224,\n",
      "         1998,  7388,  4456,  7691,  1999,  1037,  2313,  1011,  2241,  2522,\n",
      "        27794,   102])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1])\n",
      "\n",
      "#>>>    24.1 8.38 \t\t|\t\t 15.72\n",
      "[Nov 01, 18:37:22] 0 2.2649578568234574e-06\n",
      "#>>>    24.3 8.53 \t\t|\t\t 15.770000000000001\n",
      "[Nov 01, 18:37:22] 1 2.264250058942707e-06\n",
      "#>>>    24.44 9.95 \t\t|\t\t 14.490000000000002\n",
      "[Nov 01, 18:37:23] 2 2.3017967130108445e-06\n",
      "#>>>    24.88 8.7 \t\t|\t\t 16.18\n",
      "[Nov 01, 18:37:23] 3 2.3002511484662756e-06\n",
      "#>>>    25.35 9.05 \t\t|\t\t 16.3\n",
      "[Nov 01, 18:37:23] 4 2.2993031633716093e-06\n",
      "#>>>    23.73 8.87 \t\t|\t\t 14.860000000000001\n",
      "[Nov 01, 18:37:24] 5 4.771768222185817e-06\n",
      "#>>>    23.05 8.93 \t\t|\t\t 14.120000000000001\n",
      "[Nov 01, 18:37:24] 6 3.734001840230121e-05\n",
      "#>>>    23.87 7.6 \t\t|\t\t 16.270000000000003\n",
      "[Nov 01, 18:37:24] 7 4.404198045657295e-05\n",
      "#>>>    23.9 9.65 \t\t|\t\t 14.249999999999998\n",
      "[Nov 01, 18:37:25] 8 4.4021874290286195e-05\n",
      "#>>>    24.46 8.73 \t\t|\t\t 15.73\n",
      "[Nov 01, 18:37:25] 9 4.3981242358772175e-05\n",
      "#>>>    24.85 9.56 \t\t|\t\t 15.290000000000001\n",
      "[Nov 01, 18:37:25] 10 4.404744909163751e-05\n",
      "#>>>    24.43 9.03 \t\t|\t\t 15.4\n",
      "[Nov 01, 18:37:26] 11 4.400853116310529e-05\n",
      "#>>>    24.55 9.59 \t\t|\t\t 14.96\n",
      "[Nov 01, 18:37:26] 12 4.408440776336788e-05\n",
      "#>>>    24.33 9.06 \t\t|\t\t 15.269999999999998\n",
      "[Nov 01, 18:37:26] 13 4.40449872712653e-05\n",
      "#>>>    24.92 9.39 \t\t|\t\t 15.530000000000001\n",
      "[Nov 01, 18:37:27] 14 4.400296509980044e-05\n",
      "#>>>    23.5 8.59 \t\t|\t\t 14.91\n",
      "[Nov 01, 18:37:27] 15 4.400038839600552e-05\n",
      "#>>>    23.93 9.87 \t\t|\t\t 14.06\n",
      "[Nov 01, 18:37:27] 16 4.410196621156519e-05\n",
      "#>>>    24.34 8.64 \t\t|\t\t 15.7\n",
      "[Nov 01, 18:37:28] 17 4.4060613456843193e-05\n",
      "#>>>    23.82 8.71 \t\t|\t\t 15.11\n",
      "[Nov 01, 18:37:28] 18 4.402669237235391e-05\n",
      "#>>>    24.58 8.8 \t\t|\t\t 15.779999999999998\n",
      "[Nov 01, 18:37:28] 19 4.3989463678121074e-05\n",
      "#>>>    24.78 8.82 \t\t|\t\t 15.96\n",
      "[Nov 01, 18:37:29] 20 4.395163922245994e-05\n",
      "#>>>    24.25 9.27 \t\t|\t\t 14.98\n",
      "[Nov 01, 18:37:29] 21 4.392209575919469e-05\n",
      "#>>>    24.87 9.28 \t\t|\t\t 15.590000000000002\n",
      "[Nov 01, 18:37:29] 22 4.388018530519e-05\n",
      "#>>>    24.3 9.21 \t\t|\t\t 15.09\n",
      "[Nov 01, 18:37:30] 23 4.38397621356216e-05\n",
      "#>>>    24.22 9.49 \t\t|\t\t 14.729999999999999\n",
      "[Nov 01, 18:37:30] 24 4.3805302308849515e-05\n",
      "#>>>    23.91 9.39 \t\t|\t\t 14.52\n",
      "[Nov 01, 18:37:30] 25 4.376378804916028e-05\n",
      "#>>>    24.46 8.51 \t\t|\t\t 15.950000000000001\n",
      "[Nov 01, 18:37:31] 26 4.372169317990983e-05\n",
      "#>>>    24.25 9.97 \t\t|\t\t 14.28\n",
      "[Nov 01, 18:37:31] 27 4.37262778026053e-05\n",
      "#>>>    24.15 8.51 \t\t|\t\t 15.639999999999999\n",
      "[Nov 01, 18:37:31] 28 4.368411614013421e-05\n",
      "#>>>    24.34 8.83 \t\t|\t\t 15.51\n",
      "[Nov 01, 18:37:32] 29 4.3642231329090106e-05\n",
      "#>>>    24.19 8.89 \t\t|\t\t 15.3\n",
      "[Nov 01, 18:37:32] 30 4.36013494953533e-05\n",
      "#>>>    24.35 8.65 \t\t|\t\t 15.700000000000001\n",
      "[Nov 01, 18:37:32] 31 4.35650194559542e-05\n",
      "#>>>    23.96 8.48 \t\t|\t\t 15.48\n",
      "[Nov 01, 18:37:33] 32 4.352385350048572e-05\n",
      "#>>>    24.27 8.65 \t\t|\t\t 15.62\n",
      "[Nov 01, 18:37:33] 33 4.354640862802062e-05\n",
      "#>>>    24.26 8.57 \t\t|\t\t 15.690000000000001\n",
      "[Nov 01, 18:37:34] 34 4.3503864318503846e-05\n",
      "#>>>    24.69 9.28 \t\t|\t\t 15.410000000000002\n",
      "[Nov 01, 18:37:34] 35 4.346515099197224e-05\n",
      "#>>>    24.19 9.27 \t\t|\t\t 14.920000000000002\n",
      "[Nov 01, 18:37:34] 36 4.3425213633367376e-05\n",
      "#>>>    25.17 8.85 \t\t|\t\t 16.32\n",
      "[Nov 01, 18:37:35] 37 4.338235838733068e-05\n",
      "#>>>    24.67 9.08 \t\t|\t\t 15.590000000000002\n",
      "[Nov 01, 18:37:35] 38 4.3339695007981436e-05\n",
      "#>>>    24.33 8.85 \t\t|\t\t 15.479999999999999\n",
      "[Nov 01, 18:37:35] 39 4.3304494506569886e-05\n",
      "#>>>    23.95 8.34 \t\t|\t\t 15.61\n",
      "[Nov 01, 18:37:36] 40 4.328363713074448e-05\n",
      "#>>>    24.32 8.82 \t\t|\t\t 15.5\n",
      "[Nov 01, 18:37:36] 41 4.3241422649314596e-05\n",
      "#>>>    24.61 10.22 \t\t|\t\t 14.389999999999999\n",
      "[Nov 01, 18:37:36] 42 4.320125084768132e-05\n",
      "#>>>    24.02 9.55 \t\t|\t\t 14.469999999999999\n",
      "[Nov 01, 18:37:37] 43 4.320656495460926e-05\n",
      "#>>>    23.63 8.8 \t\t|\t\t 14.829999999999998\n",
      "[Nov 01, 18:37:37] 44 4.3167534342763296e-05\n",
      "#>>>    24.24 9.79 \t\t|\t\t 14.45\n",
      "[Nov 01, 18:37:37] 45 4.313107953142732e-05\n",
      "#>>>    24.4 8.88 \t\t|\t\t 15.519999999999998\n",
      "[Nov 01, 18:37:38] 46 4.309600204657948e-05\n",
      "#>>>    24.56 9.36 \t\t|\t\t 15.2\n",
      "[Nov 01, 18:37:38] 47 4.305422851849612e-05\n",
      "#>>>    24.45 9.11 \t\t|\t\t 15.34\n",
      "[Nov 01, 18:37:38] 48 4.3012239720160817e-05\n",
      "#>>>    24.63 9.44 \t\t|\t\t 15.19\n",
      "[Nov 01, 18:37:39] 49 4.2974461358695895e-05\n",
      "#>>>    23.93 8.32 \t\t|\t\t 15.61\n",
      "[Nov 01, 18:37:39] 50 4.295439771825408e-05\n",
      "#>>>    24.27 8.36 \t\t|\t\t 15.91\n",
      "[Nov 01, 18:37:39] 51 4.291302655538394e-05\n",
      "#>>>    24.31 9.17 \t\t|\t\t 15.139999999999999\n",
      "[Nov 01, 18:37:40] 52 4.287397660029837e-05\n",
      "#>>>    24.3 8.77 \t\t|\t\t 15.530000000000001\n",
      "[Nov 01, 18:37:40] 53 4.283341973266322e-05\n",
      "#>>>    23.6 8.63 \t\t|\t\t 14.97\n",
      "[Nov 01, 18:37:40] 54 4.2793871980547645e-05\n",
      "#>>>    24.28 8.81 \t\t|\t\t 15.47\n",
      "[Nov 01, 18:37:41] 55 4.2751845516606434e-05\n",
      "#>>>    24.83 9.21 \t\t|\t\t 15.619999999999997\n",
      "[Nov 01, 18:37:41] 56 4.2742872537144314e-05\n",
      "#>>>    24.62 9.06 \t\t|\t\t 15.56\n",
      "[Nov 01, 18:37:41] 57 4.270198857491641e-05\n",
      "#>>>    24.46 9.64 \t\t|\t\t 14.82\n",
      "[Nov 01, 18:37:42] 58 4.266561569448751e-05\n",
      "#>>>    24.53 9.34 \t\t|\t\t 15.190000000000001\n",
      "[Nov 01, 18:37:42] 59 4.2628288253353186e-05\n",
      "#>>>    24.58 8.92 \t\t|\t\t 15.659999999999998\n",
      "[Nov 01, 18:37:42] 60 4.26006809076554e-05\n",
      "#>>>    23.97 8.4 \t\t|\t\t 15.569999999999999\n",
      "[Nov 01, 18:37:43] 61 4.255973051545699e-05\n",
      "#>>>    24.87 8.57 \t\t|\t\t 16.3\n",
      "[Nov 01, 18:37:43] 62 4.25183740444993e-05\n",
      "#>>>    24.35 9.19 \t\t|\t\t 15.160000000000002\n",
      "[Nov 01, 18:37:43] 63 4.2483253524460634e-05\n",
      "#>>>    24.32 8.79 \t\t|\t\t 15.530000000000001\n",
      "[Nov 01, 18:37:44] 64 4.2538219914298955e-05\n",
      "#>>>    24.06 9.28 \t\t|\t\t 14.78\n",
      "[Nov 01, 18:37:44] 65 4.250200327373353e-05\n",
      "#>>>    24.69 8.81 \t\t|\t\t 15.88\n",
      "[Nov 01, 18:37:45] 66 4.24703785360547e-05\n",
      "#>>>    25.03 9.22 \t\t|\t\t 15.81\n",
      "[Nov 01, 18:37:45] 67 4.242851165392172e-05\n",
      "#>>>    24.0 9.2 \t\t|\t\t 14.8\n",
      "[Nov 01, 18:37:45] 68 4.239789539751995e-05\n",
      "#>>>    24.61 8.33 \t\t|\t\t 16.28\n",
      "[Nov 01, 18:37:46] 69 4.2358157326426345e-05\n",
      "#>>>    24.86 8.7 \t\t|\t\t 16.16\n",
      "[Nov 01, 18:37:46] 70 4.2317523966570986e-05\n",
      "#>>>    24.44 9.14 \t\t|\t\t 15.3\n",
      "[Nov 01, 18:37:46] 71 4.2278719333148207e-05\n",
      "#>>>    23.96 9.04 \t\t|\t\t 14.920000000000002\n",
      "[Nov 01, 18:37:47] 72 4.223897378916277e-05\n",
      "#>>>    25.04 10.09 \t\t|\t\t 14.95\n",
      "[Nov 01, 18:37:47] 73 4.226622646063665e-05\n",
      "#>>>    24.06 9.41 \t\t|\t\t 14.649999999999999\n",
      "[Nov 01, 18:37:47] 74 4.2232013759738e-05\n",
      "#>>>    24.2 8.66 \t\t|\t\t 15.54\n",
      "[Nov 01, 18:37:48] 75 4.219114519517892e-05\n",
      "#>>>    24.17 9.06 \t\t|\t\t 15.110000000000001\n",
      "[Nov 01, 18:37:48] 76 4.215365898612932e-05\n",
      "#>>>    23.68 9.99 \t\t|\t\t 13.69\n",
      "[Nov 01, 18:37:48] 77 4.2182723957325746e-05\n",
      "#>>>    24.5 8.83 \t\t|\t\t 15.67\n",
      "[Nov 01, 18:37:49] 78 4.2141792926929664e-05\n",
      "#>>>    24.85 9.05 \t\t|\t\t 15.8\n",
      "[Nov 01, 18:37:49] 79 4.2101517488980855e-05\n",
      "#>>>    24.55 9.21 \t\t|\t\t 15.34\n",
      "[Nov 01, 18:37:49] 80 4.210129178147592e-05\n",
      "#>>>    23.94 9.29 \t\t|\t\t 14.650000000000002\n",
      "[Nov 01, 18:37:50] 81 4.207403468741613e-05\n",
      "#>>>    24.13 8.75 \t\t|\t\t 15.379999999999999\n",
      "[Nov 01, 18:37:50] 82 4.2033309202246105e-05\n",
      "#>>>    24.23 8.64 \t\t|\t\t 15.59\n",
      "[Nov 01, 18:37:50] 83 4.2021083596002214e-05\n",
      "#>>>    24.4 8.71 \t\t|\t\t 15.689999999999998\n",
      "[Nov 01, 18:37:51] 84 4.202436119478645e-05\n",
      "#>>>    24.69 9.42 \t\t|\t\t 15.270000000000001\n",
      "[Nov 01, 18:37:51] 85 4.1990841250247004e-05\n",
      "#>>>    24.25 8.44 \t\t|\t\t 15.81\n",
      "[Nov 01, 18:37:51] 86 4.195129043958145e-05\n",
      "#>>>    24.26 9.02 \t\t|\t\t 15.240000000000002\n",
      "[Nov 01, 18:37:52] 87 4.1918792862715614e-05\n",
      "#>>>    24.69 9.24 \t\t|\t\t 15.450000000000001\n",
      "[Nov 01, 18:37:52] 88 4.18828492094822e-05\n",
      "#>>>    24.97 8.55 \t\t|\t\t 16.419999999999998\n",
      "[Nov 01, 18:37:52] 89 4.184145809790999e-05\n",
      "#>>>    25.35 9.1 \t\t|\t\t 16.25\n",
      "[Nov 01, 18:37:53] 90 4.181422771585181e-05\n",
      "#>>>    24.36 9.56 \t\t|\t\t 14.799999999999999\n",
      "[Nov 01, 18:37:53] 91 4.177860475417447e-05\n",
      "#>>>    24.38 8.29 \t\t|\t\t 16.09\n",
      "[Nov 01, 18:37:53] 92 4.1741013247477014e-05\n",
      "#>>>    24.24 8.67 \t\t|\t\t 15.569999999999999\n",
      "[Nov 01, 18:37:54] 93 4.1709113843655616e-05\n",
      "#>>>    24.74 9.21 \t\t|\t\t 15.529999999999998\n",
      "[Nov 01, 18:37:54] 94 4.221979758556422e-05\n",
      "#>>>    24.56 8.94 \t\t|\t\t 15.62\n",
      "[Nov 01, 18:37:54] 95 4.2182007043092445e-05\n",
      "#>>>    24.6 8.78 \t\t|\t\t 15.820000000000002\n",
      "[Nov 01, 18:37:55] 96 4.2141240641360546e-05\n",
      "#>>>    24.02 9.37 \t\t|\t\t 14.65\n",
      "[Nov 01, 18:37:55] 97 4.210302581349277e-05\n",
      "#>>>    24.2 8.81 \t\t|\t\t 15.389999999999999\n",
      "[Nov 01, 18:37:55] 98 4.206452503903337e-05\n",
      "#>>>    25.02 9.47 \t\t|\t\t 15.549999999999999\n",
      "[Nov 01, 18:37:56] 99 6.322961431114401e-05\n",
      "#>>>    24.68 8.33 \t\t|\t\t 16.35\n",
      "[Nov 01, 18:37:56] 100 6.316674977496948e-05\n",
      "#>>>    24.14 9.3 \t\t|\t\t 14.84\n",
      "[Nov 01, 18:37:56] 101 6.310660047623021e-05\n",
      "#>>>    24.34 8.52 \t\t|\t\t 15.82\n",
      "[Nov 01, 18:37:57] 102 6.31077184916799e-05\n",
      "#>>>    23.74 8.43 \t\t|\t\t 15.309999999999999\n",
      "[Nov 01, 18:37:57] 103 6.44358517508704e-05\n",
      "#>>>    24.35 9.16 \t\t|\t\t 15.190000000000001\n",
      "[Nov 01, 18:37:57] 104 6.438088850289824e-05\n",
      "#>>>    24.21 8.97 \t\t|\t\t 15.24\n",
      "[Nov 01, 18:37:58] 105 6.434118733156659e-05\n",
      "#>>>    24.69 9.18 \t\t|\t\t 15.510000000000002\n",
      "[Nov 01, 18:37:58] 106 6.427940910007725e-05\n",
      "#>>>    24.64 9.27 \t\t|\t\t 15.370000000000001\n",
      "[Nov 01, 18:37:59] 107 6.422006546779199e-05\n",
      "#>>>    24.65 9.28 \t\t|\t\t 15.37\n",
      "[Nov 01, 18:37:59] 108 6.416037145541384e-05\n",
      "#>>>    24.52 8.82 \t\t|\t\t 15.7\n",
      "[Nov 01, 18:37:59] 109 6.409951164796186e-05\n",
      "#>>>    24.68 9.06 \t\t|\t\t 15.62\n",
      "[Nov 01, 18:38:00] 110 6.404028845855056e-05\n",
      "#>>>    24.06 9.14 \t\t|\t\t 14.919999999999998\n",
      "[Nov 01, 18:38:00] 111 6.397819276230548e-05\n",
      "#>>>    24.62 9.19 \t\t|\t\t 15.430000000000001\n",
      "[Nov 01, 18:38:00] 112 6.391628581753407e-05\n",
      "[Nov 01, 18:38:00] #> Done with all triples!\n",
      "#> Saving a checkpoint to /home/bengsoon/Projects/xcs224u_project/zeroqaret/nbs/experiments/default/none/2023-10/31/12.41.13/checkpoints/colbert ..\n",
      "#> Joined...\n"
     ]
    }
   ],
   "source": [
    "finetune_colbert(experiment_name=f\"{dataset_name}_colbertv2_finetuned\",\n",
    "                          csv_file=f\"../datasets/{dataset_name}/qg/{dataset_name}_qg_all.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[Nov 01, 19:02:33] #> Creating directory /home/bengsoon/Projects/xcs224u_project/zeroqaret/nbs/experiments/nfcorpus_colbertv2_ft/indexes/nfcorpus.2bits \n",
      "\n",
      "\n",
      "#> Starting...\n",
      "nranks = 1 \t num_gpus = 1 \t device=0\n",
      "{\n",
      "    \"query_token_id\": \"[unused0]\",\n",
      "    \"doc_token_id\": \"[unused1]\",\n",
      "    \"query_token\": \"[Q]\",\n",
      "    \"doc_token\": \"[D]\",\n",
      "    \"ncells\": null,\n",
      "    \"centroid_score_threshold\": null,\n",
      "    \"ndocs\": null,\n",
      "    \"load_index_with_mmap\": false,\n",
      "    \"index_path\": null,\n",
      "    \"nbits\": 2,\n",
      "    \"kmeans_niters\": 4,\n",
      "    \"resume\": false,\n",
      "    \"similarity\": \"cosine\",\n",
      "    \"bsize\": 64,\n",
      "    \"accumsteps\": 1,\n",
      "    \"lr\": 3e-6,\n",
      "    \"maxsteps\": 500000,\n",
      "    \"save_every\": null,\n",
      "    \"warmup\": null,\n",
      "    \"warmup_bert\": null,\n",
      "    \"relu\": false,\n",
      "    \"nway\": 2,\n",
      "    \"use_ib_negatives\": false,\n",
      "    \"reranker\": false,\n",
      "    \"distillation_alpha\": 1.0,\n",
      "    \"ignore_scores\": false,\n",
      "    \"model_name\": null,\n",
      "    \"query_maxlen\": 32,\n",
      "    \"attend_to_mask_tokens\": false,\n",
      "    \"interaction\": \"colbert\",\n",
      "    \"dim\": 128,\n",
      "    \"doc_maxlen\": 300,\n",
      "    \"mask_punctuation\": true,\n",
      "    \"checkpoint\": \"\\/home\\/bengsoon\\/Projects\\/xcs224u_project\\/zeroqaret\\/nbs\\/experiments\\/default\\/none\\/2023-10\\/31\\/12.41.13\\/checkpoints\\/colbert\",\n",
      "    \"triples\": \"..\\/datasets\\/nfcorpus\\/qg\\/colbert_training\\/triples.jsonl\",\n",
      "    \"collection\": \"\\/home\\/bengsoon\\/Projects\\/xcs224u_project\\/zeroqaret\\/datasets\\/nfcorpus\\/colbert\\/nfcorpus_collection.tsv\",\n",
      "    \"queries\": \"..\\/datasets\\/nfcorpus\\/qg\\/colbert_training\\/queries.tsv\",\n",
      "    \"index_name\": \"nfcorpus.2bits\",\n",
      "    \"overwrite\": false,\n",
      "    \"root\": \"\\/home\\/bengsoon\\/Projects\\/xcs224u_project\\/zeroqaret\\/nbs\\/experiments\",\n",
      "    \"experiment\": \"nfcorpus_colbertv2_ft\",\n",
      "    \"index_root\": null,\n",
      "    \"name\": \"2023-10\\/31\\/12.41.13\",\n",
      "    \"rank\": 0,\n",
      "    \"nranks\": 1,\n",
      "    \"amp\": true,\n",
      "    \"gpus\": 1\n",
      "}\n",
      "[Nov 01, 19:02:38] [0] \t\t # of sampled PIDs = 3633 \t sampled_pids[:3] = [1706, 3001, 41]\n",
      "[Nov 01, 19:02:38] [0] \t\t #> Encoding 3633 passages..\n",
      "[Nov 01, 19:02:46] [0] \t\t avg_doclen_est = 235.5755615234375 \t len(local_sample) = 3,633\n",
      "[Nov 01, 19:02:46] [0] \t\t Creaing 8,192 partitions.\n",
      "[Nov 01, 19:02:46] [0] \t\t *Estimated* 855,846 embeddings.\n",
      "[Nov 01, 19:02:46] [0] \t\t #> Saving the indexing plan to /home/bengsoon/Projects/xcs224u_project/zeroqaret/nbs/experiments/nfcorpus_colbertv2_ft/indexes/nfcorpus.2bits/plan.json ..\n",
      "Clustering 813054 points in 128D to 8192 clusters, redo 1 times, 4 iterations\n",
      "  Preprocessing in 0.06 s\n",
      "  Iteration 3 (1.04 s, search 0.94 s): objective=195714 imbalance=1.356 nsplit=0       \n",
      "[Nov 01, 19:02:48] Loading decompress_residuals_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n",
      "[Nov 01, 19:02:48] Loading packbits_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n",
      "[0.032, 0.037, 0.035, 0.033, 0.034, 0.035, 0.037, 0.032, 0.031, 0.034, 0.033, 0.033, 0.036, 0.037, 0.033, 0.035, 0.031, 0.034, 0.032, 0.033, 0.034, 0.035, 0.033, 0.035, 0.033, 0.032, 0.037, 0.034, 0.032, 0.038, 0.033, 0.038, 0.036, 0.034, 0.034, 0.032, 0.039, 0.036, 0.033, 0.041, 0.034, 0.034, 0.034, 0.035, 0.033, 0.034, 0.035, 0.039, 0.035, 0.033, 0.032, 0.035, 0.035, 0.033, 0.033, 0.035, 0.043, 0.034, 0.039, 0.035, 0.034, 0.036, 0.035, 0.039, 0.036, 0.035, 0.035, 0.038, 0.033, 0.034, 0.037, 0.032, 0.033, 0.036, 0.034, 0.038, 0.035, 0.035, 0.035, 0.038, 0.035, 0.034, 0.035, 0.038, 0.031, 0.034, 0.033, 0.037, 0.032, 0.038, 0.033, 0.038, 0.034, 0.034, 0.035, 0.037, 0.04, 0.035, 0.034, 0.034, 0.037, 0.039, 0.036, 0.034, 0.035, 0.034, 0.034, 0.034, 0.035, 0.033, 0.035, 0.036, 0.035, 0.031, 0.035, 0.035, 0.033, 0.033, 0.035, 0.035, 0.033, 0.035, 0.036, 0.036, 0.033, 0.035, 0.034, 0.034]\n",
      "[Nov 01, 19:02:48] #> Got bucket_cutoffs_quantiles = tensor([0.2500, 0.5000, 0.7500], device='cuda:0') and bucket_weights_quantiles = tensor([0.1250, 0.3750, 0.6250, 0.8750], device='cuda:0')\n",
      "[Nov 01, 19:02:48] #> Got bucket_cutoffs = tensor([-0.0275,  0.0002,  0.0279], device='cuda:0') and bucket_weights = tensor([-0.0488, -0.0127,  0.0130,  0.0493], device='cuda:0')\n",
      "[Nov 01, 19:02:48] avg_residual = 0.0347900390625\n",
      "[Nov 01, 19:02:48] [0] \t\t #> Encoding 3633 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Nov 01, 19:02:56] [0] \t\t #> Saving chunk 0: \t 3,633 passages and 855,846 embeddings. From #0 onward.\n",
      "[Nov 01, 19:02:56] [0] \t\t #> Checking all files were saved...\n",
      "[Nov 01, 19:02:56] [0] \t\t Found all files!\n",
      "[Nov 01, 19:02:56] [0] \t\t #> Building IVF...\n",
      "[Nov 01, 19:02:56] [0] \t\t #> Loading codes...\n",
      "[Nov 01, 19:02:56] [0] \t\t Sorting codes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:08,  8.17s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00, 728.94it/s]\n",
      "100%|██████████| 8192/8192 [00:00<00:00, 86335.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Nov 01, 19:02:56] [0] \t\t Getting unique codes...\n",
      "[Nov 01, 19:02:56] #> Optimizing IVF to store map from centroids to list of pids..\n",
      "[Nov 01, 19:02:56] #> Building the emb2pid mapping..\n",
      "[Nov 01, 19:02:56] len(emb2pid) = 855846\n",
      "[Nov 01, 19:02:57] #> Saved optimized IVF to /home/bengsoon/Projects/xcs224u_project/zeroqaret/nbs/experiments/nfcorpus_colbertv2_ft/indexes/nfcorpus.2bits/ivf.pid.pt\n",
      "[Nov 01, 19:02:57] [0] \t\t #> Saving the indexing metadata to /home/bengsoon/Projects/xcs224u_project/zeroqaret/nbs/experiments/nfcorpus_colbertv2_ft/indexes/nfcorpus.2bits/metadata.json ..\n",
      "#> Joined...\n",
      "[Nov 01, 19:02:58] #> Loading codec...\n",
      "[Nov 01, 19:02:58] #> Loading IVF...\n",
      "[Nov 01, 19:02:58] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1517.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Nov 01, 19:02:58] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 92.66it/s]\n"
     ]
    }
   ],
   "source": [
    "checkpoint = '/home/bengsoon/Projects/xcs224u_project/zeroqaret/nbs/experiments/default/none/2023-10/31/12.41.13/checkpoints/colbert'\n",
    "\n",
    "\n",
    "colbert_model_ft = ColBERTRetrievalSearch(checkpoint, \n",
    "                                   index_name, \n",
    "                                   experiment_name=f\"{dataset_name}_colbertv2_ft\", \n",
    "                                   collection=collection, \n",
    "                                   collection_ids=collection_ids,\n",
    "                                   doc_maxlen=doc_maxlen, \n",
    "                                   nbits=nbits, \n",
    "                                   overwrite_param=\"reuse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "323it [00:02, 117.89it/s]\n"
     ]
    }
   ],
   "source": [
    "colbert_retriever_ft = EvaluateRetrieval(colbert_model_ft)\n",
    "results = colbert_retriever_ft.retrieve(collection, queries)\n",
    "\n",
    "# the keys in results need to be converted back to original qids\n",
    "results = {queries_ids[int(k)]:v   for k, v in results.items()}\n",
    "\n",
    "colbert_retriever_ft.qrels = qrels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "nfcorpus_results.collect(\"ColBERTv2_ft\", retriever, results, {'Average Query Time (ms/it)': 8.48, 'Total Query Time (s)': 2.0, 'Total Document Embedding Time (s)': None})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Baseline SBERT</th>\n",
       "      <th>multi-qa-MiniLM-L6-cos-v1_ft</th>\n",
       "      <th>ColBERTv2 Baseline</th>\n",
       "      <th>ColBERTv2_ft</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NDCG@1</th>\n",
       "      <td>0.388540</td>\n",
       "      <td>0.385450</td>\n",
       "      <td>0.47214</td>\n",
       "      <td>0.47214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NDCG@3</th>\n",
       "      <td>0.348380</td>\n",
       "      <td>0.339320</td>\n",
       "      <td>0.41224</td>\n",
       "      <td>0.40997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NDCG@5</th>\n",
       "      <td>0.324230</td>\n",
       "      <td>0.312470</td>\n",
       "      <td>0.38223</td>\n",
       "      <td>0.38063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NDCG@10</th>\n",
       "      <td>0.296740</td>\n",
       "      <td>0.287040</td>\n",
       "      <td>0.34323</td>\n",
       "      <td>0.34277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NDCG@100</th>\n",
       "      <td>0.266600</td>\n",
       "      <td>0.254110</td>\n",
       "      <td>0.30330</td>\n",
       "      <td>0.30339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NDCG@1000</th>\n",
       "      <td>0.350880</td>\n",
       "      <td>0.335650</td>\n",
       "      <td>0.35523</td>\n",
       "      <td>0.35371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAP@1</th>\n",
       "      <td>0.050240</td>\n",
       "      <td>0.041510</td>\n",
       "      <td>0.06371</td>\n",
       "      <td>0.06340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAP@3</th>\n",
       "      <td>0.079710</td>\n",
       "      <td>0.071340</td>\n",
       "      <td>0.10011</td>\n",
       "      <td>0.09915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAP@5</th>\n",
       "      <td>0.091500</td>\n",
       "      <td>0.082020</td>\n",
       "      <td>0.11375</td>\n",
       "      <td>0.11327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAP@10</th>\n",
       "      <td>0.105330</td>\n",
       "      <td>0.096700</td>\n",
       "      <td>0.12995</td>\n",
       "      <td>0.12969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAP@100</th>\n",
       "      <td>0.129700</td>\n",
       "      <td>0.118850</td>\n",
       "      <td>0.15842</td>\n",
       "      <td>0.15824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAP@1000</th>\n",
       "      <td>0.141630</td>\n",
       "      <td>0.129740</td>\n",
       "      <td>0.16677</td>\n",
       "      <td>0.16640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall@1</th>\n",
       "      <td>0.050240</td>\n",
       "      <td>0.041510</td>\n",
       "      <td>0.06371</td>\n",
       "      <td>0.06340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall@3</th>\n",
       "      <td>0.090630</td>\n",
       "      <td>0.084550</td>\n",
       "      <td>0.10706</td>\n",
       "      <td>0.10508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall@5</th>\n",
       "      <td>0.108830</td>\n",
       "      <td>0.101320</td>\n",
       "      <td>0.12936</td>\n",
       "      <td>0.12896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall@10</th>\n",
       "      <td>0.139960</td>\n",
       "      <td>0.131930</td>\n",
       "      <td>0.16009</td>\n",
       "      <td>0.16050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall@100</th>\n",
       "      <td>0.266360</td>\n",
       "      <td>0.262240</td>\n",
       "      <td>0.28271</td>\n",
       "      <td>0.28333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall@1000</th>\n",
       "      <td>0.578160</td>\n",
       "      <td>0.559680</td>\n",
       "      <td>0.49210</td>\n",
       "      <td>0.48742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P@1</th>\n",
       "      <td>0.402480</td>\n",
       "      <td>0.402480</td>\n",
       "      <td>0.48916</td>\n",
       "      <td>0.48916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P@3</th>\n",
       "      <td>0.324050</td>\n",
       "      <td>0.318890</td>\n",
       "      <td>0.38493</td>\n",
       "      <td>0.38080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P@5</th>\n",
       "      <td>0.277400</td>\n",
       "      <td>0.266870</td>\n",
       "      <td>0.32384</td>\n",
       "      <td>0.32136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P@10</th>\n",
       "      <td>0.218270</td>\n",
       "      <td>0.213930</td>\n",
       "      <td>0.24272</td>\n",
       "      <td>0.24303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P@100</th>\n",
       "      <td>0.067800</td>\n",
       "      <td>0.064610</td>\n",
       "      <td>0.07480</td>\n",
       "      <td>0.07523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P@1000</th>\n",
       "      <td>0.018890</td>\n",
       "      <td>0.018310</td>\n",
       "      <td>0.01434</td>\n",
       "      <td>0.01419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average Query Time (ms/it)</th>\n",
       "      <td>7.597585</td>\n",
       "      <td>7.196279</td>\n",
       "      <td>9.39000</td>\n",
       "      <td>8.48000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total Query Time (s)</th>\n",
       "      <td>2.454020</td>\n",
       "      <td>2.324398</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>2.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total Document Embedding Time (s)</th>\n",
       "      <td>7.395014</td>\n",
       "      <td>7.668651</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Baseline SBERT  \\\n",
       "NDCG@1                                   0.388540   \n",
       "NDCG@3                                   0.348380   \n",
       "NDCG@5                                   0.324230   \n",
       "NDCG@10                                  0.296740   \n",
       "NDCG@100                                 0.266600   \n",
       "NDCG@1000                                0.350880   \n",
       "MAP@1                                    0.050240   \n",
       "MAP@3                                    0.079710   \n",
       "MAP@5                                    0.091500   \n",
       "MAP@10                                   0.105330   \n",
       "MAP@100                                  0.129700   \n",
       "MAP@1000                                 0.141630   \n",
       "Recall@1                                 0.050240   \n",
       "Recall@3                                 0.090630   \n",
       "Recall@5                                 0.108830   \n",
       "Recall@10                                0.139960   \n",
       "Recall@100                               0.266360   \n",
       "Recall@1000                              0.578160   \n",
       "P@1                                      0.402480   \n",
       "P@3                                      0.324050   \n",
       "P@5                                      0.277400   \n",
       "P@10                                     0.218270   \n",
       "P@100                                    0.067800   \n",
       "P@1000                                   0.018890   \n",
       "Average Query Time (ms/it)               7.597585   \n",
       "Total Query Time (s)                     2.454020   \n",
       "Total Document Embedding Time (s)        7.395014   \n",
       "\n",
       "                                   multi-qa-MiniLM-L6-cos-v1_ft  \\\n",
       "NDCG@1                                                 0.385450   \n",
       "NDCG@3                                                 0.339320   \n",
       "NDCG@5                                                 0.312470   \n",
       "NDCG@10                                                0.287040   \n",
       "NDCG@100                                               0.254110   \n",
       "NDCG@1000                                              0.335650   \n",
       "MAP@1                                                  0.041510   \n",
       "MAP@3                                                  0.071340   \n",
       "MAP@5                                                  0.082020   \n",
       "MAP@10                                                 0.096700   \n",
       "MAP@100                                                0.118850   \n",
       "MAP@1000                                               0.129740   \n",
       "Recall@1                                               0.041510   \n",
       "Recall@3                                               0.084550   \n",
       "Recall@5                                               0.101320   \n",
       "Recall@10                                              0.131930   \n",
       "Recall@100                                             0.262240   \n",
       "Recall@1000                                            0.559680   \n",
       "P@1                                                    0.402480   \n",
       "P@3                                                    0.318890   \n",
       "P@5                                                    0.266870   \n",
       "P@10                                                   0.213930   \n",
       "P@100                                                  0.064610   \n",
       "P@1000                                                 0.018310   \n",
       "Average Query Time (ms/it)                             7.196279   \n",
       "Total Query Time (s)                                   2.324398   \n",
       "Total Document Embedding Time (s)                      7.668651   \n",
       "\n",
       "                                   ColBERTv2 Baseline  ColBERTv2_ft  \n",
       "NDCG@1                                        0.47214       0.47214  \n",
       "NDCG@3                                        0.41224       0.40997  \n",
       "NDCG@5                                        0.38223       0.38063  \n",
       "NDCG@10                                       0.34323       0.34277  \n",
       "NDCG@100                                      0.30330       0.30339  \n",
       "NDCG@1000                                     0.35523       0.35371  \n",
       "MAP@1                                         0.06371       0.06340  \n",
       "MAP@3                                         0.10011       0.09915  \n",
       "MAP@5                                         0.11375       0.11327  \n",
       "MAP@10                                        0.12995       0.12969  \n",
       "MAP@100                                       0.15842       0.15824  \n",
       "MAP@1000                                      0.16677       0.16640  \n",
       "Recall@1                                      0.06371       0.06340  \n",
       "Recall@3                                      0.10706       0.10508  \n",
       "Recall@5                                      0.12936       0.12896  \n",
       "Recall@10                                     0.16009       0.16050  \n",
       "Recall@100                                    0.28271       0.28333  \n",
       "Recall@1000                                   0.49210       0.48742  \n",
       "P@1                                           0.48916       0.48916  \n",
       "P@3                                           0.38493       0.38080  \n",
       "P@5                                           0.32384       0.32136  \n",
       "P@10                                          0.24272       0.24303  \n",
       "P@100                                         0.07480       0.07523  \n",
       "P@1000                                        0.01434       0.01419  \n",
       "Average Query Time (ms/it)                    9.39000       8.48000  \n",
       "Total Query Time (s)                          3.00000       2.00000  \n",
       "Total Document Embedding Time (s)                 NaN           NaN  "
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nfcorpus_results.all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-01 19:05:21.985\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msave_as_csv\u001b[0m:\u001b[36m8\u001b[0m - \u001b[1mTable 'all' saved as '../datasets/nfcorpus/20231101_nfcorpus_results.csv'.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "nfcorpus_results.save_as_csv(f\"../datasets/{dataset_name}/20231101_{dataset_name}_results.csv\", \"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### all-mpnet-base-v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_emb = models.Transformer('sentence-transformers/all-mpnet-base-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "pooling = models.Pooling(word_emb.get_word_embedding_dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('all-mpnet-base-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = losses.MultipleNegativesRankingLoss(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73cb397732334a31a7bca3cb85f1c65d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37e8af69a8c746baaa083c5c2167903d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1295 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6319d0a39e2452ba0b956de9655865c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1295 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2003f036a6447ff8a981888874ea08d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1295 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tune the model\n",
    "num_epochs = 3\n",
    "warmup_steps = int(len(train_dataloader) * num_epochs * 0.1)\n",
    "model.fit(train_objectives=[(train_dataloader, train_loss)], epochs=num_epochs, warmup_steps=warmup_steps, show_progress_bar=True, checkpoint_path=\"../models/scifact_all_mpnetv2_ft\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"../models/scifact_all_mpnetv2_ft\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-10-31 12:24:57.778\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mzeroqaret.dataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1mDatasets will be saved in '/home/bengsoon/Projects/xcs224u_project/zeroqaret/datasets'\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "ft_retriever = SBERTEval(\"../models/scifact_all_mpnetv2_ft/\", normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-10-31 12:24:59.035\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mbeir_retrieval\u001b[0m:\u001b[36m13\u001b[0m - \u001b[1m\n",
      "   \n",
      "****************************************************************************************************   \n",
      "******                                                                                        ******   \n",
      "*                                     Evaluation for 'scifact'                                     *   \n",
      "******                                                                                        ******   \n",
      "****************************************************************************************************\n",
      "\u001b[0m\n",
      "\u001b[32m2023-10-31 12:24:59.037\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mzeroqaret.dataset\u001b[0m:\u001b[36mload_dataset\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1mDownloading dataset 'scifact'...\u001b[0m\n",
      "\u001b[32m2023-10-31 12:24:59.039\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mzeroqaret.dataset\u001b[0m:\u001b[36mload_dataset\u001b[0m:\u001b[36m65\u001b[0m - \u001b[1mSaved on '/home/bengsoon/Projects/xcs224u_project/zeroqaret/datasets/scifact'\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "758ac8f8c7104e61867a7357e5ef5020",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5183 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-10-31 12:24:59.100\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mbeir_retrieval\u001b[0m:\u001b[36m21\u001b[0m - \u001b[1mPre-computing Document Embeddings for 'scifact' dataset...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2811f3a2e3364d06b38f8f71b804afdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-10-31 12:25:37.090\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mbeir_retrieval\u001b[0m:\u001b[36m32\u001b[0m - \u001b[1mNumber of documents: 5183, Dim: 768\u001b[0m\n",
      "\u001b[32m2023-10-31 12:25:37.092\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mbeir_retrieval\u001b[0m:\u001b[36m33\u001b[0m - \u001b[1mIndex size (in MB): 15.92MB\u001b[0m\n",
      "\u001b[32m2023-10-31 12:25:37.093\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mbeir_retrieval\u001b[0m:\u001b[36m34\u001b[0m - \u001b[1mTime taken for pre-computing corpus embedding: 37.97 s\u001b[0m\n",
      "\u001b[32m2023-10-31 12:25:37.094\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mbeir_retrieval\u001b[0m:\u001b[36m35\u001b[0m - \u001b[1mPre-computing of Document Embeddings done.\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[32m2023-10-31 12:25:37.094\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mbeir_retrieval\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mStarting query benchmark evaluation ...\u001b[0m\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [00:04<00:00, 67.91it/s]\n",
      "\u001b[32m2023-10-31 12:25:41.517\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mbeir_retrieval\u001b[0m:\u001b[36m60\u001b[0m - \u001b[1mAverage time taken: 14.13 ms / query\u001b[0m\n",
      "\u001b[32m2023-10-31 12:25:41.518\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mbeir_retrieval\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mTotal time taken: 4237.63 s\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "ft_results, ft_time = ft_retriever.beir_retrieval(\"scifact\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "scifact_results.collect(\"scifact_all_mpnetv2_ft\", ft_retriever, ft_results, ft_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Zero-shot SBERT</th>\n",
       "      <th>finetune_mpnet</th>\n",
       "      <th>scifact_all_mpnetv2_ft</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NDCG@1</th>\n",
       "      <td>0.53333</td>\n",
       "      <td>0.35667</td>\n",
       "      <td>0.50667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NDCG@3</th>\n",
       "      <td>0.60009</td>\n",
       "      <td>0.45264</td>\n",
       "      <td>0.56486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NDCG@5</th>\n",
       "      <td>0.62803</td>\n",
       "      <td>0.47535</td>\n",
       "      <td>0.59359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NDCG@10</th>\n",
       "      <td>0.65570</td>\n",
       "      <td>0.50400</td>\n",
       "      <td>0.61472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NDCG@100</th>\n",
       "      <td>0.68911</td>\n",
       "      <td>0.54203</td>\n",
       "      <td>0.65350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NDCG@1000</th>\n",
       "      <td>0.69653</td>\n",
       "      <td>0.55711</td>\n",
       "      <td>0.66212</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Zero-shot SBERT  finetune_mpnet  scifact_all_mpnetv2_ft\n",
       "NDCG@1             0.53333         0.35667                 0.50667\n",
       "NDCG@3             0.60009         0.45264                 0.56486\n",
       "NDCG@5             0.62803         0.47535                 0.59359\n",
       "NDCG@10            0.65570         0.50400                 0.61472\n",
       "NDCG@100           0.68911         0.54203                 0.65350\n",
       "NDCG@1000          0.69653         0.55711                 0.66212"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scifact_results.ndcg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Paired Encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_scifact_df = pd.read_csv(\"../datasets/scifact/qg/scifact_qg_all.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_scifact_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pids = gen_scifact_df[\"pid\"].tolist()\n",
    "passages = gen_scifact_df[\"passage\"].tolist()\n",
    "titles = gen_scifact_df[\"title\"].tolist()\n",
    "questions = gen_scifact_df[\"question\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus, queries, qrels = beir_datasets.load_dataset(\"scifact\")\n",
    "corpus_ids, query_ids = list(corpus), list(queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbert_model_name = \"all-mpnet-base-v2\"\n",
    "sbert_model = SentenceTransformer(sbert_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "passages_emb = sbert_model.encode(passages, convert_to_tensor=True)\n",
    "titles_emb = sbert_model.encode(titles, convert_to_tensor=True)\n",
    "questions_emb = sbert_model.encode(questions, convert_to_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_queries_paired(passages_emb,\n",
    "                          titles_emb,\n",
    "                          questions_emb,\n",
    "                          queries: Union[str, List], # single query or batch queries\n",
    "                          top_k: int,\n",
    "                          model\n",
    "                  ) -> (List[List[int]], List[List[float]]) :\n",
    "\n",
    "    \"\"\"\n",
    "    Performs cosine similarity calculation between query and generated-(passage, titles, questions) embeddings.\n",
    "    Returns (List[list of top-k docs indices for each query], List[similarity score for each query])  \n",
    "    \"\"\"\n",
    "    \n",
    "    if isinstance(queries, str):\n",
    "        queries = [queries]\n",
    "    \n",
    "    queries_emb = model.encode(queries, convert_to_tensor=True)\n",
    "    sim_scores_passages = sbert_util.cos_sim(queries_emb, passages_emb)\n",
    "    sim_scores_titles = sbert_util.cos_sim(queries_emb, titles_emb)\n",
    "    sim_scores_questions = sbert_util.cos_sim(queries_emb, questions_emb)\n",
    "    \n",
    "    average_sim_scores = torch.vstack((sim_scores_passages, sim_scores_questions, sim_scores_titles)).mean(0, keepdim=True)\n",
    "    \n",
    "    # #### Get top-k ranking\n",
    "    average_sim_scores[torch.isnan(average_sim_scores)] = -1\n",
    "    sim_scores_top_k_values, sim_scores_top_k_idx = torch.topk(average_sim_scores, top_k, dim=1, largest=True, sorted=True)\n",
    "    \n",
    "    sim_scores_top_k_values = sim_scores_top_k_values.cpu().tolist()\n",
    "    sim_scores_top_k_idx = sim_scores_top_k_idx.cpu().tolist()\n",
    "    \n",
    "    return sim_scores_top_k_values, sim_scores_top_k_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_queries_with_emb(ref_emb,\n",
    "                          queries: Union[str, List], # single query or batch queries\n",
    "                          top_k: int,\n",
    "                          model\n",
    "                  ) -> (List[List[int]], List[List[float]]) :\n",
    "\n",
    "    \"\"\"\n",
    "    Performs cosine similarity calculation between query and generated-(passage, titles, questions) embeddings.\n",
    "    Returns (List[list of top-k docs indices for each query], List[similarity score for each query])  \n",
    "    \"\"\"\n",
    "    \n",
    "    if isinstance(queries, str):\n",
    "        queries = [queries]\n",
    "    \n",
    "    queries_emb = model.encode(queries, convert_to_tensor=True)\n",
    "    sim_scores = sbert_util.cos_sim(queries_emb, ref_emb)\n",
    "    # sim_scores_titles = sbert_util.cos_sim(queries_emb, titles_emb)\n",
    "    # sim_scores_questions = sbert_util.cos_sim(queries_emb, questions_emb)\n",
    "    \n",
    "    \n",
    "    # #### Get top-k ranking\n",
    "    sim_scores[torch.isnan(sim_scores)] = -1\n",
    "    sim_scores_top_k_values, sim_scores_top_k_idx = torch.topk(sim_scores, top_k, dim=1, largest=True, sorted=True)\n",
    "    \n",
    "    sim_scores_top_k_values = sim_scores_top_k_values.cpu().tolist()\n",
    "    sim_scores_top_k_idx = sim_scores_top_k_idx.cpu().tolist()\n",
    "    \n",
    "    return sim_scores_top_k_values, sim_scores_top_k_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerank(ref_emb: Dict[str, Dict[str, str]],\n",
    "           query_emb: Dict[str, str],\n",
    "           results: Dict[str, Dict[str, float]],\n",
    "           top_k: int) -> Dict[str, Dict[str, float]]:\n",
    "    \n",
    "        ref_emb[:top_k]        new_corpus = {}\n",
    "    \n",
    "        for query_id in results:\n",
    "            if len(results[query_id]) > top_k:\n",
    "                for (doc_id, _) in sorted(results[query_id].items(), key=lambda item: item[1], reverse=True)[:top_k]:\n",
    "                    new_corpus[doc_id] = corpus[doc_id]\n",
    "            else:\n",
    "                for doc_id in results[query_id]:\n",
    "                    new_corpus[doc_id] = corpus[doc_id]\n",
    "                    \n",
    "        return self.retriever.search(new_corpus, queries, top_k, self.score_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "passages_results_docs_ids = search_queries_with_emb(passages_emb, query, retriever.top_k+500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_emb[passages_result_docs_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "\n",
    "for query_id in query_ids:\n",
    "    query = queries[query_id]\n",
    "    _, passages_result_docs_ids = search_queries_with_emb(passages_emb, query, retriever.top_k+500)\n",
    "    _, questions_result_doc_ids = search_queries_with_emb(titles_emb[passages_result_docs_ids], query, retriever.top_k+250)\n",
    "    final_result_scores, final_result_doc_ids = search_queries_with_emb(titles_emb[questions_result_doc_ids], query, retriever.top_k)\n",
    "    results[query_id] =  {str(corpus_ids[id]): score for id, score in zip(final_result_doc_ids[0], final_result_scores[0])}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scifact_results.collect(experiment_name=\"Paired SBERT - First Try\", retriever=retriever, results=results, results_time=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scifact_results.all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_scores_passages.shape # (1, corpus length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_sim_scores = torch.vstack((sim_scores_passages, sim_scores_questions, sim_scores_titles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_sim_scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_sim_scores.mean(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## ColBERTv2 - vanilla"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The original code in `load_collection()` from _ColBERT/colbert/evaluation/loaders.py_ required monotonic `pid`, but that is not necessarily our case. We'll have to monkey patch it to pass that assertion at line 166: ```assert pid == 'id' or int(pid) == line_idx, f\"pid={pid}, line_idx={line_idx}\"``` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"fiqa\"\n",
    "corpus, queries, qrels = beir_datasets.load_dataset(dataset_name)\n",
    "\n",
    "# The indices in BeIR datasets may not be monotic, \n",
    "### so we will need a dictionary with enumerated indices (which is used in ColBERT) as keys and BeIR index as values\n",
    "### collection_ids = {colbert_index: beir_index}\n",
    "collection_ids = {idx: val for idx, val in enumerate(list(corpus))}\n",
    "\n",
    "# Load datasets for ColBERT\n",
    "collection_path, queries_path = beir_datasets.convert_for_colbert(dataset_name)\n",
    "collection, queries = Collection(path=collection_path), Queries(path=queries_path)\n",
    "\n",
    "# queries_ids = list(queries)\n",
    "# queries = list(queries.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at an example of a query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries[8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and an example of a passage from the collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(collection[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbits = 2   # encode each dimension with 2 bits\n",
    "doc_maxlen = 300 # truncate passages at 300 tokens\n",
    "\n",
    "index_name = f'{dataset_name}.{nbits}bits'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = 'colbert-ir/colbertv2.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Run().context(RunConfig(nranks=1, experiment='notebook')):  # nranks specifies the number of GPUs to use\n",
    "    config = ColBERTConfig(doc_maxlen=doc_maxlen, nbits=nbits, kmeans_niters=4) # kmeans_niters specifies the number of iterations of k-means clustering; 4 is a good and fast default.\n",
    "                                                                                # Consider larger numbers for small datasets.\n",
    "\n",
    "    indexer = Indexer(checkpoint=checkpoint, config=config)\n",
    "    indexer.index(name=index_name, collection=collection, overwrite='reuse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexer.index??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexer.get_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To create the searcher using its relative name (i.e., not a full path), set\n",
    "# experiment=value_used_for_indexing in the RunConfig.\n",
    "with Run().context(RunConfig(experiment='notebook')):\n",
    "    searcher = Searcher(index=index_name, collection=collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = queries[8] # try with an in-range query or supply your own\n",
    "print(f\"#> {query}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the top-3 passages for this query\n",
    "results = searcher.search(query, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qrels['8']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out the top-k retrieved passages\n",
    "for passage_id, passage_rank, passage_score in zip(*results):\n",
    "    print(f\"\\t [{passage_rank}] \\t\\t {passage_score:.1f} \\t\\t {searcher.collection[passage_id]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rankings = searcher.search_all(queries, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rankings.todict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xcs224u",
   "language": "python",
   "name": "xcs224u"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
